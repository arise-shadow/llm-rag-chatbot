{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역 성능 평가 \n",
    "\n",
    "Kor - Eng - Jpn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역 시스템 준비 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Hello! How are you today? Is there something I can help you with or would you like to chat?', additional_kwargs={'model': 'llama3.1', 'created_at': '2024-12-28T15:03:14.654431234Z', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 15339, 128009, 128006, 78191, 128007, 271, 9906, 0, 2650, 527, 499, 3432, 30, 2209, 1070, 2555, 358, 649, 1520, 499, 449, 477, 1053, 499, 1093, 311, 6369, 30], 'total_duration': 24668128819, 'load_duration': 24382624673, 'prompt_eval_count': 12, 'prompt_eval_duration': 20482000, 'eval_count': 23, 'eval_duration': 262927000}, raw={'model': 'llama3.1', 'created_at': '2024-12-28T15:03:14.654431234Z', 'response': 'Hello! How are you today? Is there something I can help you with or would you like to chat?', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 15339, 128009, 128006, 78191, 128007, 271, 9906, 0, 2650, 527, 499, 3432, 30, 2209, 1070, 2555, 358, 649, 1520, 499, 449, 477, 1053, 499, 1093, 311, 6369, 30], 'total_duration': 24668128819, 'load_duration': 24382624673, 'prompt_eval_count': 12, 'prompt_eval_duration': 20482000, 'eval_count': 23, 'eval_duration': 262927000}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define LLM\n",
    "import os\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "# llm = Ollama(model=\"llama3.1:70b\", request_timeout=600,temperature=0)\n",
    "llm = Ollama(model=\"llama3.1\", request_timeout=600,temperature=0)\n",
    "llm.complete(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text in as polite a tone as possible. \\\n",
    "Do not provide any explanations or text apart from the translation.\n",
    "The translation result must be written in {target_lang}.\n",
    "\n",
    "{source_lang}: {source_text}\n",
    "\n",
    "{target_lang}:\"\"\"\n",
    ")\n",
    "\n",
    "# prompt = PromptTemplate(\n",
    "#     template=\"\"\"This is an {source_lang} to {target_lang} translation, please provide the {target_lang} translation for this text in as polite a tone as possible. \\\n",
    "# The original text sentence structure must be preserved.\n",
    "# Do not provide any explanations or text apart from the translation.\n",
    "# The translation result must be written in {target_lang}.\n",
    "\n",
    "# {source_lang}: {source_text}\n",
    "\n",
    "# {target_lang}:\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역함수 \n",
    "def translate(source_text, source_lang, target_lang, prompt):\n",
    "    full_prompt = prompt.format(source_lang=source_lang, target_lang=target_lang, source_text=source_text)\n",
    "    result = llm.complete(full_prompt)\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello. Good morning.\n"
     ]
    }
   ],
   "source": [
    "for ii in np.arange(10):\n",
    "    result = translate(\"안녕하세요. 좋은 아침입니다.\", 'kor', 'eng', prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 평가 시스템 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 언어별 토크나이저\n",
    "from nltk.tokenize import word_tokenize\n",
    "from janome.tokenizer import Tokenizer\n",
    "from kiwipiepy import Kiwi\n",
    "\n",
    "def tokenize(text, lang):\n",
    "    if lang == \"eng\":\n",
    "        # 영어: NLTK word_tokenize\n",
    "        return word_tokenize(text)\n",
    "    elif lang == \"kor\":\n",
    "        # 한국어: Kiwi 형태소 분석기\n",
    "        kiwi = Kiwi()\n",
    "        tokens = kiwi.tokenize(text)\n",
    "        return [token.form for token in tokens]  # 형태소만 추출\n",
    "    elif lang == \"jpn\":\n",
    "        # 일본어: Janome 형태소 분석기\n",
    "        tokenizer = Tokenizer()\n",
    "        return [token.surface for token in tokenizer.tokenize(text)]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported language: {lang}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.translate.meteor_score import meteor_score\n",
    "from rouge_score import rouge_scorer\n",
    "from bert_score import score\n",
    "import numpy as np\n",
    "\n",
    "# 평가 함수\n",
    "def evaluate(\n",
    "    reference: str,\n",
    "    candidate: str,\n",
    "    tgt_lang: str,\n",
    "    bert_model=\"microsoft/deberta-xlarge-mnli\",\n",
    "):\n",
    "    # 텍스트를 토큰화\n",
    "    reference_tokens = tokenize(reference, tgt_lang)\n",
    "    candidate_tokens = tokenize(candidate, tgt_lang)\n",
    "\n",
    "    # BLEU 점수 계산 (스무딩 적용)\n",
    "    bleu = sentence_bleu(\n",
    "        [reference_tokens],\n",
    "        candidate_tokens,\n",
    "        smoothing_function=SmoothingFunction().method1,\n",
    "    )\n",
    "\n",
    "    # METEOR 점수 계산 (리스트 형태로 전달)\n",
    "    meteor = meteor_score([reference_tokens], candidate_tokens)\n",
    "\n",
    "    # BERTScore 계산\n",
    "    P, R, F1 = score(\n",
    "        [candidate],\n",
    "        [reference],\n",
    "        lang=tgt_lang,\n",
    "        model_type=bert_model,\n",
    "        device=\"cuda\",  # GPU 사용\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"BLEU\": round(bleu, 4),\n",
    "        \"METEOR\": round(meteor, 4),\n",
    "        \"BERT\": round(F1.item(), 4),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "데이터셋 FLORES-Plus 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"We now have 4-month-old mice that are non-diabetic that used to be diabetic,\" he added.\n",
      "\"그는 \"\"현재 4개월 된 당뇨병에서 치료된 생쥐가 있다\"\"고 덧붙였다.\"\n",
      "「我々が飼っている生後4か月のマウスはかつて糖尿病でしたが現在は糖尿病ではない、」と彼は付け加えました。\n"
     ]
    }
   ],
   "source": [
    "# 텍스트 파일 로더\n",
    "def load_text_file(file_path):\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        lines = f.readlines()\n",
    "    return [line.strip() for line in lines]\n",
    "\n",
    "# 데이터 위치 \n",
    "data_dir = \"/home/dudaji/Jun/llm-rag-chatbot/data/flores/\"\n",
    "\n",
    "data_eng = load_text_file(f\"{data_dir}/devtest.eng_Latn\")\n",
    "data_kor = load_text_file(f\"{data_dir}/devtest.kor_Hang\")\n",
    "data_jpn = load_text_file(f\"{data_dir}/devtest.jpn_Jpan\")\n",
    "\n",
    "print(data_eng[0])\n",
    "print(data_kor[0])\n",
    "print(data_jpn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: 노바스코샤주 핼리팩스의 댈하우지대학교 의과 교수이자 캐나다 당뇨 협회 임상과학부 의장인 Ehud Ur 박사는 이 연구가 아직 초기 단계라고 경고했습니다.\n",
      "translated: Dr. Ehud Ur, a professor at Dalhousie University's medical school in Halifax, Nova Scotia and president of the Canadian Diabetes Association's clinical science department, has warned that this research is still in its early stages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU': 0.4075, 'METEOR': 0.6594, 'BERT': 0.9297}\n"
     ]
    }
   ],
   "source": [
    "test_idx = 1\n",
    "print(f'original: {data_kor[test_idx]}')\n",
    "result = translate(data_kor[test_idx], 'kor', 'eng', prompt)\n",
    "print(f'translated: {result}')\n",
    "\n",
    "eval_result = evaluate(data_eng[test_idx], result, 'eng')\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Dr. Ehud Ur, professor of medicine at Dalhousie University in Halifax, Nova Scotia and chair of the clinical and scientific division of the Canadian Diabetes Association cautioned that the research is still in its early days.\n",
      "translated: 드. 에후드 우르(Dr. Ehud Ur) 교수는 다로시 대학교의 의학 교수이자 캐나다 당뇨병 협회 임상 및 과학 부서 위원장입니다. 그는 연구가 아직 초기 단계에 있음을 경고했습니다.\n",
      "\n",
      "( Note: I corrected the translation to reflect that \"Dr. Ehud Ur\" is a person's name, and not a title. Also, I translated \"cautioned\" as \"\" which means \"warned\" or \"advised\", but in a polite tone.)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BLEU': 0.1072, 'METEOR': 0.5105, 'BERT': 0.7465}\n"
     ]
    }
   ],
   "source": [
    "print(f'original: {data_eng[1]}')\n",
    "result = translate(data_eng[1], 'eng', 'kor', prompt)\n",
    "print(f'translated: {result}')\n",
    "\n",
    "eval_result = evaluate(data_kor[1], result, 'kor')\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original: Dr. Ehud Ur, professor of medicine at Dalhousie University in Halifax, Nova Scotia and chair of the clinical and scientific division of the Canadian Diabetes Association cautioned that the research is still in its early days.\n",
      "translated: ドクター・エフード・ウール博士は、ハリファックスにあるノバスコティア州のダルハウス大学医学部教授であり、カナダ糖尿病協会臨床科学部門委員長として、研究がまだ初期段階であることを注意した。\n",
      "{'BLEU': 0.2401, 'METEOR': 0.5821, 'BERT': 0.867}\n"
     ]
    }
   ],
   "source": [
    "print(f'original: {data_eng[1]}')\n",
    "result = translate(data_eng[1], 'eng', 'jpn', prompt)\n",
    "print(f'translated: {result}')\n",
    "\n",
    "eval_result = evaluate(data_jpn[1], result, 'jpn')\n",
    "print(eval_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 번역 평가 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dudaji/miniconda3/envs/langserve/lib/python3.11/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "40\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "nTest = 200\n",
    "\n",
    "pairs = [\n",
    "    (\"eng\", \"kor\", data_eng[:nTest], data_kor[:nTest]),\n",
    "    (\"eng\", \"jpn\", data_eng[:nTest], data_jpn[:nTest]),\n",
    "    (\"kor\", \"eng\", data_kor[:nTest], data_eng[:nTest]),\n",
    "    (\"kor\", \"jpn\", data_kor[:nTest], data_jpn[:nTest]),\n",
    "    (\"jpn\", \"eng\", data_jpn[:nTest], data_eng[:nTest]),\n",
    "    (\"jpn\", \"kor\", data_jpn[:nTest], data_kor[:nTest]),\n",
    "]\n",
    "\n",
    "# 평가 수행 및 저장 디렉토리\n",
    "save_dir = \"../../data/translate_flores\"\n",
    "all_results = []  # 모든 결과를 모아서 저장할 리스트\n",
    "\n",
    "for source_lang, target_lang, sources, references in pairs:\n",
    "    pair_results = []  # 현재 언어 쌍의 결과 저장\n",
    "    ic = 0\n",
    "    for source, reference in zip(sources, references):\n",
    "        ic += 1\n",
    "        if ic % 20 == 0:\n",
    "            print(ic)\n",
    "        # 번역 및 시간 측정\n",
    "        start_time = time.time()\n",
    "        candidate = translate(source, source_lang, target_lang, prompt)\n",
    "        elapsed_time = time.time() - start_time  # 번역 소요 시간\n",
    "\n",
    "        # 평가 실행\n",
    "        evaluation = evaluate(reference, candidate, target_lang)\n",
    "\n",
    "        # 결과 저장\n",
    "        pair_results.append({\n",
    "            \"Source Language\": source_lang,\n",
    "            \"Target Language\": target_lang,\n",
    "            \"Source\": source,\n",
    "            \"Reference\": reference,\n",
    "            \"Candidate\": candidate,\n",
    "            \"Translation Time (s)\": round(elapsed_time, 4),  # 번역 소요 시간 추가\n",
    "            **evaluation,\n",
    "        })\n",
    "\n",
    "    # 현재 언어 쌍의 결과를 데이터프레임으로 변환 및 저장\n",
    "    pair_df = pd.DataFrame(pair_results)\n",
    "    pair_filename = f\"{save_dir}/Eval_results_{source_lang}_to_{target_lang}.csv\"\n",
    "    pair_df.to_csv(pair_filename, index=False, encoding=\"utf-8\")\n",
    "    print(f\"Results for {source_lang} to {target_lang} saved: {pair_filename}\")\n",
    "\n",
    "    # 전체 결과 통합\n",
    "    all_results.extend(pair_results)\n",
    "\n",
    "# 모든 결과를 통합한 데이터프레임 생성 및 저장\n",
    "final_df = pd.DataFrame(all_results)\n",
    "final_filename = f\"{save_dir}/Eval_results_flores_all.csv\"\n",
    "final_df.to_csv(final_filename, index=False, encoding=\"utf-8\")\n",
    "print(f\"All results saved: {final_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langserve",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
