{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNGD SDK 문서 챗봇 \n",
    "\n",
    "- 작성자: 이준원 (Joonwon Lee)\n",
    "\n",
    "- 날짜: 12/24, 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kernel name: llm-quantize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field, HttpUrl\n",
    "import json\n",
    "from markdownify import markdownify as md\n",
    "from llama_index.core import Document \n",
    "from llama_index.core.schema import TextNode\n",
    "import os\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Page(BaseModel):\n",
    "    id: str = Field(..., description=\"ID of the Page\")\n",
    "    link: HttpUrl = Field(description=\"Url link of the page\")\n",
    "    name: str = Field(description=\"Name of the page\")\n",
    "    parent: str = Field(default=\"\", description=\"ID of the parent page\")\n",
    "    child: List[str] = Field(default=[], description=\"List of ids of the child pages\")\n",
    "    description: str = Field(default=\"\", description=\"Description of the page\")\n",
    "    description_clean: str = Field(default=\"\", description=\"Content markdown\")\n",
    "    html_content: str = Field(default=\"\", description=\"HTML code of the main content in the page\")\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash((self.link, self.name))\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        if not isinstance(other, Page):\n",
    "            return False\n",
    "        return (self.link, self.name) == (other.link, other.name)\n",
    "    \n",
    "class CustomDocument(Document):\n",
    "    page_content: str = Field(default=\"\", description=\"Additional content for the document\")\n",
    "\n",
    "def convert_page_to_llama_index_document(page: Page) -> CustomDocument:\n",
    "    return CustomDocument(\n",
    "        doc_id=page.id,\n",
    "        metadata={\n",
    "            \"source\": str(page.link),\n",
    "            \"title\": page.name,\n",
    "            \"parent_doc_id\": page.parent,\n",
    "            \"child_doc_ids\": json.dumps(page.child),\n",
    "        },\n",
    "        text=page.description_clean,  # 기본 text\n",
    "        page_content=page.description_clean,  # 추가 속성\n",
    "    )   \n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DB 가져오기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Page(id='3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/intro.html'), name='intro', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFuriosa LLM\\n===========\\n\\n\\n\\n\\n\\nFuriosa LLM\\n[#](#furiosa-llm \"Link to this heading\")\\n====================================================\\n\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models,\\nFuriosa LLM is designed to provide the state-of-the-art serving optimization.\\nThe features of Furiosa LLM includes:\\n\\n* vLLM-compatible API\\n* Efficient KV cache management with PagedAttention\\n* Continuous batching of incoming requests in serving\\n* Quantization: INT4, INT8, FP8, GPTQ, AWQ\\n* Data Parallelism and Pipeline Parallelism across multiple NPUs\\n* Tensor Parallelism (planned in release 2024.2) across multiple NPUs\\n* OpenAI-compatible API server\\n* Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned)\\n* HuggingFace model integration and hub support\\n* HuggingFace PEFT support (planned)\\n\\n\\n[previous\\n\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\")\\n[next\\n\\nReferences](references.html \"next page\")\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\") * .pdf\\nFuriosa LLM ===========\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ====================================================\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models, Furiosa LLM is designed to provide the state-of-the-art serving optimization. The features of Furiosa LLM includes:\\n* vLLM-compatible API * Efficient KV cache management with PagedAttention * Continuous batching of incoming requests in serving * Quantization: INT4, INT8, FP8, GPTQ, AWQ * Data Parallelism and Pipeline Parallelism across multiple NPUs * Tensor Parallelism (planned in release 2024.2) across multiple NPUs * OpenAI-compatible API server * Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned) * HuggingFace model integration and hub support * HuggingFace PEFT support (planned)\\n[previous\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/furiosa_llm/intro.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Furiosa LLM\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"furiosa-llm\">\\n     <span id=\"furiosallm\">\\n     </span>\\n     <h1>\\n      Furiosa LLM\\n      <a class=\"headerlink\" href=\"#furiosa-llm\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      Furiosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models,\\nFuriosa LLM is designed to provide the state-of-the-art serving optimization.\\nThe features of Furiosa LLM includes:\\n     </p>\\n     <ul class=\"simple\">\\n      <li>\\n       <p>\\n        vLLM-compatible API\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Efficient KV cache management with PagedAttention\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Continuous batching of incoming requests in serving\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Quantization: INT4, INT8, FP8, GPTQ, AWQ\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Data Parallelism and Pipeline Parallelism across multiple NPUs\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Tensor Parallelism (planned in release 2024.2) across multiple NPUs\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        OpenAI-compatible API server\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned)\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        HuggingFace model integration and hub support\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        HuggingFace PEFT support (planned)\\n       </p>\\n      </li>\\n     </ul>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../getting_started/furiosa_mlperf.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Running MLPerf™ Inference Benchmark\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"references.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        References\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='dcd59fbc-fb76-4f34-b6ec-ea88a833b047', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/kubernetes/device_plugin.html'), name='device_plugin', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/cloud_native_toolkit/kubernetes/device_plugin.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstalling Furiosa Device Plugin\\n================================\\n\\n\\nContents\\n--------\\n\\n\\n* [Furiosa Device Plugin](#furiosa-device-plugin)\\n  + [Configuration](#configuration)\\n  + [Deploying Furiosa Device Plugin with Helm](#deploying-furiosa-device-plugin-with-helm)\\n\\n\\n\\n\\n\\nInstalling Furiosa Device Plugin\\n[#](#installing-furiosa-device-plugin \"Link to this heading\")\\n==============================================================================================\\n\\nFuriosa Device Plugin\\n[#](#furiosa-device-plugin \"Link to this heading\")\\n------------------------------------------------------------------------\\n\\nThe Furiosa device plugin implements the\\n[Kubernetes Device Plugin](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/)\\ninterface for FuriosaAI NPU devices, and its features are as follows:\\n\\n* discovering the Furiosa NPU devices and register to a Kubernetes cluster.\\n* tracking the health of the devices and report to a Kubernetes cluster.\\n* running AI workload on the top of the Furiosa NPU devices within a Kubernetes cluster.\\n\\n### Configuration [#](#configuration \"Link to this heading\")\\n\\nThe Furiosa NPU can be integrated into the Kubernetes cluster in various configurations.\\nA single NPU card can either be exposed as a single resource or partitioned into multiple resources.\\nPartitioning into multiple resources allows for more granular control.\\n\\nThe following table shows the available resource strategy:\\n\\n\\nResource Strategy\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n\\n| NPU Configuration | Resource Name | Resource Count Per Card |\\n| --- | --- | --- |\\n| legacy | beta.furiosa.ai/npu | 1 |\\n| generic | furiosa.ai/rngd | 1 |\\n\\nThe helm chart of Furiosa device plugin is available at\\n[furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts)\\n.\\n\\nFollowing shows default values of the helm chart.\\n\\n```\\nconfig:\\n  resourceStrategy: generic\\n  debugMode: false\\n  disabledDeviceUUIDListMap:\\n\\n```\\n\\n\\n\\n### Deploying Furiosa Device Plugin with Helm [#](#deploying-furiosa-device-plugin-with-helm \"Link to this heading\")\\n\\nThe Furiosa device plugin helm chart is available at\\n[furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts)\\n. To configure deployment as you need, you can modify\\n`charts/furiosa-device-plugin/values.yaml`\\n.\\n\\n* If resourceStrategy is not specified, the default value is\\n  `\"generic\"`\\n  .\\n* If debugMode is not specified, the default value is\\n  `false`\\n  .\\n* If disabledDeviceUUIDListMap is not specified, the default value is empty list\\n  `[]`\\n  .\\n\\nYou can deploy the Furiosa Device Plugin by running the following commands:\\n\\n```\\nhelm repo add furiosa https://furiosa-ai.github.io/helm-charts\\nhelm repo update\\nhelm install furiosa-device-plugin furiosa/furiosa-device-plugin -n kube-system\\n\\n```\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nInstalling Furiosa Feature Discovery](feature_discovery.html \"previous page\")\\n[next\\n\\nInstalling Furiosa Metrics Exporter](metrics_exporter.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Furiosa Device Plugin](#furiosa-device-plugin)\\n  + [Configuration](#configuration)\\n  + [Deploying Furiosa Device Plugin with Helm](#deploying-furiosa-device-plugin-with-helm)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/cloud_native_toolkit/kubernetes/device_plugin.rst \"Download source file\") * .pdf\\nInstalling Furiosa Device Plugin ================================\\nContents --------\\n* [Furiosa Device Plugin](#furiosa-device-plugin)   + [Configuration](#configuration)   + [Deploying Furiosa Device Plugin with Helm](#deploying-furiosa-device-plugin-with-helm)\\nInstalling Furiosa Device Plugin [#](#installing-furiosa-device-plugin \"Link to this heading\") ==============================================================================================\\nFuriosa Device Plugin [#](#furiosa-device-plugin \"Link to this heading\") ------------------------------------------------------------------------\\nThe Furiosa device plugin implements the [Kubernetes Device Plugin](https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/) interface for FuriosaAI NPU devices, and its features are as follows:\\n* discovering the Furiosa NPU devices and register to a Kubernetes cluster. * tracking the health of the devices and report to a Kubernetes cluster. * running AI workload on the top of the Furiosa NPU devices within a Kubernetes cluster.\\n### Configuration [#](#configuration \"Link to this heading\")\\nThe Furiosa NPU can be integrated into the Kubernetes cluster in various configurations. A single NPU card can either be exposed as a single resource or partitioned into multiple resources. Partitioning into multiple resources allows for more granular control.\\nThe following table shows the available resource strategy:\\nResource Strategy\\n[#](#id1 \"Link to this table\")\\n| NPU Configuration | Resource Name | Resource Count Per Card | | --- | --- | --- | | legacy | beta.furiosa.ai/npu | 1 | | generic | furiosa.ai/rngd | 1 |\\nThe helm chart of Furiosa device plugin is available at [furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts) .\\nFollowing shows default values of the helm chart.\\n``` config:   resourceStrategy: generic   debugMode: false   disabledDeviceUUIDListMap:\\n```\\n### Deploying Furiosa Device Plugin with Helm [#](#deploying-furiosa-device-plugin-with-helm \"Link to this heading\")\\nThe Furiosa device plugin helm chart is available at [furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts) . To configure deployment as you need, you can modify `charts/furiosa-device-plugin/values.yaml` .\\n* If resourceStrategy is not specified, the default value is   `\"generic\"`   . * If debugMode is not specified, the default value is   `false`   . * If disabledDeviceUUIDListMap is not specified, the default value is empty list   `[]`   .\\nYou can deploy the Furiosa Device Plugin by running the following commands:\\n``` helm repo add furiosa https://furiosa-ai.github.io/helm-charts helm repo update helm install furiosa-device-plugin furiosa/furiosa-device-plugin -n kube-system\\n```\\n[previous\\nInstalling Furiosa Feature Discovery](feature_discovery.html \"previous page\") [next\\nInstalling Furiosa Metrics Exporter](metrics_exporter.html \"next page\")\\nContents\\n* [Furiosa Device Plugin](#furiosa-device-plugin)   + [Configuration](#configuration)   + [Deploying Furiosa Device Plugin with Helm](#deploying-furiosa-device-plugin-with-helm)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/cloud_native_toolkit/kubernetes/device_plugin.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Installing Furiosa Device Plugin\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-device-plugin\">\\n          Furiosa Device Plugin\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#configuration\">\\n            Configuration\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-device-plugin-with-helm\">\\n            Deploying Furiosa Device Plugin with Helm\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"installing-furiosa-device-plugin\">\\n     <span id=\"deviceplugin\">\\n     </span>\\n     <h1>\\n      Installing Furiosa Device Plugin\\n      <a class=\"headerlink\" href=\"#installing-furiosa-device-plugin\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <section id=\"furiosa-device-plugin\">\\n      <h2>\\n       Furiosa Device Plugin\\n       <a class=\"headerlink\" href=\"#furiosa-device-plugin\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The Furiosa device plugin implements the\\n       <a class=\"reference external\" href=\"https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/\">\\n        Kubernetes Device Plugin\\n       </a>\\n       interface for FuriosaAI NPU devices, and its features are as follows:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         discovering the Furiosa NPU devices and register to a Kubernetes cluster.\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         tracking the health of the devices and report to a Kubernetes cluster.\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         running AI workload on the top of the Furiosa NPU devices within a Kubernetes cluster.\\n        </p>\\n       </li>\\n      </ul>\\n      <section id=\"configuration\">\\n       <h3>\\n        Configuration\\n        <a class=\"headerlink\" href=\"#configuration\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The Furiosa NPU can be integrated into the Kubernetes cluster in various configurations.\\nA single NPU card can either be exposed as a single resource or partitioned into multiple resources.\\nPartitioning into multiple resources allows for more granular control.\\n       </p>\\n       <p>\\n        The following table shows the available resource strategy:\\n       </p>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table table-center\" id=\"id1\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           Resource Strategy\\n          </span>\\n          <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 33.3%\"/>\\n          <col style=\"width: 33.3%\"/>\\n          <col style=\"width: 33.3%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             NPU Configuration\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Resource Name\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Resource Count Per Card\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             legacy\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             beta.furiosa.ai/npu\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             1\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             generic\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa.ai/rngd\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             1\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n       <p>\\n        The helm chart of Furiosa device plugin is available at\\n        <a class=\"github reference external\" href=\"https://github.com/furiosa-ai/helm-charts\">\\n         furiosa-ai/helm-charts\\n        </a>\\n        .\\n       </p>\\n       <p>\\n        Following shows default values of the helm chart.\\n       </p>\\n       <div class=\"highlight-yaml notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"nt\">config</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"nt\">resourceStrategy</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">generic</span>\\n<span class=\"w\">  </span><span class=\"nt\">debugMode</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">false</span>\\n<span class=\"w\">  </span><span class=\"nt\">disabledDeviceUUIDListMap</span><span class=\"p\">:</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"deploying-furiosa-device-plugin-with-helm\">\\n       <h3>\\n        Deploying Furiosa Device Plugin with Helm\\n        <a class=\"headerlink\" href=\"#deploying-furiosa-device-plugin-with-helm\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The Furiosa device plugin helm chart is available at\\n        <a class=\"github reference external\" href=\"https://github.com/furiosa-ai/helm-charts\">\\n         furiosa-ai/helm-charts\\n        </a>\\n        . To configure deployment as you need, you can modify\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          charts/furiosa-device-plugin/values.yaml\\n         </span>\\n        </code>\\n        .\\n       </p>\\n       <ul class=\"simple\">\\n        <li>\\n         <p>\\n          If resourceStrategy is not specified, the default value is\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            \"generic\"\\n           </span>\\n          </code>\\n          .\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          If debugMode is not specified, the default value is\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            false\\n           </span>\\n          </code>\\n          .\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          If disabledDeviceUUIDListMap is not specified, the default value is empty list\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            []\\n           </span>\\n          </code>\\n          .\\n         </p>\\n        </li>\\n       </ul>\\n       <p>\\n        You can deploy the Furiosa Device Plugin by running the following commands:\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>helm<span class=\"w\"> </span>repo<span class=\"w\"> </span>add<span class=\"w\"> </span>furiosa<span class=\"w\"> </span>https://furiosa-ai.github.io/helm-charts\\nhelm<span class=\"w\"> </span>repo<span class=\"w\"> </span>update\\nhelm<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-device-plugin<span class=\"w\"> </span>furiosa/furiosa-device-plugin<span class=\"w\"> </span>-n<span class=\"w\"> </span>kube-system\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"feature_discovery.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Feature Discovery\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"metrics_exporter.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Metrics Exporter\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-device-plugin\">\\n         Furiosa Device Plugin\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#configuration\">\\n           Configuration\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-device-plugin-with-helm\">\\n           Deploying Furiosa Device Plugin with Helm\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='3bb3bd0a-7bdc-45a7-8e3e-e556a52d7eda', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/getting_started/furiosa_mlperf.html'), name='furiosa_mlperf', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/getting_started/furiosa_mlperf.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRunning MLPerf™ Inference Benchmark\\n===================================\\n\\n\\nContents\\n--------\\n\\n\\n* [Installing\\n  `furiosa-mlperf`\\n  command](#installing-furiosa-mlperf-command)\\n* [Running MLPerf Inference Benchmark](#id1)\\n  + [SYNOPSIS](#synopsis)\\n  + [Examples](#examples)\\n* [Running\\n  `furiosa-mlperf`\\n  in container environment](#running-furiosa-mlperf-in-container-environment)\\n\\n\\n\\n\\n\\nRunning MLPerf™ Inference Benchmark\\n[#](#running-mlperf-inference-benchmark \"Link to this heading\")\\n===================================================================================================\\n\\nMLPerf™ is a benchmark suite that evaluates the performance of machine learning (ML) software, hardware, and\\ncloud platforms. It is generally used to compare the performance of different systems,\\nand to help developers and end users make decisions about AI systems.\\n\\nFuriosaAI Software Stack provides\\n`furiosa-mlperf`\\ncommand to run easily the MLPerf Inference Benchmark.\\nThis section describes how to reproduce the MLPerf™ Inference Benchmark using the FuriosaAI Software Stack.\\n\\nNote\\n\\n`furiosa-mlperf`\\nis based on MLPerf™ Inference Benchmark v4.1.\\n\\nThe only exception is that we replaced the Llama2 benchmark with one using Llama 3.1.\\n\\n\\nInstalling\\n`furiosa-mlperf`\\ncommand\\n[#](#installing-furiosa-mlperf-command \"Link to this heading\")\\n--------------------------------------------------------------------------------------------------\\n\\nTo install the\\n`furiosa-mlperf`\\ncommand, you need to install\\n`furiosa-mlperf`\\nas following:\\n\\nThe minimum requirements for\\n`furiosa-mlperf`\\nare as follows:\\n\\n* Ubuntu 20.04 LTS (Debian bullseye) or later\\n* Root permission or sudo permission\\n* Configuring the APT server and installing device drivers (\\n  [Setting up APT server](prerequisites.html#aptsetup)\\n  )\\n* About 100GB storage space (only for the Llama 3.1 70B)\\n\\nThen, please install the\\n`furiosa-mlperf`\\npackage as follows:\\n\\n```\\nsudo apt update\\nsudo apt install -y furiosa-mlperf\\n\\n```\\n\\nThis command installs packages\\n`furiosa-compiler`\\n,\\n`furiosa-mlperf`\\nand\\n`furiosa-mlperf-resources`\\n.\\n\\n\\nRunning MLPerf Inference Benchmark\\n[#](#id1 \"Link to this heading\")\\n-------------------------------------------------------------------\\n\\n### SYNOPSIS [#](#synopsis \"Link to this heading\")\\n\\nThe\\n`furiosa-mlperf`\\ncommand provides the following subcommands:\\n\\n```\\nFuriosaAI MLPerf Inference Benchmark Launcher v2024.1.0 (2024-10-04T13:45:37Z)\\n\\nUsage: furiosa-mlperf <COMMAND>\\n\\nCommands:\\n  bert-offline       Run BERT benchmark with offline scenario\\n  bert-server        Run BERT benchmark with server scenario\\n  gpt-j-offline      Run GPT-J benchmark with offline scenario\\n  gpt-j-server       Run GPT-J benchmark with server scenario\\n  llama-3.1-offline  Run Llama 3.1 benchmark with offline scenario\\n  llama-3.1-server   Run Llama 3.1 benchmark with server scenario\\n  help               Print this message or the help of the given subcommand(s)\\n\\nOptions:\\n  -h, --help     Print help\\n  -V, --version  Print version\\n\\n```\\n\\n\\n\\n### Examples [#](#examples \"Link to this heading\")\\n\\n* BERT benchmark\\n  \\n  The BERT benchmark is based on running with a single RNGD.\\n  \\n  + Server Scenario\\n    \\n    To run BERT Large serving inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf bert-server ./bert-large ./bert-server-result --device-mesh \"npu:0:*\"\\n    \\n    ```\\n  + Offline Scenario\\n    \\n    To run BERT Large offline inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf bert-offline ./bert-large ./bert-offline-result --device-mesh \"npu:0:*\"\\n    \\n    ```\\n* GPT-J benchmark\\n  \\n  The GPT-J benchmark is based on running with a single RNGD.\\n  \\n  + Server Scenario\\n    \\n    To run GPT-J 6B serving inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf gpt-j-server ./gpt-j-6b ./gpt-j-server-result\\n    \\n    ```\\n  + Offline Scenario\\n    \\n    To run GPT-J 6B offline inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf gpt-j-offline ./gpt-j-6b ./gpt-j-offline-result\\n    \\n    ```\\n* Llama 3.1 benchmark\\n  \\n  The Llama 3.1 benchmark is based on running with four RNGDs.\\n  \\n  + Server Scenario\\n    \\n    To run Llama 3.1 70B serving inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf llama-3.1-server ./llama-3.1-70b ./llama-3.1-server-result\\n    \\n    ```\\n  + Offline Scenario\\n    \\n    To run Llama 3.1 70B offline inference benchmark, you can use the following command:\\n    \\n    ```\\n    furiosa-mlperf llama-3.1-offline ./llama-3.1-70b ./llama-3.1-offline-result\\n    \\n    ```\\n* Common\\n  \\n  Once the process completes, it writes the results to a file in the specified results directory.\\n  You can open this file to view a summary of the results.\\n  \\n  ```\\n  cat gpt-j-offline-result/mlperf_log_summary.txt\\n  \\n  ```\\n  \\n  \\n  ```\\n  ================================================\\n  MLPerf Results Summary\\n  ================================================\\n  SUT name : GPT-J SUT\\n  Scenario : Offline\\n  Mode     : PerformanceOnly\\n  Samples per second: 11.842\\n  Tokens per second (inferred): 817.095\\n  Result is : VALID\\n    Min duration satisfied : Yes\\n    Min queries satisfied : Yes\\n    Early stopping satisfied: Yes\\n  \\n  ```\\n\\n\\nRunning\\n`furiosa-mlperf`\\nin container environment\\n[#](#running-furiosa-mlperf-in-container-environment \"Link to this heading\")\\n------------------------------------------------------------------------------------------------------------------------------\\n\\nFuriosaAI provides a containerized version of the\\n`furiosa-mlperf`\\ncommand.\\nIf you use the containerized version, you can run the\\n`furiosa-mlperf`\\ncommand\\nwithout installing the FuriosaAI Software Stack on your host system or\\nyou can run the command on Kubernetes environment.\\n\\nTo run the\\n`furiosa-mlperf`\\ncontainer, you can use the following command:\\n\\n(Assumes model artifacts exist in\\n`/opt/gpt-j-6b`\\ndirectory)\\n\\n```\\n$ docker run -it --rm --privileged \\\\\\n  -v /opt/gpt-j-6b:gpt-j-6b furiosa-mlperf:2024.1.0 bash\\n\\n(container) # furiosa-mlperf gpt-j-offline /gpt-j-6b /gpt-j-offline-result\\n\\n```\\n\\nTo run in a containerized environment, refer to the examples provided in this document.\\n\\nWarning\\n\\nThe example above uses the\\n`--privileged`\\noption for simplicity, but it is not recommended for security reasons.\\nIf you are using Kubernetes, please refer to the following page for the recommended method:\\n[Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n\\n\\n\\n\\n\\n[previous\\n\\nQuick Start with Furiosa LLM](furiosa_llm.html \"previous page\")\\n[next\\n\\nFuriosa LLM](../furiosa_llm/intro.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Installing\\n  `furiosa-mlperf`\\n  command](#installing-furiosa-mlperf-command)\\n* [Running MLPerf Inference Benchmark](#id1)\\n  + [SYNOPSIS](#synopsis)\\n  + [Examples](#examples)\\n* [Running\\n  `furiosa-mlperf`\\n  in container environment](#running-furiosa-mlperf-in-container-environment)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/getting_started/furiosa_mlperf.rst \"Download source file\") * .pdf\\nRunning MLPerf™ Inference Benchmark ===================================\\nContents --------\\n* [Installing   `furiosa-mlperf`   command](#installing-furiosa-mlperf-command) * [Running MLPerf Inference Benchmark](#id1)   + [SYNOPSIS](#synopsis)   + [Examples](#examples) * [Running   `furiosa-mlperf`   in container environment](#running-furiosa-mlperf-in-container-environment)\\nRunning MLPerf™ Inference Benchmark [#](#running-mlperf-inference-benchmark \"Link to this heading\") ===================================================================================================\\nMLPerf™ is a benchmark suite that evaluates the performance of machine learning (ML) software, hardware, and cloud platforms. It is generally used to compare the performance of different systems, and to help developers and end users make decisions about AI systems.\\nFuriosaAI Software Stack provides `furiosa-mlperf` command to run easily the MLPerf Inference Benchmark. This section describes how to reproduce the MLPerf™ Inference Benchmark using the FuriosaAI Software Stack.\\nNote  `furiosa-mlperf` is based on MLPerf™ Inference Benchmark v4.1.\\nThe only exception is that we replaced the Llama2 benchmark with one using Llama 3.1.\\nInstalling `furiosa-mlperf` command [#](#installing-furiosa-mlperf-command \"Link to this heading\") --------------------------------------------------------------------------------------------------\\nTo install the `furiosa-mlperf` command, you need to install `furiosa-mlperf` as following:\\nThe minimum requirements for `furiosa-mlperf` are as follows:\\n* Ubuntu 20.04 LTS (Debian bullseye) or later * Root permission or sudo permission * Configuring the APT server and installing device drivers (   [Setting up APT server](prerequisites.html#aptsetup)   ) * About 100GB storage space (only for the Llama 3.1 70B)\\nThen, please install the `furiosa-mlperf` package as follows:\\n``` sudo apt update sudo apt install -y furiosa-mlperf\\n```\\nThis command installs packages `furiosa-compiler` , `furiosa-mlperf` and `furiosa-mlperf-resources` .\\nRunning MLPerf Inference Benchmark [#](#id1 \"Link to this heading\") -------------------------------------------------------------------\\n### SYNOPSIS [#](#synopsis \"Link to this heading\")\\nThe `furiosa-mlperf` command provides the following subcommands:\\n``` FuriosaAI MLPerf Inference Benchmark Launcher v2024.1.0 (2024-10-04T13:45:37Z)\\nUsage: furiosa-mlperf <COMMAND>\\nCommands:   bert-offline       Run BERT benchmark with offline scenario   bert-server        Run BERT benchmark with server scenario   gpt-j-offline      Run GPT-J benchmark with offline scenario   gpt-j-server       Run GPT-J benchmark with server scenario   llama-3.1-offline  Run Llama 3.1 benchmark with offline scenario   llama-3.1-server   Run Llama 3.1 benchmark with server scenario   help               Print this message or the help of the given subcommand(s)\\nOptions:   -h, --help     Print help   -V, --version  Print version\\n```\\n### Examples [#](#examples \"Link to this heading\")\\n* BERT benchmark      The BERT benchmark is based on running with a single RNGD.      + Server Scenario          To run BERT Large serving inference benchmark, you can use the following command:          ```     furiosa-mlperf bert-server ./bert-large ./bert-server-result --device-mesh \"npu:0:*\"          ```   + Offline Scenario          To run BERT Large offline inference benchmark, you can use the following command:          ```     furiosa-mlperf bert-offline ./bert-large ./bert-offline-result --device-mesh \"npu:0:*\"          ``` * GPT-J benchmark      The GPT-J benchmark is based on running with a single RNGD.      + Server Scenario          To run GPT-J 6B serving inference benchmark, you can use the following command:          ```     furiosa-mlperf gpt-j-server ./gpt-j-6b ./gpt-j-server-result          ```   + Offline Scenario          To run GPT-J 6B offline inference benchmark, you can use the following command:          ```     furiosa-mlperf gpt-j-offline ./gpt-j-6b ./gpt-j-offline-result          ``` * Llama 3.1 benchmark      The Llama 3.1 benchmark is based on running with four RNGDs.      + Server Scenario          To run Llama 3.1 70B serving inference benchmark, you can use the following command:          ```     furiosa-mlperf llama-3.1-server ./llama-3.1-70b ./llama-3.1-server-result          ```   + Offline Scenario          To run Llama 3.1 70B offline inference benchmark, you can use the following command:          ```     furiosa-mlperf llama-3.1-offline ./llama-3.1-70b ./llama-3.1-offline-result          ``` * Common      Once the process completes, it writes the results to a file in the specified results directory.   You can open this file to view a summary of the results.      ```   cat gpt-j-offline-result/mlperf_log_summary.txt      ```         ```   ================================================   MLPerf Results Summary   ================================================   SUT name : GPT-J SUT   Scenario : Offline   Mode     : PerformanceOnly   Samples per second: 11.842   Tokens per second (inferred): 817.095   Result is : VALID     Min duration satisfied : Yes     Min queries satisfied : Yes     Early stopping satisfied: Yes      ```\\nRunning `furiosa-mlperf` in container environment [#](#running-furiosa-mlperf-in-container-environment \"Link to this heading\") ------------------------------------------------------------------------------------------------------------------------------\\nFuriosaAI provides a containerized version of the `furiosa-mlperf` command. If you use the containerized version, you can run the `furiosa-mlperf` command without installing the FuriosaAI Software Stack on your host system or you can run the command on Kubernetes environment.\\nTo run the `furiosa-mlperf` container, you can use the following command:\\n(Assumes model artifacts exist in `/opt/gpt-j-6b` directory)\\n``` $ docker run -it --rm --privileged \\\\   -v /opt/gpt-j-6b:gpt-j-6b furiosa-mlperf:2024.1.0 bash\\n(container) # furiosa-mlperf gpt-j-offline /gpt-j-6b /gpt-j-offline-result\\n```\\nTo run in a containerized environment, refer to the examples provided in this document.\\nWarning\\nThe example above uses the `--privileged` option for simplicity, but it is not recommended for security reasons. If you are using Kubernetes, please refer to the following page for the recommended method: [Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n[previous\\nQuick Start with Furiosa LLM](furiosa_llm.html \"previous page\") [next\\nFuriosa LLM](../furiosa_llm/intro.html \"next page\")\\nContents\\n* [Installing   `furiosa-mlperf`   command](#installing-furiosa-mlperf-command) * [Running MLPerf Inference Benchmark](#id1)   + [SYNOPSIS](#synopsis)   + [Examples](#examples) * [Running   `furiosa-mlperf`   in container environment](#running-furiosa-mlperf-in-container-environment)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/getting_started/furiosa_mlperf.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Running MLPerf™ Inference Benchmark\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#installing-furiosa-mlperf-command\">\\n          Installing\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            furiosa-mlperf\\n           </span>\\n          </code>\\n          command\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#id1\">\\n          Running MLPerf Inference Benchmark\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#synopsis\">\\n            SYNOPSIS\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#examples\">\\n            Examples\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#running-furiosa-mlperf-in-container-environment\">\\n          Running\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            furiosa-mlperf\\n           </span>\\n          </code>\\n          in container environment\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"running-mlperf-inference-benchmark\">\\n     <span id=\"gettingstartedfuriosamlperf\">\\n     </span>\\n     <h1>\\n      Running MLPerf™ Inference Benchmark\\n      <a class=\"headerlink\" href=\"#running-mlperf-inference-benchmark\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      MLPerf™ is a benchmark suite that evaluates the performance of machine learning (ML) software, hardware, and\\ncloud platforms. It is generally used to compare the performance of different systems,\\nand to help developers and end users make decisions about AI systems.\\n     </p>\\n     <p>\\n      FuriosaAI Software Stack provides\\n      <code class=\"docutils literal notranslate\">\\n       <span class=\"pre\">\\n        furiosa-mlperf\\n       </span>\\n      </code>\\n      command to run easily the MLPerf Inference Benchmark.\\nThis section describes how to reproduce the MLPerf™ Inference Benchmark using the FuriosaAI Software Stack.\\n     </p>\\n     <div class=\"admonition note\">\\n      <p class=\"admonition-title\">\\n       Note\\n      </p>\\n      <p>\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       is based on MLPerf™ Inference Benchmark v4.1.\\n      </p>\\n      <p>\\n       The only exception is that we replaced the Llama2 benchmark with one using Llama 3.1.\\n      </p>\\n     </div>\\n     <section id=\"installing-furiosa-mlperf-command\">\\n      <h2>\\n       Installing\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       command\\n       <a class=\"headerlink\" href=\"#installing-furiosa-mlperf-command\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       To install the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       command, you need to install\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       as following:\\n      </p>\\n      <p>\\n       The minimum requirements for\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       are as follows:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         Ubuntu 20.04 LTS (Debian bullseye) or later\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Root permission or sudo permission\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Configuring the APT server and installing device drivers (\\n         <a class=\"reference internal\" href=\"prerequisites.html#aptsetup\">\\n          <span class=\"std std-ref\">\\n           Setting up APT server\\n          </span>\\n         </a>\\n         )\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         About 100GB storage space (only for the Llama 3.1 70B)\\n        </p>\\n       </li>\\n      </ul>\\n      <p>\\n       Then, please install the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       package as follows:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>update\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>-y<span class=\"w\"> </span>furiosa-mlperf\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       This command installs packages\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-compiler\\n        </span>\\n       </code>\\n       ,\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       and\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf-resources\\n        </span>\\n       </code>\\n       .\\n      </p>\\n     </section>\\n     <section id=\"id1\">\\n      <h2>\\n       Running MLPerf Inference Benchmark\\n       <a class=\"headerlink\" href=\"#id1\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <section id=\"synopsis\">\\n       <h3>\\n        SYNOPSIS\\n        <a class=\"headerlink\" href=\"#synopsis\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-mlperf\\n         </span>\\n        </code>\\n        command provides the following subcommands:\\n       </p>\\n       <div class=\"highlight-default notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">FuriosaAI</span> <span class=\"n\">MLPerf</span> <span class=\"n\">Inference</span> <span class=\"n\">Benchmark</span> <span class=\"n\">Launcher</span> <span class=\"n\">v2024</span><span class=\"mf\">.1.0</span> <span class=\"p\">(</span><span class=\"mi\">2024</span><span class=\"o\">-</span><span class=\"mi\">10</span><span class=\"o\">-</span><span class=\"mi\">04</span><span class=\"n\">T13</span><span class=\"p\">:</span><span class=\"mi\">45</span><span class=\"p\">:</span><span class=\"mi\">37</span><span class=\"n\">Z</span><span class=\"p\">)</span>\\n\\n<span class=\"n\">Usage</span><span class=\"p\">:</span> <span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">mlperf</span> <span class=\"o\">&lt;</span><span class=\"n\">COMMAND</span><span class=\"o\">&gt;</span>\\n\\n<span class=\"n\">Commands</span><span class=\"p\">:</span>\\n  <span class=\"n\">bert</span><span class=\"o\">-</span><span class=\"n\">offline</span>       <span class=\"n\">Run</span> <span class=\"n\">BERT</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">offline</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">bert</span><span class=\"o\">-</span><span class=\"n\">server</span>        <span class=\"n\">Run</span> <span class=\"n\">BERT</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">server</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">gpt</span><span class=\"o\">-</span><span class=\"n\">j</span><span class=\"o\">-</span><span class=\"n\">offline</span>      <span class=\"n\">Run</span> <span class=\"n\">GPT</span><span class=\"o\">-</span><span class=\"n\">J</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">offline</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">gpt</span><span class=\"o\">-</span><span class=\"n\">j</span><span class=\"o\">-</span><span class=\"n\">server</span>       <span class=\"n\">Run</span> <span class=\"n\">GPT</span><span class=\"o\">-</span><span class=\"n\">J</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">server</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mf\">3.1</span><span class=\"o\">-</span><span class=\"n\">offline</span>  <span class=\"n\">Run</span> <span class=\"n\">Llama</span> <span class=\"mf\">3.1</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">offline</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mf\">3.1</span><span class=\"o\">-</span><span class=\"n\">server</span>   <span class=\"n\">Run</span> <span class=\"n\">Llama</span> <span class=\"mf\">3.1</span> <span class=\"n\">benchmark</span> <span class=\"k\">with</span> <span class=\"n\">server</span> <span class=\"n\">scenario</span>\\n  <span class=\"n\">help</span>               <span class=\"n\">Print</span> <span class=\"n\">this</span> <span class=\"n\">message</span> <span class=\"ow\">or</span> <span class=\"n\">the</span> <span class=\"n\">help</span> <span class=\"n\">of</span> <span class=\"n\">the</span> <span class=\"n\">given</span> <span class=\"n\">subcommand</span><span class=\"p\">(</span><span class=\"n\">s</span><span class=\"p\">)</span>\\n\\n<span class=\"n\">Options</span><span class=\"p\">:</span>\\n  <span class=\"o\">-</span><span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"o\">--</span><span class=\"n\">help</span>     <span class=\"n\">Print</span> <span class=\"n\">help</span>\\n  <span class=\"o\">-</span><span class=\"n\">V</span><span class=\"p\">,</span> <span class=\"o\">--</span><span class=\"n\">version</span>  <span class=\"n\">Print</span> <span class=\"n\">version</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"examples\">\\n       <h3>\\n        Examples\\n        <a class=\"headerlink\" href=\"#examples\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <ul>\\n        <li>\\n         <p>\\n          BERT benchmark\\n         </p>\\n         <p>\\n          The BERT benchmark is based on running with a single RNGD.\\n         </p>\\n         <ul>\\n          <li>\\n           <p>\\n            Server Scenario\\n           </p>\\n           <p>\\n            To run BERT Large serving inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>bert-server<span class=\"w\"> </span>./bert-large<span class=\"w\"> </span>./bert-server-result<span class=\"w\"> </span>--device-mesh<span class=\"w\"> </span><span class=\"s2\">\"npu:0:*\"</span>\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n          <li>\\n           <p>\\n            Offline Scenario\\n           </p>\\n           <p>\\n            To run BERT Large offline inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>bert-offline<span class=\"w\"> </span>./bert-large<span class=\"w\"> </span>./bert-offline-result<span class=\"w\"> </span>--device-mesh<span class=\"w\"> </span><span class=\"s2\">\"npu:0:*\"</span>\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n         </ul>\\n        </li>\\n        <li>\\n         <p>\\n          GPT-J benchmark\\n         </p>\\n         <p>\\n          The GPT-J benchmark is based on running with a single RNGD.\\n         </p>\\n         <ul>\\n          <li>\\n           <p>\\n            Server Scenario\\n           </p>\\n           <p>\\n            To run GPT-J 6B serving inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>gpt-j-server<span class=\"w\"> </span>./gpt-j-6b<span class=\"w\"> </span>./gpt-j-server-result\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n          <li>\\n           <p>\\n            Offline Scenario\\n           </p>\\n           <p>\\n            To run GPT-J 6B offline inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>gpt-j-offline<span class=\"w\"> </span>./gpt-j-6b<span class=\"w\"> </span>./gpt-j-offline-result\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n         </ul>\\n        </li>\\n        <li>\\n         <p>\\n          Llama 3.1 benchmark\\n         </p>\\n         <p>\\n          The Llama 3.1 benchmark is based on running with four RNGDs.\\n         </p>\\n         <ul>\\n          <li>\\n           <p>\\n            Server Scenario\\n           </p>\\n           <p>\\n            To run Llama 3.1 70B serving inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>llama-3.1-server<span class=\"w\"> </span>./llama-3.1-70b<span class=\"w\"> </span>./llama-3.1-server-result\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n          <li>\\n           <p>\\n            Offline Scenario\\n           </p>\\n           <p>\\n            To run Llama 3.1 70B offline inference benchmark, you can use the following command:\\n           </p>\\n           <div class=\"highlight-sh notranslate\">\\n            <div class=\"highlight\">\\n             <pre><span></span>furiosa-mlperf<span class=\"w\"> </span>llama-3.1-offline<span class=\"w\"> </span>./llama-3.1-70b<span class=\"w\"> </span>./llama-3.1-offline-result\\n</pre>\\n            </div>\\n           </div>\\n          </li>\\n         </ul>\\n        </li>\\n        <li>\\n         <p>\\n          Common\\n         </p>\\n         <p>\\n          Once the process completes, it writes the results to a file in the specified results directory.\\nYou can open this file to view a summary of the results.\\n         </p>\\n         <div class=\"highlight-sh notranslate\">\\n          <div class=\"highlight\">\\n           <pre><span></span>cat<span class=\"w\"> </span>gpt-j-offline-result/mlperf_log_summary.txt\\n</pre>\\n          </div>\\n         </div>\\n         <div class=\"highlight-default notranslate\">\\n          <div class=\"highlight\">\\n           <pre><span></span><span class=\"o\">================================================</span>\\n<span class=\"n\">MLPerf</span> <span class=\"n\">Results</span> <span class=\"n\">Summary</span>\\n<span class=\"o\">================================================</span>\\n<span class=\"n\">SUT</span> <span class=\"n\">name</span> <span class=\"p\">:</span> <span class=\"n\">GPT</span><span class=\"o\">-</span><span class=\"n\">J</span> <span class=\"n\">SUT</span>\\n<span class=\"n\">Scenario</span> <span class=\"p\">:</span> <span class=\"n\">Offline</span>\\n<span class=\"n\">Mode</span>     <span class=\"p\">:</span> <span class=\"n\">PerformanceOnly</span>\\n<span class=\"n\">Samples</span> <span class=\"n\">per</span> <span class=\"n\">second</span><span class=\"p\">:</span> <span class=\"mf\">11.842</span>\\n<span class=\"n\">Tokens</span> <span class=\"n\">per</span> <span class=\"n\">second</span> <span class=\"p\">(</span><span class=\"n\">inferred</span><span class=\"p\">):</span> <span class=\"mf\">817.095</span>\\n<span class=\"n\">Result</span> <span class=\"ow\">is</span> <span class=\"p\">:</span> <span class=\"n\">VALID</span>\\n  <span class=\"n\">Min</span> <span class=\"n\">duration</span> <span class=\"n\">satisfied</span> <span class=\"p\">:</span> <span class=\"n\">Yes</span>\\n  <span class=\"n\">Min</span> <span class=\"n\">queries</span> <span class=\"n\">satisfied</span> <span class=\"p\">:</span> <span class=\"n\">Yes</span>\\n  <span class=\"n\">Early</span> <span class=\"n\">stopping</span> <span class=\"n\">satisfied</span><span class=\"p\">:</span> <span class=\"n\">Yes</span>\\n</pre>\\n          </div>\\n         </div>\\n        </li>\\n       </ul>\\n      </section>\\n     </section>\\n     <section id=\"running-furiosa-mlperf-in-container-environment\">\\n      <h2>\\n       Running\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       in container environment\\n       <a class=\"headerlink\" href=\"#running-furiosa-mlperf-in-container-environment\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       FuriosaAI provides a containerized version of the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       command.\\nIf you use the containerized version, you can run the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       command\\nwithout installing the FuriosaAI Software Stack on your host system or\\nyou can run the command on Kubernetes environment.\\n      </p>\\n      <p>\\n       To run the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-mlperf\\n        </span>\\n       </code>\\n       container, you can use the following command:\\n      </p>\\n      <p>\\n       (Assumes model artifacts exist in\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         /opt/gpt-j-6b\\n        </span>\\n       </code>\\n       directory)\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>$<span class=\"w\"> </span>docker<span class=\"w\"> </span>run<span class=\"w\"> </span>-it<span class=\"w\"> </span>--rm<span class=\"w\"> </span>--privileged<span class=\"w\"> </span><span class=\"se\">\\\\</span>\\n<span class=\"w\">  </span>-v<span class=\"w\"> </span>/opt/gpt-j-6b:gpt-j-6b<span class=\"w\"> </span>furiosa-mlperf:2024.1.0<span class=\"w\"> </span>bash\\n\\n<span class=\"o\">(</span>container<span class=\"o\">)</span><span class=\"w\"> </span><span class=\"c1\"># furiosa-mlperf gpt-j-offline /gpt-j-6b /gpt-j-offline-result</span>\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       To run in a containerized environment, refer to the examples provided in this document.\\n      </p>\\n      <div class=\"admonition warning\">\\n       <p class=\"admonition-title\">\\n        Warning\\n       </p>\\n       <p>\\n        The example above uses the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          --privileged\\n         </span>\\n        </code>\\n        option for simplicity, but it is not recommended for security reasons.\\nIf you are using Kubernetes, please refer to the following page for the recommended method:\\n        <a class=\"reference internal\" href=\"../cloud_native_toolkit/intro.html#cloudnativetoolkit\">\\n         <span class=\"std std-ref\">\\n          Cloud Native Toolkit\\n         </span>\\n        </a>\\n       </p>\\n      </div>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"furiosa_llm.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Quick Start with Furiosa LLM\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../furiosa_llm/intro.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Furiosa LLM\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#installing-furiosa-mlperf-command\">\\n         Installing\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           furiosa-mlperf\\n          </span>\\n         </code>\\n         command\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#id1\">\\n         Running MLPerf Inference Benchmark\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#synopsis\">\\n           SYNOPSIS\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#examples\">\\n           Examples\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#running-furiosa-mlperf-in-container-environment\">\\n         Running\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           furiosa-mlperf\\n          </span>\\n         </code>\\n         in container environment\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='a3d94379-304a-4dbc-8300-39169378bfd5', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/furiosa-llm-serve.html'), name='furiosa-llm-serve', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/furiosa_llm/furiosa-llm-serve.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nOpenAI Compatible Server\\n========================\\n\\n\\nContents\\n--------\\n\\n\\n* [Preparing Chat Templates](#preparing-chat-templates)\\n* [Launching the Server](#launching-the-server)\\n  + [Arguments for the serve command](#arguments-for-the-serve-command)\\n* [Examples](#examples)\\n  + [LLaMA-3.1-70B with 4 RNGDs](#llama-3-1-70b-with-4-rngds)\\n  + [LLaMA-3.1-8B with Single RNGD](#llama-3-1-8b-with-single-rngd)\\n* [Using OpenAI Client](#using-openai-client)\\n* [The compatibility with OpenAI API](#the-compatibility-with-openai-api)\\n\\n\\n\\n\\n\\nOpenAI Compatible Server\\n[#](#openai-compatible-server \"Link to this heading\")\\n==============================================================================\\n\\nThe\\n`furiosa-llm`\\npackage includes an OpenAI-compatible server\\nthat can interact with OpenAI clients (and, of course, HTTP clients as well),\\nsupporting the\\n`/v1/chat/completions`\\nand\\n`/v1/completions`\\nAPIs.\\nIn this section, we will explain how to launch the OpenAI-compatible\\nfuriosa-llm\\n\\nserver.\\n\\nTip\\n\\nYou can learn more about the OpenAI API at\\n[Completions API](https://platform.openai.com/docs/api-reference/completions)\\nand\\n[Chat API](https://platform.openai.com/docs/api-reference/chat)\\n.\\n\\nTo launch the server, you must prepare: (1) the FuriosaAI LLM Engine artifact and\\n(2) a chat template for the model. To download the FuriosaAI LLM Engine artifact,\\nfollow the instructions provided through our distribution channels or contact our sales team.\\nTo prepare the chat template, follow the instructions in the following section.\\n\\nPreparing Chat Templates\\n[#](#preparing-chat-templates \"Link to this heading\")\\n------------------------------------------------------------------------------\\n\\nFuriosa SDK 2024.1.0 (alpha) uses Transformers v4.31.0, which does not include a chat template.\\nTherefore, to support\\n`/v1/chat/completions`\\n,\\nyou must provide a chat template yourself. This constraint will be removed in future releases.\\n\\nWarning\\n\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n\\nIf you have access to the Llama repositories on Hugging Face,\\nyou can obtain the chat template for Llama using the following commands:\\n\\n```\\n# Prerequisite: create a separate environment to install the latest Transformers version\\npip install \"transformers>=4.34.0\"\\npython - <<EOF\\nfrom transformers import AutoTokenizer\\ntok = AutoTokenizer.from_pretrained(\\'meta-llama/Meta-Llama-3.1-70B-Instruct\\')\\nwith open(\\'chat_template.tpl\\', \\'w\\') as f:\\n    f.write(tok.chat_template)\\nEOF\\n\\n```\\n\\n\\n\\nLaunching the Server\\n[#](#launching-the-server \"Link to this heading\")\\n----------------------------------------------------------------------\\n\\nYou can launch the server using the\\nfuriosa-llm serve\\n\\ncommand.\\n\\n### Arguments for the serve command [#](#arguments-for-the-serve-command \"Link to this heading\")\\n\\n```\\nusage: furiosa-llm serve [-h] --model {furiosa-ai/llama-3-1-70b,furiosa-ai/llama-3-1-8b,furiosa-ai/fake-llm} --artifact ARTIFACT [--host HOST] [--port PORT]\\n                     --chat-template CHAT_TEMPLATE [--response-role RESPONSE_ROLE] [-pp PIPELINE_PARALLEL_SIZE] [-tp TENSOR_PARALLEL_SIZE] [--devices DEVICES]\\n\\noptions:\\n-h, --help            show this help message and exit\\n--model {furiosa-ai/llama-3-1-70b,furiosa-ai/llama-3-1-8b,furiosa-ai/fake-llm}\\n                        The model to use. Currently only one model is supported per server.\\n--artifact ARTIFACT   Path to Furiosa LLM Engine artifact\\n--host HOST           Host to bind the server to\\n--port PORT           Port to bind the server to\\n--chat-template CHAT_TEMPLATE\\n                        Path to chat template file (must be a jinja2 template)\\n--response-role RESPONSE_ROLE\\n                        Response role for /v1/chat/completions API (default: \\'assistant\\')\\n-pp PIPELINE_PARALLEL_SIZE, --pipeline-parallel-size PIPELINE_PARALLEL_SIZE\\n                        Number of pipeline stages.\\n-tp TENSOR_PARALLEL_SIZE, --tensor-parallel-size TENSOR_PARALLEL_SIZE\\n                        Number of tensor parallel replicas.\\n--devices DEVICES     Devices to use (e.g. \"npu:0:*,npu:1:*\"). If unspecified, all available devices from the host will be used.\\n\\n```\\n\\n\\n\\n\\nExamples\\n[#](#examples \"Link to this heading\")\\n----------------------------------------------\\n\\n### LLaMA-3.1-70B with 4 RNGDs [#](#llama-3-1-70b-with-4-rngds \"Link to this heading\")\\n\\n```\\nfuriosa-llm serve \\\\\\n--model {path to mlperf-llama-3-1-fp8-pp4} \\\\\\n-tp 4 -pp 4 --devices \"npu:0:*,npu:1:*,npu:2:*,npu:3:*\" \\\\\\n--chat-template {path to chat template}\\n\\n```\\n\\n\\n\\n### LLaMA-3.1-8B with Single RNGD [#](#llama-3-1-8b-with-single-rngd \"Link to this heading\")\\n\\n```\\nfuriosa-llm serve \\\\\\n--model {path to mlperf-llama-3-1-8b-fp8} \\\\\\n-tp 4 -pp 1 --devices \"npu:0:*\" \\\\  # You may choose arbitrary device index, if multiple devices are on host\\n--chat-template {path to chat template}\\n\\n```\\n\\n\\n\\n\\nUsing OpenAI Client\\n[#](#using-openai-client \"Link to this heading\")\\n--------------------------------------------------------------------\\n\\nYou can use two APIs:\\n`client.chat.completions`\\nand\\n`client.completions`\\n.\\nYou can also set\\n`stream=True`\\nto receive a streaming response.\\n\\nTip\\n\\nYou can install the OpenAI Python client using the following command:\\n\\n```\\npip install openai\\n\\n```\\n\\n\\n\\n```\\nimport openai\\n\\nHOST = \"localhost:8000\"\\nopenai.api_base = f\"http://{HOST}/v1\"\\nopenai.api_key = \"0000\"\\n\\nstream_chat_completion = openai.ChatCompletion.create(\\n    model=\"\",\\n    messages=[\\n        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\\n        {\"role\": \"user\", \"content\": \"What is the largest animal in the world?\"},\\n    ],\\n    stream=True,\\n)\\n\\nfor completion in stream_chat_completion:\\n    content = completion.choices[0].delta.get(\"content\")\\n    if content:\\n        print(content, end=\"\")\\n\\n```\\n\\n\\n\\nThe compatibility with OpenAI API\\n[#](#the-compatibility-with-openai-api \"Link to this heading\")\\n------------------------------------------------------------------------------------------------\\n\\nCurrently,\\n`furiosa\\n\\nserve`\\nsupports the following OpenAI API parameters:\\nYou can find more about each parameter at\\n[Completions API](https://platform.openai.com/docs/api-reference/completions)\\nand\\n[Chat API](https://platform.openai.com/docs/api-reference/chat)\\n.\\n\\nWarning\\n\\nPlease note that using\\n`use_beam_search`\\nwith\\n`stream`\\nis not allowed\\nbecause the beam search cannot determine the tokens until the end of the sequence.\\n\\nIn 2024.1 release,\\n`n`\\nworks only for beam search and it will be fixed in the next release.\\n\\n* `n`\\n* `temperature`\\n* `top_p`\\n* `top_k`\\n* `early_stopping`\\n* `length_penalty`\\n* `max_tokens`\\n* `min_tokens`\\n* `use_beam_search`\\n* `best_of`\\n\\n\\n\\n[previous\\n\\nFuriosa LLM](intro.html \"previous page\")\\n[next\\n\\nReferences](references.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Preparing Chat Templates](#preparing-chat-templates)\\n* [Launching the Server](#launching-the-server)\\n  + [Arguments for the serve command](#arguments-for-the-serve-command)\\n* [Examples](#examples)\\n  + [LLaMA-3.1-70B with 4 RNGDs](#llama-3-1-70b-with-4-rngds)\\n  + [LLaMA-3.1-8B with Single RNGD](#llama-3-1-8b-with-single-rngd)\\n* [Using OpenAI Client](#using-openai-client)\\n* [The compatibility with OpenAI API](#the-compatibility-with-openai-api)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/furiosa_llm/furiosa-llm-serve.rst \"Download source file\") * .pdf\\nOpenAI Compatible Server ========================\\nContents --------\\n* [Preparing Chat Templates](#preparing-chat-templates) * [Launching the Server](#launching-the-server)   + [Arguments for the serve command](#arguments-for-the-serve-command) * [Examples](#examples)   + [LLaMA-3.1-70B with 4 RNGDs](#llama-3-1-70b-with-4-rngds)   + [LLaMA-3.1-8B with Single RNGD](#llama-3-1-8b-with-single-rngd) * [Using OpenAI Client](#using-openai-client) * [The compatibility with OpenAI API](#the-compatibility-with-openai-api)\\nOpenAI Compatible Server [#](#openai-compatible-server \"Link to this heading\") ==============================================================================\\nThe `furiosa-llm` package includes an OpenAI-compatible server that can interact with OpenAI clients (and, of course, HTTP clients as well), supporting the `/v1/chat/completions` and `/v1/completions` APIs. In this section, we will explain how to launch the OpenAI-compatible furiosa-llm\\nserver.\\nTip\\nYou can learn more about the OpenAI API at [Completions API](https://platform.openai.com/docs/api-reference/completions) and [Chat API](https://platform.openai.com/docs/api-reference/chat) .\\nTo launch the server, you must prepare: (1) the FuriosaAI LLM Engine artifact and (2) a chat template for the model. To download the FuriosaAI LLM Engine artifact, follow the instructions provided through our distribution channels or contact our sales team. To prepare the chat template, follow the instructions in the following section.\\nPreparing Chat Templates [#](#preparing-chat-templates \"Link to this heading\") ------------------------------------------------------------------------------\\nFuriosa SDK 2024.1.0 (alpha) uses Transformers v4.31.0, which does not include a chat template. Therefore, to support `/v1/chat/completions` , you must provide a chat template yourself. This constraint will be removed in future releases.\\nWarning\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version, and the features and APIs described in this document may change in the future.\\nIf you have access to the Llama repositories on Hugging Face, you can obtain the chat template for Llama using the following commands:\\n``` # Prerequisite: create a separate environment to install the latest Transformers version pip install \"transformers>=4.34.0\" python - <<EOF from transformers import AutoTokenizer tok = AutoTokenizer.from_pretrained(\\'meta-llama/Meta-Llama-3.1-70B-Instruct\\') with open(\\'chat_template.tpl\\', \\'w\\') as f:     f.write(tok.chat_template) EOF\\n```\\nLaunching the Server [#](#launching-the-server \"Link to this heading\") ----------------------------------------------------------------------\\nYou can launch the server using the furiosa-llm serve\\ncommand.\\n### Arguments for the serve command [#](#arguments-for-the-serve-command \"Link to this heading\")\\n``` usage: furiosa-llm serve [-h] --model {furiosa-ai/llama-3-1-70b,furiosa-ai/llama-3-1-8b,furiosa-ai/fake-llm} --artifact ARTIFACT [--host HOST] [--port PORT]                      --chat-template CHAT_TEMPLATE [--response-role RESPONSE_ROLE] [-pp PIPELINE_PARALLEL_SIZE] [-tp TENSOR_PARALLEL_SIZE] [--devices DEVICES]\\noptions: -h, --help            show this help message and exit --model {furiosa-ai/llama-3-1-70b,furiosa-ai/llama-3-1-8b,furiosa-ai/fake-llm}                         The model to use. Currently only one model is supported per server. --artifact ARTIFACT   Path to Furiosa LLM Engine artifact --host HOST           Host to bind the server to --port PORT           Port to bind the server to --chat-template CHAT_TEMPLATE                         Path to chat template file (must be a jinja2 template) --response-role RESPONSE_ROLE                         Response role for /v1/chat/completions API (default: \\'assistant\\') -pp PIPELINE_PARALLEL_SIZE, --pipeline-parallel-size PIPELINE_PARALLEL_SIZE                         Number of pipeline stages. -tp TENSOR_PARALLEL_SIZE, --tensor-parallel-size TENSOR_PARALLEL_SIZE                         Number of tensor parallel replicas. --devices DEVICES     Devices to use (e.g. \"npu:0:*,npu:1:*\"). If unspecified, all available devices from the host will be used.\\n```\\nExamples [#](#examples \"Link to this heading\") ----------------------------------------------\\n### LLaMA-3.1-70B with 4 RNGDs [#](#llama-3-1-70b-with-4-rngds \"Link to this heading\")\\n``` furiosa-llm serve \\\\ --model {path to mlperf-llama-3-1-fp8-pp4} \\\\ -tp 4 -pp 4 --devices \"npu:0:*,npu:1:*,npu:2:*,npu:3:*\" \\\\ --chat-template {path to chat template}\\n```\\n### LLaMA-3.1-8B with Single RNGD [#](#llama-3-1-8b-with-single-rngd \"Link to this heading\")\\n``` furiosa-llm serve \\\\ --model {path to mlperf-llama-3-1-8b-fp8} \\\\ -tp 4 -pp 1 --devices \"npu:0:*\" \\\\  # You may choose arbitrary device index, if multiple devices are on host --chat-template {path to chat template}\\n```\\nUsing OpenAI Client [#](#using-openai-client \"Link to this heading\") --------------------------------------------------------------------\\nYou can use two APIs: `client.chat.completions` and `client.completions` . You can also set `stream=True` to receive a streaming response.\\nTip\\nYou can install the OpenAI Python client using the following command:\\n``` pip install openai\\n```\\n``` import openai\\nHOST = \"localhost:8000\" openai.api_base = f\"http://{HOST}/v1\" openai.api_key = \"0000\"\\nstream_chat_completion = openai.ChatCompletion.create(     model=\"\",     messages=[         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},         {\"role\": \"user\", \"content\": \"What is the largest animal in the world?\"},     ],     stream=True, )\\nfor completion in stream_chat_completion:     content = completion.choices[0].delta.get(\"content\")     if content:         print(content, end=\"\")\\n```\\nThe compatibility with OpenAI API [#](#the-compatibility-with-openai-api \"Link to this heading\") ------------------------------------------------------------------------------------------------\\nCurrently, `furiosa\\nserve` supports the following OpenAI API parameters: You can find more about each parameter at [Completions API](https://platform.openai.com/docs/api-reference/completions) and [Chat API](https://platform.openai.com/docs/api-reference/chat) .\\nWarning\\nPlease note that using `use_beam_search` with `stream` is not allowed because the beam search cannot determine the tokens until the end of the sequence.\\nIn 2024.1 release, `n` works only for beam search and it will be fixed in the next release.\\n* `n` * `temperature` * `top_p` * `top_k` * `early_stopping` * `length_penalty` * `max_tokens` * `min_tokens` * `use_beam_search` * `best_of` \\n[previous\\nFuriosa LLM](intro.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nContents\\n* [Preparing Chat Templates](#preparing-chat-templates) * [Launching the Server](#launching-the-server)   + [Arguments for the serve command](#arguments-for-the-serve-command) * [Examples](#examples)   + [LLaMA-3.1-70B with 4 RNGDs](#llama-3-1-70b-with-4-rngds)   + [LLaMA-3.1-8B with Single RNGD](#llama-3-1-8b-with-single-rngd) * [Using OpenAI Client](#using-openai-client) * [The compatibility with OpenAI API](#the-compatibility-with-openai-api)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/furiosa_llm/furiosa-llm-serve.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     OpenAI Compatible Server\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#preparing-chat-templates\">\\n          Preparing Chat Templates\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#launching-the-server\">\\n          Launching the Server\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#arguments-for-the-serve-command\">\\n            Arguments for the serve command\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#examples\">\\n          Examples\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#llama-3-1-70b-with-4-rngds\">\\n            LLaMA-3.1-70B with 4 RNGDs\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#llama-3-1-8b-with-single-rngd\">\\n            LLaMA-3.1-8B with Single RNGD\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#using-openai-client\">\\n          Using OpenAI Client\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#the-compatibility-with-openai-api\">\\n          The compatibility with OpenAI API\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"openai-compatible-server\">\\n     <span id=\"openaiserver\">\\n     </span>\\n     <h1>\\n      OpenAI Compatible Server\\n      <a class=\"headerlink\" href=\"#openai-compatible-server\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      The\\n      <code class=\"docutils literal notranslate\">\\n       <span class=\"pre\">\\n        furiosa-llm\\n       </span>\\n      </code>\\n      package includes an OpenAI-compatible server\\nthat can interact with OpenAI clients (and, of course, HTTP clients as well),\\nsupporting the\\n      <code class=\"docutils literal notranslate\">\\n       <span class=\"pre\">\\n        /v1/chat/completions\\n       </span>\\n      </code>\\n      and\\n      <code class=\"docutils literal notranslate\">\\n       <span class=\"pre\">\\n        /v1/completions\\n       </span>\\n      </code>\\n      APIs.\\nIn this section, we will explain how to launch the OpenAI-compatible\\n      <cite>\\n       furiosa-llm\\n      </cite>\\n      server.\\n     </p>\\n     <div class=\"admonition tip\">\\n      <p class=\"admonition-title\">\\n       Tip\\n      </p>\\n      <p>\\n       You can learn more about the OpenAI API at\\n       <a class=\"reference external\" href=\"https://platform.openai.com/docs/api-reference/completions\">\\n        Completions API\\n       </a>\\n       and\\n       <a class=\"reference external\" href=\"https://platform.openai.com/docs/api-reference/chat\">\\n        Chat API\\n       </a>\\n       .\\n      </p>\\n     </div>\\n     <p>\\n      To launch the server, you must prepare: (1) the FuriosaAI LLM Engine artifact and\\n(2) a chat template for the model. To download the FuriosaAI LLM Engine artifact,\\nfollow the instructions provided through our distribution channels or contact our sales team.\\nTo prepare the chat template, follow the instructions in the following section.\\n     </p>\\n     <section id=\"preparing-chat-templates\">\\n      <h2>\\n       Preparing Chat Templates\\n       <a class=\"headerlink\" href=\"#preparing-chat-templates\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Furiosa SDK 2024.1.0 (alpha) uses Transformers v4.31.0, which does not include a chat template.\\nTherefore, to support\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         /v1/chat/completions\\n        </span>\\n       </code>\\n       ,\\nyou must provide a chat template yourself. This constraint will be removed in future releases.\\n      </p>\\n      <div class=\"admonition warning\">\\n       <p class=\"admonition-title\">\\n        Warning\\n       </p>\\n       <p>\\n        This document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n       </p>\\n      </div>\\n      <p>\\n       If you have access to the Llama repositories on Hugging Face,\\nyou can obtain the chat template for Llama using the following commands:\\n      </p>\\n      <div class=\"highlight-default notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span><span class=\"c1\"># Prerequisite: create a separate environment to install the latest Transformers version</span>\\n<span class=\"n\">pip</span> <span class=\"n\">install</span> <span class=\"s2\">\"transformers&gt;=4.34.0\"</span>\\n<span class=\"n\">python</span> <span class=\"o\">-</span> <span class=\"o\">&lt;&lt;</span><span class=\"n\">EOF</span>\\n<span class=\"kn\">from</span> <span class=\"nn\">transformers</span> <span class=\"kn\">import</span> <span class=\"n\">AutoTokenizer</span>\\n<span class=\"n\">tok</span> <span class=\"o\">=</span> <span class=\"n\">AutoTokenizer</span><span class=\"o\">.</span><span class=\"n\">from_pretrained</span><span class=\"p\">(</span><span class=\"s1\">\\'meta-llama/Meta-Llama-3.1-70B-Instruct\\'</span><span class=\"p\">)</span>\\n<span class=\"k\">with</span> <span class=\"nb\">open</span><span class=\"p\">(</span><span class=\"s1\">\\'chat_template.tpl\\'</span><span class=\"p\">,</span> <span class=\"s1\">\\'w\\'</span><span class=\"p\">)</span> <span class=\"k\">as</span> <span class=\"n\">f</span><span class=\"p\">:</span>\\n    <span class=\"n\">f</span><span class=\"o\">.</span><span class=\"n\">write</span><span class=\"p\">(</span><span class=\"n\">tok</span><span class=\"o\">.</span><span class=\"n\">chat_template</span><span class=\"p\">)</span>\\n<span class=\"n\">EOF</span>\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"launching-the-server\">\\n      <h2>\\n       Launching the Server\\n       <a class=\"headerlink\" href=\"#launching-the-server\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       You can launch the server using the\\n       <cite>\\n        furiosa-llm serve\\n       </cite>\\n       command.\\n      </p>\\n      <section id=\"arguments-for-the-serve-command\">\\n       <h3>\\n        Arguments for the serve command\\n        <a class=\"headerlink\" href=\"#arguments-for-the-serve-command\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <div class=\"highlight-default notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">usage</span><span class=\"p\">:</span> <span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">llm</span> <span class=\"n\">serve</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"n\">h</span><span class=\"p\">]</span> <span class=\"o\">--</span><span class=\"n\">model</span> <span class=\"p\">{</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">70</span><span class=\"n\">b</span><span class=\"p\">,</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">8</span><span class=\"n\">b</span><span class=\"p\">,</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">fake</span><span class=\"o\">-</span><span class=\"n\">llm</span><span class=\"p\">}</span> <span class=\"o\">--</span><span class=\"n\">artifact</span> <span class=\"n\">ARTIFACT</span> <span class=\"p\">[</span><span class=\"o\">--</span><span class=\"n\">host</span> <span class=\"n\">HOST</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"o\">--</span><span class=\"n\">port</span> <span class=\"n\">PORT</span><span class=\"p\">]</span>\\n                     <span class=\"o\">--</span><span class=\"n\">chat</span><span class=\"o\">-</span><span class=\"n\">template</span> <span class=\"n\">CHAT_TEMPLATE</span> <span class=\"p\">[</span><span class=\"o\">--</span><span class=\"n\">response</span><span class=\"o\">-</span><span class=\"n\">role</span> <span class=\"n\">RESPONSE_ROLE</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"n\">pp</span> <span class=\"n\">PIPELINE_PARALLEL_SIZE</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"o\">-</span><span class=\"n\">tp</span> <span class=\"n\">TENSOR_PARALLEL_SIZE</span><span class=\"p\">]</span> <span class=\"p\">[</span><span class=\"o\">--</span><span class=\"n\">devices</span> <span class=\"n\">DEVICES</span><span class=\"p\">]</span>\\n\\n<span class=\"n\">options</span><span class=\"p\">:</span>\\n<span class=\"o\">-</span><span class=\"n\">h</span><span class=\"p\">,</span> <span class=\"o\">--</span><span class=\"n\">help</span>            <span class=\"n\">show</span> <span class=\"n\">this</span> <span class=\"n\">help</span> <span class=\"n\">message</span> <span class=\"ow\">and</span> <span class=\"n\">exit</span>\\n<span class=\"o\">--</span><span class=\"n\">model</span> <span class=\"p\">{</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">70</span><span class=\"n\">b</span><span class=\"p\">,</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">8</span><span class=\"n\">b</span><span class=\"p\">,</span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">ai</span><span class=\"o\">/</span><span class=\"n\">fake</span><span class=\"o\">-</span><span class=\"n\">llm</span><span class=\"p\">}</span>\\n                        <span class=\"n\">The</span> <span class=\"n\">model</span> <span class=\"n\">to</span> <span class=\"n\">use</span><span class=\"o\">.</span> <span class=\"n\">Currently</span> <span class=\"n\">only</span> <span class=\"n\">one</span> <span class=\"n\">model</span> <span class=\"ow\">is</span> <span class=\"n\">supported</span> <span class=\"n\">per</span> <span class=\"n\">server</span><span class=\"o\">.</span>\\n<span class=\"o\">--</span><span class=\"n\">artifact</span> <span class=\"n\">ARTIFACT</span>   <span class=\"n\">Path</span> <span class=\"n\">to</span> <span class=\"n\">Furiosa</span> <span class=\"n\">LLM</span> <span class=\"n\">Engine</span> <span class=\"n\">artifact</span>\\n<span class=\"o\">--</span><span class=\"n\">host</span> <span class=\"n\">HOST</span>           <span class=\"n\">Host</span> <span class=\"n\">to</span> <span class=\"n\">bind</span> <span class=\"n\">the</span> <span class=\"n\">server</span> <span class=\"n\">to</span>\\n<span class=\"o\">--</span><span class=\"n\">port</span> <span class=\"n\">PORT</span>           <span class=\"n\">Port</span> <span class=\"n\">to</span> <span class=\"n\">bind</span> <span class=\"n\">the</span> <span class=\"n\">server</span> <span class=\"n\">to</span>\\n<span class=\"o\">--</span><span class=\"n\">chat</span><span class=\"o\">-</span><span class=\"n\">template</span> <span class=\"n\">CHAT_TEMPLATE</span>\\n                        <span class=\"n\">Path</span> <span class=\"n\">to</span> <span class=\"n\">chat</span> <span class=\"n\">template</span> <span class=\"n\">file</span> <span class=\"p\">(</span><span class=\"n\">must</span> <span class=\"n\">be</span> <span class=\"n\">a</span> <span class=\"n\">jinja2</span> <span class=\"n\">template</span><span class=\"p\">)</span>\\n<span class=\"o\">--</span><span class=\"n\">response</span><span class=\"o\">-</span><span class=\"n\">role</span> <span class=\"n\">RESPONSE_ROLE</span>\\n                        <span class=\"n\">Response</span> <span class=\"n\">role</span> <span class=\"k\">for</span> <span class=\"o\">/</span><span class=\"n\">v1</span><span class=\"o\">/</span><span class=\"n\">chat</span><span class=\"o\">/</span><span class=\"n\">completions</span> <span class=\"n\">API</span> <span class=\"p\">(</span><span class=\"n\">default</span><span class=\"p\">:</span> <span class=\"s1\">\\'assistant\\'</span><span class=\"p\">)</span>\\n<span class=\"o\">-</span><span class=\"n\">pp</span> <span class=\"n\">PIPELINE_PARALLEL_SIZE</span><span class=\"p\">,</span> <span class=\"o\">--</span><span class=\"n\">pipeline</span><span class=\"o\">-</span><span class=\"n\">parallel</span><span class=\"o\">-</span><span class=\"n\">size</span> <span class=\"n\">PIPELINE_PARALLEL_SIZE</span>\\n                        <span class=\"n\">Number</span> <span class=\"n\">of</span> <span class=\"n\">pipeline</span> <span class=\"n\">stages</span><span class=\"o\">.</span>\\n<span class=\"o\">-</span><span class=\"n\">tp</span> <span class=\"n\">TENSOR_PARALLEL_SIZE</span><span class=\"p\">,</span> <span class=\"o\">--</span><span class=\"n\">tensor</span><span class=\"o\">-</span><span class=\"n\">parallel</span><span class=\"o\">-</span><span class=\"n\">size</span> <span class=\"n\">TENSOR_PARALLEL_SIZE</span>\\n                        <span class=\"n\">Number</span> <span class=\"n\">of</span> <span class=\"n\">tensor</span> <span class=\"n\">parallel</span> <span class=\"n\">replicas</span><span class=\"o\">.</span>\\n<span class=\"o\">--</span><span class=\"n\">devices</span> <span class=\"n\">DEVICES</span>     <span class=\"n\">Devices</span> <span class=\"n\">to</span> <span class=\"n\">use</span> <span class=\"p\">(</span><span class=\"n\">e</span><span class=\"o\">.</span><span class=\"n\">g</span><span class=\"o\">.</span> <span class=\"s2\">\"npu:0:*,npu:1:*\"</span><span class=\"p\">)</span><span class=\"o\">.</span> <span class=\"n\">If</span> <span class=\"n\">unspecified</span><span class=\"p\">,</span> <span class=\"nb\">all</span> <span class=\"n\">available</span> <span class=\"n\">devices</span> <span class=\"kn\">from</span> <span class=\"nn\">the</span> <span class=\"n\">host</span> <span class=\"n\">will</span> <span class=\"n\">be</span> <span class=\"n\">used</span><span class=\"o\">.</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n     <section id=\"examples\">\\n      <h2>\\n       Examples\\n       <a class=\"headerlink\" href=\"#examples\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <section id=\"llama-3-1-70b-with-4-rngds\">\\n       <h3>\\n        LLaMA-3.1-70B with 4 RNGDs\\n        <a class=\"headerlink\" href=\"#llama-3-1-70b-with-4-rngds\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <div class=\"highlight-default notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">llm</span> <span class=\"n\">serve</span> \\\\\\n<span class=\"o\">--</span><span class=\"n\">model</span> <span class=\"p\">{</span><span class=\"n\">path</span> <span class=\"n\">to</span> <span class=\"n\">mlperf</span><span class=\"o\">-</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"n\">fp8</span><span class=\"o\">-</span><span class=\"n\">pp4</span><span class=\"p\">}</span> \\\\\\n<span class=\"o\">-</span><span class=\"n\">tp</span> <span class=\"mi\">4</span> <span class=\"o\">-</span><span class=\"n\">pp</span> <span class=\"mi\">4</span> <span class=\"o\">--</span><span class=\"n\">devices</span> <span class=\"s2\">\"npu:0:*,npu:1:*,npu:2:*,npu:3:*\"</span> \\\\\\n<span class=\"o\">--</span><span class=\"n\">chat</span><span class=\"o\">-</span><span class=\"n\">template</span> <span class=\"p\">{</span><span class=\"n\">path</span> <span class=\"n\">to</span> <span class=\"n\">chat</span> <span class=\"n\">template</span><span class=\"p\">}</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"llama-3-1-8b-with-single-rngd\">\\n       <h3>\\n        LLaMA-3.1-8B with Single RNGD\\n        <a class=\"headerlink\" href=\"#llama-3-1-8b-with-single-rngd\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <div class=\"highlight-default notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">furiosa</span><span class=\"o\">-</span><span class=\"n\">llm</span> <span class=\"n\">serve</span> \\\\\\n<span class=\"o\">--</span><span class=\"n\">model</span> <span class=\"p\">{</span><span class=\"n\">path</span> <span class=\"n\">to</span> <span class=\"n\">mlperf</span><span class=\"o\">-</span><span class=\"n\">llama</span><span class=\"o\">-</span><span class=\"mi\">3</span><span class=\"o\">-</span><span class=\"mi\">1</span><span class=\"o\">-</span><span class=\"mi\">8</span><span class=\"n\">b</span><span class=\"o\">-</span><span class=\"n\">fp8</span><span class=\"p\">}</span> \\\\\\n<span class=\"o\">-</span><span class=\"n\">tp</span> <span class=\"mi\">4</span> <span class=\"o\">-</span><span class=\"n\">pp</span> <span class=\"mi\">1</span> <span class=\"o\">--</span><span class=\"n\">devices</span> <span class=\"s2\">\"npu:0:*\"</span> \\\\  <span class=\"c1\"># You may choose arbitrary device index, if multiple devices are on host</span>\\n<span class=\"o\">--</span><span class=\"n\">chat</span><span class=\"o\">-</span><span class=\"n\">template</span> <span class=\"p\">{</span><span class=\"n\">path</span> <span class=\"n\">to</span> <span class=\"n\">chat</span> <span class=\"n\">template</span><span class=\"p\">}</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n     <section id=\"using-openai-client\">\\n      <h2>\\n       Using OpenAI Client\\n       <a class=\"headerlink\" href=\"#using-openai-client\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       You can use two APIs:\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         client.chat.completions\\n        </span>\\n       </code>\\n       and\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         client.completions\\n        </span>\\n       </code>\\n       .\\nYou can also set\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         stream=True\\n        </span>\\n       </code>\\n       to receive a streaming response.\\n      </p>\\n      <div class=\"admonition tip\">\\n       <p class=\"admonition-title\">\\n        Tip\\n       </p>\\n       <p>\\n        You can install the OpenAI Python client using the following command:\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>pip<span class=\"w\"> </span>install<span class=\"w\"> </span>openai\\n</pre>\\n        </div>\\n       </div>\\n      </div>\\n      <div class=\"highlight-default notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span><span class=\"kn\">import</span> <span class=\"nn\">openai</span>\\n\\n<span class=\"n\">HOST</span> <span class=\"o\">=</span> <span class=\"s2\">\"localhost:8000\"</span>\\n<span class=\"n\">openai</span><span class=\"o\">.</span><span class=\"n\">api_base</span> <span class=\"o\">=</span> <span class=\"sa\">f</span><span class=\"s2\">\"http://</span><span class=\"si\">{</span><span class=\"n\">HOST</span><span class=\"si\">}</span><span class=\"s2\">/v1\"</span>\\n<span class=\"n\">openai</span><span class=\"o\">.</span><span class=\"n\">api_key</span> <span class=\"o\">=</span> <span class=\"s2\">\"0000\"</span>\\n\\n<span class=\"n\">stream_chat_completion</span> <span class=\"o\">=</span> <span class=\"n\">openai</span><span class=\"o\">.</span><span class=\"n\">ChatCompletion</span><span class=\"o\">.</span><span class=\"n\">create</span><span class=\"p\">(</span>\\n    <span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s2\">\"\"</span><span class=\"p\">,</span>\\n    <span class=\"n\">messages</span><span class=\"o\">=</span><span class=\"p\">[</span>\\n        <span class=\"p\">{</span><span class=\"s2\">\"role\"</span><span class=\"p\">:</span> <span class=\"s2\">\"system\"</span><span class=\"p\">,</span> <span class=\"s2\">\"content\"</span><span class=\"p\">:</span> <span class=\"s2\">\"You are a helpful assistant.\"</span><span class=\"p\">},</span>\\n        <span class=\"p\">{</span><span class=\"s2\">\"role\"</span><span class=\"p\">:</span> <span class=\"s2\">\"user\"</span><span class=\"p\">,</span> <span class=\"s2\">\"content\"</span><span class=\"p\">:</span> <span class=\"s2\">\"What is the largest animal in the world?\"</span><span class=\"p\">},</span>\\n    <span class=\"p\">],</span>\\n    <span class=\"n\">stream</span><span class=\"o\">=</span><span class=\"kc\">True</span><span class=\"p\">,</span>\\n<span class=\"p\">)</span>\\n\\n<span class=\"k\">for</span> <span class=\"n\">completion</span> <span class=\"ow\">in</span> <span class=\"n\">stream_chat_completion</span><span class=\"p\">:</span>\\n    <span class=\"n\">content</span> <span class=\"o\">=</span> <span class=\"n\">completion</span><span class=\"o\">.</span><span class=\"n\">choices</span><span class=\"p\">[</span><span class=\"mi\">0</span><span class=\"p\">]</span><span class=\"o\">.</span><span class=\"n\">delta</span><span class=\"o\">.</span><span class=\"n\">get</span><span class=\"p\">(</span><span class=\"s2\">\"content\"</span><span class=\"p\">)</span>\\n    <span class=\"k\">if</span> <span class=\"n\">content</span><span class=\"p\">:</span>\\n        <span class=\"nb\">print</span><span class=\"p\">(</span><span class=\"n\">content</span><span class=\"p\">,</span> <span class=\"n\">end</span><span class=\"o\">=</span><span class=\"s2\">\"\"</span><span class=\"p\">)</span>\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"the-compatibility-with-openai-api\">\\n      <h2>\\n       The compatibility with OpenAI API\\n       <a class=\"headerlink\" href=\"#the-compatibility-with-openai-api\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Currently,\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa\\n        </span>\\n        <span class=\"pre\">\\n         serve\\n        </span>\\n       </code>\\n       supports the following OpenAI API parameters:\\nYou can find more about each parameter at\\n       <a class=\"reference external\" href=\"https://platform.openai.com/docs/api-reference/completions\">\\n        Completions API\\n       </a>\\n       and\\n       <a class=\"reference external\" href=\"https://platform.openai.com/docs/api-reference/chat\">\\n        Chat API\\n       </a>\\n       .\\n      </p>\\n      <div class=\"admonition warning\">\\n       <p class=\"admonition-title\">\\n        Warning\\n       </p>\\n       <p>\\n        Please note that using\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          use_beam_search\\n         </span>\\n        </code>\\n        with\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          stream\\n         </span>\\n        </code>\\n        is not allowed\\nbecause the beam search cannot determine the tokens until the end of the sequence.\\n       </p>\\n       <p>\\n        In 2024.1 release,\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          n\\n         </span>\\n        </code>\\n        works only for beam search and it will be fixed in the next release.\\n       </p>\\n      </div>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           n\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           temperature\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           top_p\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           top_k\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           early_stopping\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           length_penalty\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           max_tokens\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           min_tokens\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           use_beam_search\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           best_of\\n          </span>\\n         </code>\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"intro.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Furiosa LLM\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"references.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        References\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#preparing-chat-templates\">\\n         Preparing Chat Templates\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#launching-the-server\">\\n         Launching the Server\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#arguments-for-the-serve-command\">\\n           Arguments for the serve command\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#examples\">\\n         Examples\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#llama-3-1-70b-with-4-rngds\">\\n           LLaMA-3.1-70B with 4 RNGDs\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#llama-3-1-8b-with-single-rngd\">\\n           LLaMA-3.1-8B with Single RNGD\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#using-openai-client\">\\n         Using OpenAI Client\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#the-compatibility-with-openai-api\">\\n         The compatibility with OpenAI API\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='13853744-dc18-4c98-b1c2-4f5806b28514', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/'), name='', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](_sources/index.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFuriosaAI Developer Center\\n==========================\\n\\n\\nContents\\n--------\\n\\n\\n* [Overview](#overview)\\n* [Getting Started](#getting-started)\\n* [Cloud Native Toolkit](#cloud-native-toolkit)\\n* [Device Management](#device-management)\\n* [Customer Support](#customer-support)\\n\\n\\n\\n\\n\\nFuriosaAI Developer Center\\n[#](#furiosaai-developer-center \"Link to this heading\")\\n==================================================================================\\n\\nWelcome to the FuriosaAI Developer Center.\\nFuriosaAI provides an streamlined software stack for deep learning model inference on FuriosaAI NPUs.\\nThis document provides a guide to easily perform the entire workflow of writing inference applications,\\nfrom starting with PyTorch model to model quantization, serving, and production deployment.\\n\\nWarning\\n\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n\\n\\nOverview\\n[#](#overview \"Link to this heading\")\\n----------------------------------------------\\n\\n* [FuriosaAI RNGD](overview/rngd.html#rngd)\\n  : RNGD Hardware Specification, and features\\n* [FuriosaAI’s Software Stack](overview/software_stack.html#softwarestack)\\n  : An overview of the FuriosaAI software stack\\n* [Supported Models](overview/supported_models.html#supportedmodels)\\n  : A list of supported models\\n* [What’s New](whatsnew/index.html#whatsnew)\\n  : New features and changes in the latest release\\n* [Roadmap](overview/roadmap.html#roadmap)\\n  : The future roadmap of FuriosaAI Software Stack\\n\\nGetting Started\\n[#](#getting-started \"Link to this heading\")\\n------------------------------------------------------------\\n\\n* [Installing Prerequisites](getting_started/prerequisites.html#installingprerequisites)\\n  : How to install the prerequisites for FuriosaAI Software Stack\\n* [Quick Start with Furiosa LLM](getting_started/furiosa_llm.html#gettingstartedfuriosallm)\\n* [Running MLPerf™ Inference Benchmark](getting_started/furiosa_mlperf.html#gettingstartedfuriosamlperf)\\n\\nCloud Native Toolkit\\n[#](#cloud-native-toolkit \"Link to this heading\")\\n----------------------------------------------------------------------\\n\\n* [Cloud Native Toolkit](cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n  : An overview of the Cloud Native Toolkit\\n* [Kubernetes Support](cloud_native_toolkit/kubernetes.html#kubernetes)\\n  : An overview of the Kubernetes Support\\n\\nDevice Management\\n[#](#device-management \"Link to this heading\")\\n----------------------------------------------------------------\\n\\n* [furiosa-smi](device_management/furiosa_smi.html#furiosasmi)\\n  : A command line utility for managing FuriosaAI NPUs\\n\\nCustomer Support\\n[#](#customer-support \"Link to this heading\")\\n--------------------------------------------------------------\\n\\n* [FuriosaAI Homepage](https://furiosa.ai)\\n* [FuriosaAI Forum](https://furiosa-ai.discourse.group/)\\n* [FuriosaAI Customer Portal](https://furiosa-ai.atlassian.net/servicedesk/customer/portals/)\\n* [FuriosaAI Warboy SDK Document](https://furiosa-ai.github.io/docs/latest/en/)\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[next\\n\\nFuriosaAI RNGD](overview/rngd.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Overview](#overview)\\n* [Getting Started](#getting-started)\\n* [Cloud Native Toolkit](#cloud-native-toolkit)\\n* [Device Management](#device-management)\\n* [Customer Support](#customer-support)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](_sources/index.rst \"Download source file\") * .pdf\\nFuriosaAI Developer Center ==========================\\nContents --------\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nFuriosaAI Developer Center [#](#furiosaai-developer-center \"Link to this heading\") ==================================================================================\\nWelcome to the FuriosaAI Developer Center. FuriosaAI provides an streamlined software stack for deep learning model inference on FuriosaAI NPUs. This document provides a guide to easily perform the entire workflow of writing inference applications, from starting with PyTorch model to model quantization, serving, and production deployment.\\nWarning\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version, and the features and APIs described in this document may change in the future.\\nOverview [#](#overview \"Link to this heading\") ----------------------------------------------\\n* [FuriosaAI RNGD](overview/rngd.html#rngd)   : RNGD Hardware Specification, and features * [FuriosaAI’s Software Stack](overview/software_stack.html#softwarestack)   : An overview of the FuriosaAI software stack * [Supported Models](overview/supported_models.html#supportedmodels)   : A list of supported models * [What’s New](whatsnew/index.html#whatsnew)   : New features and changes in the latest release * [Roadmap](overview/roadmap.html#roadmap)   : The future roadmap of FuriosaAI Software Stack\\nGetting Started [#](#getting-started \"Link to this heading\") ------------------------------------------------------------\\n* [Installing Prerequisites](getting_started/prerequisites.html#installingprerequisites)   : How to install the prerequisites for FuriosaAI Software Stack * [Quick Start with Furiosa LLM](getting_started/furiosa_llm.html#gettingstartedfuriosallm) * [Running MLPerf™ Inference Benchmark](getting_started/furiosa_mlperf.html#gettingstartedfuriosamlperf)\\nCloud Native Toolkit [#](#cloud-native-toolkit \"Link to this heading\") ----------------------------------------------------------------------\\n* [Cloud Native Toolkit](cloud_native_toolkit/intro.html#cloudnativetoolkit)   : An overview of the Cloud Native Toolkit * [Kubernetes Support](cloud_native_toolkit/kubernetes.html#kubernetes)   : An overview of the Kubernetes Support\\nDevice Management [#](#device-management \"Link to this heading\") ----------------------------------------------------------------\\n* [furiosa-smi](device_management/furiosa_smi.html#furiosasmi)   : A command line utility for managing FuriosaAI NPUs\\nCustomer Support [#](#customer-support \"Link to this heading\") --------------------------------------------------------------\\n* [FuriosaAI Homepage](https://furiosa.ai) * [FuriosaAI Forum](https://furiosa-ai.discourse.group/) * [FuriosaAI Customer Portal](https://furiosa-ai.atlassian.net/servicedesk/customer/portals/) * [FuriosaAI Warboy SDK Document](https://furiosa-ai.github.io/docs/latest/en/)\\n[next\\nFuriosaAI RNGD](overview/rngd.html \"next page\")\\nContents\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"_sources/index.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     FuriosaAI Developer Center\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#overview\">\\n          Overview\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#getting-started\">\\n          Getting Started\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#cloud-native-toolkit\">\\n          Cloud Native Toolkit\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#device-management\">\\n          Device Management\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#customer-support\">\\n          Customer Support\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"furiosaai-developer-center\">\\n     <h1>\\n      FuriosaAI Developer Center\\n      <a class=\"headerlink\" href=\"#furiosaai-developer-center\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      Welcome to the FuriosaAI Developer Center.\\nFuriosaAI provides an streamlined software stack for deep learning model inference on FuriosaAI NPUs.\\nThis document provides a guide to easily perform the entire workflow of writing inference applications,\\nfrom starting with PyTorch model to model quantization, serving, and production deployment.\\n     </p>\\n     <div class=\"admonition warning\">\\n      <p class=\"admonition-title\">\\n       Warning\\n      </p>\\n      <p>\\n       This document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n      </p>\\n     </div>\\n     <section id=\"overview\">\\n      <h2>\\n       Overview\\n       <a class=\"headerlink\" href=\"#overview\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"overview/rngd.html#rngd\">\\n          <span class=\"std std-ref\">\\n           FuriosaAI RNGD\\n          </span>\\n         </a>\\n         : RNGD Hardware Specification, and features\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"overview/software_stack.html#softwarestack\">\\n          <span class=\"std std-ref\">\\n           FuriosaAI’s Software Stack\\n          </span>\\n         </a>\\n         : An overview of the FuriosaAI software stack\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"overview/supported_models.html#supportedmodels\">\\n          <span class=\"std std-ref\">\\n           Supported Models\\n          </span>\\n         </a>\\n         : A list of supported models\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"whatsnew/index.html#whatsnew\">\\n          <span class=\"std std-ref\">\\n           What’s New\\n          </span>\\n         </a>\\n         : New features and changes in the latest release\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"overview/roadmap.html#roadmap\">\\n          <span class=\"std std-ref\">\\n           Roadmap\\n          </span>\\n         </a>\\n         : The future roadmap of FuriosaAI Software Stack\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"getting-started\">\\n      <h2>\\n       Getting Started\\n       <a class=\"headerlink\" href=\"#getting-started\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"getting_started/prerequisites.html#installingprerequisites\">\\n          <span class=\"std std-ref\">\\n           Installing Prerequisites\\n          </span>\\n         </a>\\n         : How to install the prerequisites for FuriosaAI Software Stack\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"getting_started/furiosa_llm.html#gettingstartedfuriosallm\">\\n          <span class=\"std std-ref\">\\n           Quick Start with Furiosa LLM\\n          </span>\\n         </a>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"getting_started/furiosa_mlperf.html#gettingstartedfuriosamlperf\">\\n          <span class=\"std std-ref\">\\n           Running MLPerf™ Inference Benchmark\\n          </span>\\n         </a>\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"cloud-native-toolkit\">\\n      <h2>\\n       Cloud Native Toolkit\\n       <a class=\"headerlink\" href=\"#cloud-native-toolkit\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"cloud_native_toolkit/intro.html#cloudnativetoolkit\">\\n          <span class=\"std std-ref\">\\n           Cloud Native Toolkit\\n          </span>\\n         </a>\\n         : An overview of the Cloud Native Toolkit\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"cloud_native_toolkit/kubernetes.html#kubernetes\">\\n          <span class=\"std std-ref\">\\n           Kubernetes Support\\n          </span>\\n         </a>\\n         : An overview of the Kubernetes Support\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"device-management\">\\n      <h2>\\n       Device Management\\n       <a class=\"headerlink\" href=\"#device-management\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"device_management/furiosa_smi.html#furiosasmi\">\\n          <span class=\"std std-ref\">\\n           furiosa-smi\\n          </span>\\n         </a>\\n         : A command line utility for managing FuriosaAI NPUs\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"customer-support\">\\n      <h2>\\n       Customer Support\\n       <a class=\"headerlink\" href=\"#customer-support\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         <a class=\"reference external\" href=\"https://furiosa.ai\">\\n          FuriosaAI Homepage\\n         </a>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference external\" href=\"https://furiosa-ai.discourse.group/\">\\n          FuriosaAI Forum\\n         </a>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference external\" href=\"https://furiosa-ai.atlassian.net/servicedesk/customer/portals/\">\\n          FuriosaAI Customer Portal\\n         </a>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference external\" href=\"https://furiosa-ai.github.io/docs/latest/en/\">\\n          FuriosaAI Warboy SDK Document\\n         </a>\\n        </p>\\n       </li>\\n      </ul>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n      <div class=\"toctree-wrapper compound\">\\n      </div>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"right-next\" href=\"overview/rngd.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        FuriosaAI RNGD\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#overview\">\\n         Overview\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#getting-started\">\\n         Getting Started\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#cloud-native-toolkit\">\\n         Cloud Native Toolkit\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#device-management\">\\n         Device Management\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#customer-support\">\\n         Customer Support\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='2b294227-f255-492c-b642-46e100e59705', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/kubernetes.html'), name='kubernetes', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/cloud_native_toolkit/kubernetes.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nKubernetes Support\\n==================\\n\\n\\n\\n\\n\\nKubernetes Support\\n[#](#kubernetes-support \"Link to this heading\")\\n==================================================================\\n\\nWe do support the following versions of Kubernetes and CRI runtime:\\n\\n* Kubernetes: v1.24.0 or later\\n* helm v3.0.0 or later\\n* CRI Runtime:\\n  [containerd](https://github.com/containerd/containerd)\\n  or\\n  [CRI-O](https://github.com/cri-o/cri-o)\\n\\nNote\\n\\nDocker is officially deprecated as a container runtime in Kubernetes.\\nIt is recommended to use containerd or CRI-O as a container runtime.\\nOtherwise you may face unexpected issues with the device plugin.\\nFor more information, see\\n[here](https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/)\\n.\\n\\n\\nKubernetes Support\\n\\n\\n* [Installing Furiosa Feature Discovery](kubernetes/feature_discovery.html)\\n* [Installing Furiosa Device Plugin](kubernetes/device_plugin.html)\\n* [Installing Furiosa Metrics Exporter](kubernetes/metrics_exporter.html)\\n* [Scheduling NPUs](kubernetes/scheduling_npus.html)\\n\\n\\n\\n[previous\\n\\nCloud Native Toolkit](intro.html \"previous page\")\\n[next\\n\\nInstalling Furiosa Feature Discovery](kubernetes/feature_discovery.html \"next page\")\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/cloud_native_toolkit/kubernetes.rst \"Download source file\") * .pdf\\nKubernetes Support ==================\\nKubernetes Support [#](#kubernetes-support \"Link to this heading\") ==================================================================\\nWe do support the following versions of Kubernetes and CRI runtime:\\n* Kubernetes: v1.24.0 or later * helm v3.0.0 or later * CRI Runtime:   [containerd](https://github.com/containerd/containerd)   or   [CRI-O](https://github.com/cri-o/cri-o)\\nNote\\nDocker is officially deprecated as a container runtime in Kubernetes. It is recommended to use containerd or CRI-O as a container runtime. Otherwise you may face unexpected issues with the device plugin. For more information, see [here](https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/) .\\nKubernetes Support\\n* [Installing Furiosa Feature Discovery](kubernetes/feature_discovery.html) * [Installing Furiosa Device Plugin](kubernetes/device_plugin.html) * [Installing Furiosa Metrics Exporter](kubernetes/metrics_exporter.html) * [Scheduling NPUs](kubernetes/scheduling_npus.html)\\n[previous\\nCloud Native Toolkit](intro.html \"previous page\") [next\\nInstalling Furiosa Feature Discovery](kubernetes/feature_discovery.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/cloud_native_toolkit/kubernetes.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Kubernetes Support\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"kubernetes-support\">\\n     <span id=\"kubernetes\">\\n     </span>\\n     <h1>\\n      Kubernetes Support\\n      <a class=\"headerlink\" href=\"#kubernetes-support\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      We do support the following versions of Kubernetes and CRI runtime:\\n     </p>\\n     <ul class=\"simple\">\\n      <li>\\n       <p>\\n        Kubernetes: v1.24.0 or later\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        helm v3.0.0 or later\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        CRI Runtime:\\n        <a class=\"reference external\" href=\"https://github.com/containerd/containerd\">\\n         containerd\\n        </a>\\n        or\\n        <a class=\"reference external\" href=\"https://github.com/cri-o/cri-o\">\\n         CRI-O\\n        </a>\\n       </p>\\n      </li>\\n     </ul>\\n     <div class=\"admonition note\">\\n      <p class=\"admonition-title\">\\n       Note\\n      </p>\\n      <p>\\n       Docker is officially deprecated as a container runtime in Kubernetes.\\nIt is recommended to use containerd or CRI-O as a container runtime.\\nOtherwise you may face unexpected issues with the device plugin.\\nFor more information, see\\n       <a class=\"reference external\" href=\"https://kubernetes.io/blog/2020/12/02/dont-panic-kubernetes-and-docker/\">\\n        here\\n       </a>\\n       .\\n      </p>\\n     </div>\\n     <div class=\"toctree-wrapper compound\">\\n      <p aria-level=\"2\" class=\"caption\" role=\"heading\">\\n       <span class=\"caption-text\">\\n        Kubernetes Support\\n       </span>\\n      </p>\\n      <ul>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"kubernetes/feature_discovery.html\">\\n         Installing Furiosa Feature Discovery\\n        </a>\\n       </li>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"kubernetes/device_plugin.html\">\\n         Installing Furiosa Device Plugin\\n        </a>\\n       </li>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"kubernetes/metrics_exporter.html\">\\n         Installing Furiosa Metrics Exporter\\n        </a>\\n       </li>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"kubernetes/scheduling_npus.html\">\\n         Scheduling NPUs\\n        </a>\\n       </li>\\n      </ul>\\n     </div>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"intro.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Cloud Native Toolkit\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"kubernetes/feature_discovery.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Feature Discovery\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='d4927eaf-a1a0-40bd-9624-79db4213c5fc', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/roadmap.html'), name='roadmap', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/overview/roadmap.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nRoadmap\\n=======\\n\\n\\nContents\\n--------\\n\\n\\n* [Latest Recent Release](#latest-recent-release)\\n* [Future Releases](#future-releases)\\n  + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)\\n  + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\n\\n\\n\\n\\n\\nRoadmap\\n[#](#roadmap \"Link to this heading\")\\n============================================\\n\\nFurisaAI strives to deliver the releases for each month, while offering patch releases.\\nThis page shows the forward-looking roadmap of ongoing & upcoming projects\\nand when they are expected to land, broken down by areas on\\n[our software stack](software_stack.html#softwarestack)\\n.\\n\\nLatest Recent Release\\n[#](#latest-recent-release \"Link to this heading\")\\n------------------------------------------------------------------------\\n\\nThe latest release is 2024.1.0 (alpha) on October 11, 2024.\\nYou can find the release notes\\n[here](../whatsnew/index.html#whatsnew)\\n.\\n\\n\\nFuture Releases\\n[#](#future-releases \"Link to this heading\")\\n------------------------------------------------------------\\n\\nNote\\n\\nThe roadmap is subject to change and may not reflect the final product.\\n\\n\\n### 2024.2.0 (beta 0) - November, 2024 [#](#beta-0-november-2024 \"Link to this heading\")\\n\\n* Model support:\\n  \\n  + Language Models: CodeLLaaMA2, Vicuna, Solar, EXAONE-3.0\\n  + Vision Models: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, ..\\n* (Furiosa LLM) Tensor Parallelism support Phase 1: Intra-chip\\n* Torch 2.4.1 support\\n* CPU memory swapping in Furiosa LLM\\n\\n### 2024.3.0 (beta 1) - December, 2024 [#](#beta-1-december-2024 \"Link to this heading\")\\n\\n* Model support: TBD\\n* (Furiosa LLM) Tensor Parallelism support Phase 2: Inter-chip\\n* `torch.compile()`\\n  backend\\n* Huggingface Optimum integration\\n\\n\\n\\n\\n[previous\\n\\nWhat’s New](../whatsnew/index.html \"previous page\")\\n[next\\n\\nInstalling Prerequisites](../getting_started/prerequisites.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Latest Recent Release](#latest-recent-release)\\n* [Future Releases](#future-releases)\\n  + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)\\n  + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/overview/roadmap.rst \"Download source file\") * .pdf\\nRoadmap =======\\nContents --------\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nRoadmap [#](#roadmap \"Link to this heading\") ============================================\\nFurisaAI strives to deliver the releases for each month, while offering patch releases. This page shows the forward-looking roadmap of ongoing & upcoming projects and when they are expected to land, broken down by areas on [our software stack](software_stack.html#softwarestack) .\\nLatest Recent Release [#](#latest-recent-release \"Link to this heading\") ------------------------------------------------------------------------\\nThe latest release is 2024.1.0 (alpha) on October 11, 2024. You can find the release notes [here](../whatsnew/index.html#whatsnew) .\\nFuture Releases [#](#future-releases \"Link to this heading\") ------------------------------------------------------------\\nNote\\nThe roadmap is subject to change and may not reflect the final product.\\n### 2024.2.0 (beta 0) - November, 2024 [#](#beta-0-november-2024 \"Link to this heading\")\\n* Model support:      + Language Models: CodeLLaaMA2, Vicuna, Solar, EXAONE-3.0   + Vision Models: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, .. * (Furiosa LLM) Tensor Parallelism support Phase 1: Intra-chip * Torch 2.4.1 support * CPU memory swapping in Furiosa LLM\\n### 2024.3.0 (beta 1) - December, 2024 [#](#beta-1-december-2024 \"Link to this heading\")\\n* Model support: TBD * (Furiosa LLM) Tensor Parallelism support Phase 2: Inter-chip * `torch.compile()`   backend * Huggingface Optimum integration\\n[previous\\nWhat’s New](../whatsnew/index.html \"previous page\") [next\\nInstalling Prerequisites](../getting_started/prerequisites.html \"next page\")\\nContents\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/overview/roadmap.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Roadmap\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#latest-recent-release\">\\n          Latest Recent Release\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#future-releases\">\\n          Future Releases\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#beta-0-november-2024\">\\n            2024.2.0 (beta 0) - November, 2024\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#beta-1-december-2024\">\\n            2024.3.0 (beta 1) - December, 2024\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"roadmap\">\\n     <span id=\"id1\">\\n     </span>\\n     <h1>\\n      Roadmap\\n      <a class=\"headerlink\" href=\"#roadmap\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      FurisaAI strives to deliver the releases for each month, while offering patch releases.\\nThis page shows the forward-looking roadmap of ongoing &amp; upcoming projects\\nand when they are expected to land, broken down by areas on\\n      <a class=\"reference internal\" href=\"software_stack.html#softwarestack\">\\n       <span class=\"std std-ref\">\\n        our software stack\\n       </span>\\n      </a>\\n      .\\n     </p>\\n     <section id=\"latest-recent-release\">\\n      <h2>\\n       Latest Recent Release\\n       <a class=\"headerlink\" href=\"#latest-recent-release\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The latest release is 2024.1.0 (alpha) on October 11, 2024.\\nYou can find the release notes\\n       <a class=\"reference internal\" href=\"../whatsnew/index.html#whatsnew\">\\n        <span class=\"std std-ref\">\\n         here\\n        </span>\\n       </a>\\n       .\\n      </p>\\n     </section>\\n     <section id=\"future-releases\">\\n      <h2>\\n       Future Releases\\n       <a class=\"headerlink\" href=\"#future-releases\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <div class=\"admonition note\">\\n       <p class=\"admonition-title\">\\n        Note\\n       </p>\\n       <p>\\n        The roadmap is subject to change and may not reflect the final product.\\n       </p>\\n      </div>\\n      <section id=\"beta-0-november-2024\">\\n       <h3>\\n        2024.2.0 (beta 0) - November, 2024\\n        <a class=\"headerlink\" href=\"#beta-0-november-2024\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <ul class=\"simple\">\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           Model support:\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              Language Models: CodeLLaaMA2, Vicuna, Solar, EXAONE-3.0\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              Vision Models: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, ..\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n        <li>\\n         <p>\\n          (Furiosa LLM) Tensor Parallelism support Phase 1: Intra-chip\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          Torch 2.4.1 support\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          CPU memory swapping in Furiosa LLM\\n         </p>\\n        </li>\\n       </ul>\\n      </section>\\n      <section id=\"beta-1-december-2024\">\\n       <h3>\\n        2024.3.0 (beta 1) - December, 2024\\n        <a class=\"headerlink\" href=\"#beta-1-december-2024\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <ul class=\"simple\">\\n        <li>\\n         <p>\\n          Model support: TBD\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          (Furiosa LLM) Tensor Parallelism support Phase 2: Inter-chip\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            torch.compile()\\n           </span>\\n          </code>\\n          backend\\n         </p>\\n        </li>\\n        <li>\\n         <p>\\n          Huggingface Optimum integration\\n         </p>\\n        </li>\\n       </ul>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../whatsnew/index.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        What’s New\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../getting_started/prerequisites.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Prerequisites\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#latest-recent-release\">\\n         Latest Recent Release\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#future-releases\">\\n         Future Releases\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#beta-0-november-2024\">\\n           2024.2.0 (beta 0) - November, 2024\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#beta-1-december-2024\">\\n           2024.3.0 (beta 1) - December, 2024\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='4f19d9ef-0eb7-40bf-a693-6e2d80ddb54a', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/supported_models.html'), name='supported_models', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/overview/supported_models.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSupported Models\\n================\\n\\n\\nContents\\n--------\\n\\n\\n* [Decoder-only Models](#decoder-only-models)\\n* [Encoder-only Models](#encoder-only-models)\\n\\n\\n\\n\\n\\nSupported Models\\n[#](#supported-models \"Link to this heading\")\\n==============================================================\\n\\nFuriosaAI Software Stack supports a variety of Transformer-based models in HuggingFace Hub.\\nThe following is the list of model architectures that are currently supported by Furiosa SDK.\\nIf your model is based on the following architectures,\\nyou can use Furiosa SDK to compile, quantize, and run the model on FuriosaAI RNGD.\\n\\nDecoder-only Models\\n[#](#decoder-only-models \"Link to this heading\")\\n--------------------------------------------------------------------\\n\\nThe following models are supported for decoding only:\\n\\n\\nDecoder-only Models\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n\\n| Architecture | Model Name | Example HuggingFace Models |\\n| --- | --- | --- |\\n| `LlamaForCausalLM` | Llama 2, Llama 3.1 | `meta-llama/Llama-2-70b-hf` , `meta-llama/Meta-Llama-3.1-70B` , `meta-llama/Meta-Llama-3-70B-Instruct` , `meta-llama/Meta-Llama-3.1-8B` , `meta-llama/Llama-3.1-8B-Instruct` , .. |\\n| `GPTJForCausalLM` | GPT-J | `EleutherAI/gpt-j-6b` |\\n\\n\\n\\nEncoder-only Models\\n[#](#encoder-only-models \"Link to this heading\")\\n--------------------------------------------------------------------\\n\\n\\nEncoder-only Models\\n\\n[#](#id2 \"Link to this table\")\\n\\n\\n\\n| Architecture | Model Name | Example HuggingFace Models |\\n| --- | --- | --- |\\n| `BertForQuestionAnswering` | Bert | `google-bert/bert-large-uncased` , `google-bert/bert-base-uncased` , .. |\\n\\n\\n\\n\\n\\n[previous\\n\\nFuriosaAI’s Software Stack](software_stack.html \"previous page\")\\n[next\\n\\nWhat’s New](../whatsnew/index.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Decoder-only Models](#decoder-only-models)\\n* [Encoder-only Models](#encoder-only-models)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/overview/supported_models.rst \"Download source file\") * .pdf\\nSupported Models ================\\nContents --------\\n* [Decoder-only Models](#decoder-only-models) * [Encoder-only Models](#encoder-only-models)\\nSupported Models [#](#supported-models \"Link to this heading\") ==============================================================\\nFuriosaAI Software Stack supports a variety of Transformer-based models in HuggingFace Hub. The following is the list of model architectures that are currently supported by Furiosa SDK. If your model is based on the following architectures, you can use Furiosa SDK to compile, quantize, and run the model on FuriosaAI RNGD.\\nDecoder-only Models [#](#decoder-only-models \"Link to this heading\") --------------------------------------------------------------------\\nThe following models are supported for decoding only:\\nDecoder-only Models\\n[#](#id1 \"Link to this table\")\\n| Architecture | Model Name | Example HuggingFace Models | | --- | --- | --- | | `LlamaForCausalLM` | Llama 2, Llama 3.1 | `meta-llama/Llama-2-70b-hf` , `meta-llama/Meta-Llama-3.1-70B` , `meta-llama/Meta-Llama-3-70B-Instruct` , `meta-llama/Meta-Llama-3.1-8B` , `meta-llama/Llama-3.1-8B-Instruct` , .. | | `GPTJForCausalLM` | GPT-J | `EleutherAI/gpt-j-6b` |\\nEncoder-only Models [#](#encoder-only-models \"Link to this heading\") --------------------------------------------------------------------\\nEncoder-only Models\\n[#](#id2 \"Link to this table\")\\n| Architecture | Model Name | Example HuggingFace Models | | --- | --- | --- | | `BertForQuestionAnswering` | Bert | `google-bert/bert-large-uncased` , `google-bert/bert-base-uncased` , .. |\\n[previous\\nFuriosaAI’s Software Stack](software_stack.html \"previous page\") [next\\nWhat’s New](../whatsnew/index.html \"next page\")\\nContents\\n* [Decoder-only Models](#decoder-only-models) * [Encoder-only Models](#encoder-only-models)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/overview/supported_models.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Supported Models\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#decoder-only-models\">\\n          Decoder-only Models\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#encoder-only-models\">\\n          Encoder-only Models\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"supported-models\">\\n     <span id=\"supportedmodels\">\\n     </span>\\n     <h1>\\n      Supported Models\\n      <a class=\"headerlink\" href=\"#supported-models\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      FuriosaAI Software Stack supports a variety of Transformer-based models in HuggingFace Hub.\\nThe following is the list of model architectures that are currently supported by Furiosa SDK.\\nIf your model is based on the following architectures,\\nyou can use Furiosa SDK to compile, quantize, and run the model on FuriosaAI RNGD.\\n     </p>\\n     <section id=\"decoder-only-models\">\\n      <h2>\\n       Decoder-only Models\\n       <a class=\"headerlink\" href=\"#decoder-only-models\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The following models are supported for decoding only:\\n      </p>\\n      <div class=\"pst-scrollable-table-container\">\\n       <table class=\"table table-center\" id=\"id1\">\\n        <caption>\\n         <span class=\"caption-text\">\\n          Decoder-only Models\\n         </span>\\n         <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n          #\\n         </a>\\n        </caption>\\n        <colgroup>\\n         <col style=\"width: 23.6%\"/>\\n         <col style=\"width: 21.8%\"/>\\n         <col style=\"width: 54.5%\"/>\\n        </colgroup>\\n        <thead>\\n         <tr class=\"row-odd\">\\n          <th class=\"head\">\\n           <p>\\n            Architecture\\n           </p>\\n          </th>\\n          <th class=\"head\">\\n           <p>\\n            Model Name\\n           </p>\\n          </th>\\n          <th class=\"head\">\\n           <p>\\n            Example HuggingFace Models\\n           </p>\\n          </th>\\n         </tr>\\n        </thead>\\n        <tbody>\\n         <tr class=\"row-even\">\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              LlamaForCausalLM\\n             </span>\\n            </code>\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            Llama 2, Llama 3.1\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              meta-llama/Llama-2-70b-hf\\n             </span>\\n            </code>\\n            ,\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              meta-llama/Meta-Llama-3.1-70B\\n             </span>\\n            </code>\\n            ,\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              meta-llama/Meta-Llama-3-70B-Instruct\\n             </span>\\n            </code>\\n            ,\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              meta-llama/Meta-Llama-3.1-8B\\n             </span>\\n            </code>\\n            ,\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              meta-llama/Llama-3.1-8B-Instruct\\n             </span>\\n            </code>\\n            , ..\\n           </p>\\n          </td>\\n         </tr>\\n         <tr class=\"row-odd\">\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              GPTJForCausalLM\\n             </span>\\n            </code>\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            GPT-J\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              EleutherAI/gpt-j-6b\\n             </span>\\n            </code>\\n           </p>\\n          </td>\\n         </tr>\\n        </tbody>\\n       </table>\\n      </div>\\n     </section>\\n     <section id=\"encoder-only-models\">\\n      <h2>\\n       Encoder-only Models\\n       <a class=\"headerlink\" href=\"#encoder-only-models\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <div class=\"pst-scrollable-table-container\">\\n       <table class=\"table table-center\" id=\"id2\">\\n        <caption>\\n         <span class=\"caption-text\">\\n          Encoder-only Models\\n         </span>\\n         <a class=\"headerlink\" href=\"#id2\" title=\"Link to this table\">\\n          #\\n         </a>\\n        </caption>\\n        <colgroup>\\n         <col style=\"width: 23.6%\"/>\\n         <col style=\"width: 21.8%\"/>\\n         <col style=\"width: 54.5%\"/>\\n        </colgroup>\\n        <thead>\\n         <tr class=\"row-odd\">\\n          <th class=\"head\">\\n           <p>\\n            Architecture\\n           </p>\\n          </th>\\n          <th class=\"head\">\\n           <p>\\n            Model Name\\n           </p>\\n          </th>\\n          <th class=\"head\">\\n           <p>\\n            Example HuggingFace Models\\n           </p>\\n          </th>\\n         </tr>\\n        </thead>\\n        <tbody>\\n         <tr class=\"row-even\">\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              BertForQuestionAnswering\\n             </span>\\n            </code>\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            Bert\\n           </p>\\n          </td>\\n          <td>\\n           <p>\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              google-bert/bert-large-uncased\\n             </span>\\n            </code>\\n            ,\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              google-bert/bert-base-uncased\\n             </span>\\n            </code>\\n            , ..\\n           </p>\\n          </td>\\n         </tr>\\n        </tbody>\\n       </table>\\n      </div>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"software_stack.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        FuriosaAI’s Software Stack\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../whatsnew/index.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        What’s New\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#decoder-only-models\">\\n         Decoder-only Models\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#encoder-only-models\">\\n         Encoder-only Models\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='0acdfa06-7dff-4603-9a5c-dbc4e3310580', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/software_stack.html'), name='software_stack', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/overview/software_stack.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFuriosaAI’s Software Stack\\n==========================\\n\\n\\nContents\\n--------\\n\\n\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime)\\n* [Furiosa Compiler](#furiosa-compiler)\\n* [Furiosa Runtime](#furiosa-runtime)\\n* [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer)\\n* [Furiosa LLM](#furiosa-llm)\\n* [Kubernetes Support](#kubernetes-support)\\n\\n\\n\\n\\n\\nFuriosaAI’s Software Stack\\n[#](#furiosaai-s-software-stack \"Link to this heading\")\\n==================================================================================\\n\\nFuriosaAI provides the streamlined software stack to allow\\nFuriosaAI NPU to be used in various applications and environments.\\nHere, we outline the SW stack provided by FuriosaAI, explaining\\nthe roles of each component, together with guidelines and tutorials.\\nThe above diagram demonstrates the SW stack provided by FuriosaAI, by layers.\\n\\n\\nThe following outlines the key components.\\n\\nKernel Driver, Firmware, and PE Runtime\\n[#](#kernel-driver-firmware-and-pe-runtime \"Link to this heading\")\\n----------------------------------------------------------------------------------------------------------\\n\\nThe kernel device driver enables the Linux operating system to recognize NPU devices and\\nexpose them as Linux device files. The firmware runs on the SoC within the RNGD card\\nand provides low-level APIs to the PE Runtime (PERT) that runs on the Processing Element (PE).\\nPERT is responsible for communicating with the host’s runtime and\\nscheduling, managing the resources of PEs to execute NPU tasks.\\n\\n\\nFuriosa Compiler\\n[#](#furiosa-compiler \"Link to this heading\")\\n--------------------------------------------------------------\\n\\nFuriosa compiler analyzes, optimizes a model graph, and generates a NPU executable program.\\nThe operation passes involve graph-level optimization, operator fusion, memory allocation optimization, scheduling, and\\ndata movement minimization across layers.\\nWhen\\n`torch.compile()`\\nbackend,\\n`FuriosaBackend`\\nis used or\\n`furiosa-llm`\\nis used,\\nthe Furiosa Compiler is transparently used to generate NPU executable programs for Runtime.\\n\\n\\nFuriosa Runtime\\n[#](#furiosa-runtime \"Link to this heading\")\\n------------------------------------------------------------\\n\\nRuntime loads multiple executable NPU programs generated by Furiosa compiler, and run them on the NPU.\\nA single model can be compiled into multiple executable programs according to model architectures and applications.\\nRuntime is responsible for scheduling NPU programs and managing computation and memory resource on NPUs and CPUs.\\nAlso, Runtime can use multiple NPUs and provides a single entry point to run the model on multiple NPUs.\\n\\n\\nFuriosa Model Compressor (Quantizer)\\n[#](#furiosa-model-compressor-quantizer \"Link to this heading\")\\n----------------------------------------------------------------------------------------------------\\n\\nFuriosa Model Compressor is a library as well as toolkit for model calibration and quantization.\\nModel quantization is a powerful technique to reduce memory footprint, computation cost, inference latency and power consumption.\\nFuriosa Model Compressor provides post-training quantization methods, such as\\n\\n* BF16 (W16A16)\\n* INT8 Weight-Only (W8A16)\\n* FP8 (W8A8)\\n* INT8 SmoothQuant (W8A8)\\n* INT4 Weight-Only (W4A16 AWQ / GPTQ) (Planned in release 2024.2)\\n\\nFuriosa LLM\\n[#](#furiosa-llm \"Link to this heading\")\\n----------------------------------------------------\\n\\nFuriosa LLM provides a high-performance inference engine for LLM models, such as Llama 3.1 70B, 8B, GPT-J, and Bert.\\nFuriosa LLM is designed to provide the state-of-the-art serving optimization for LLM models.\\nThe key features of Furiosa LLM include vLLM-compatible API, PagedAttention, continuous batching,\\nHuggingFace hub support, and OpenAI-compatible API server. You can find further information at\\n[Furiosa LLM](../furiosa_llm/intro.html#furiosallm)\\n.\\n\\n\\nKubernetes Support\\n[#](#kubernetes-support \"Link to this heading\")\\n------------------------------------------------------------------\\n\\nKubernetes, an open-source platform designed to manage containerized applications and services, is extensively adopted\\nby various companies due to its robust capabilities for deploying, scaling, and automating containerized workloads.\\nFuriosaAI software stack also offers native integration with Kubernetes,\\nallowing seamless deployment and management of AI applications within a Kubernetes environment.\\n\\nFuriosaAI’s device plugin enables Kubernetes clusters to recognize FuriosaAI’s NPUs and\\nallows NPUs to be scheduled for workloads and services that require them.\\nThis feature allows users to easily deploy AI workloads with FuriosaAI NPUs on Kubernetes,\\nenabling efficient resource utilization and scaling.\\n\\nYou can find more information about Kubernetes support in the\\n[Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n.\\n\\n\\n\\n\\n[previous\\n\\nFuriosaAI RNGD](rngd.html \"previous page\")\\n[next\\n\\nSupported Models](supported_models.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime)\\n* [Furiosa Compiler](#furiosa-compiler)\\n* [Furiosa Runtime](#furiosa-runtime)\\n* [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer)\\n* [Furiosa LLM](#furiosa-llm)\\n* [Kubernetes Support](#kubernetes-support)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/overview/software_stack.rst \"Download source file\") * .pdf\\nFuriosaAI’s Software Stack ==========================\\nContents --------\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nFuriosaAI’s Software Stack [#](#furiosaai-s-software-stack \"Link to this heading\") ==================================================================================\\nFuriosaAI provides the streamlined software stack to allow FuriosaAI NPU to be used in various applications and environments. Here, we outline the SW stack provided by FuriosaAI, explaining the roles of each component, together with guidelines and tutorials. The above diagram demonstrates the SW stack provided by FuriosaAI, by layers.\\nThe following outlines the key components.\\nKernel Driver, Firmware, and PE Runtime [#](#kernel-driver-firmware-and-pe-runtime \"Link to this heading\") ----------------------------------------------------------------------------------------------------------\\nThe kernel device driver enables the Linux operating system to recognize NPU devices and expose them as Linux device files. The firmware runs on the SoC within the RNGD card and provides low-level APIs to the PE Runtime (PERT) that runs on the Processing Element (PE). PERT is responsible for communicating with the host’s runtime and scheduling, managing the resources of PEs to execute NPU tasks.\\nFuriosa Compiler [#](#furiosa-compiler \"Link to this heading\") --------------------------------------------------------------\\nFuriosa compiler analyzes, optimizes a model graph, and generates a NPU executable program. The operation passes involve graph-level optimization, operator fusion, memory allocation optimization, scheduling, and data movement minimization across layers. When `torch.compile()` backend, `FuriosaBackend` is used or `furiosa-llm` is used, the Furiosa Compiler is transparently used to generate NPU executable programs for Runtime.\\nFuriosa Runtime [#](#furiosa-runtime \"Link to this heading\") ------------------------------------------------------------\\nRuntime loads multiple executable NPU programs generated by Furiosa compiler, and run them on the NPU. A single model can be compiled into multiple executable programs according to model architectures and applications. Runtime is responsible for scheduling NPU programs and managing computation and memory resource on NPUs and CPUs. Also, Runtime can use multiple NPUs and provides a single entry point to run the model on multiple NPUs.\\nFuriosa Model Compressor (Quantizer) [#](#furiosa-model-compressor-quantizer \"Link to this heading\") ----------------------------------------------------------------------------------------------------\\nFuriosa Model Compressor is a library as well as toolkit for model calibration and quantization. Model quantization is a powerful technique to reduce memory footprint, computation cost, inference latency and power consumption. Furiosa Model Compressor provides post-training quantization methods, such as\\n* BF16 (W16A16) * INT8 Weight-Only (W8A16) * FP8 (W8A8) * INT8 SmoothQuant (W8A8) * INT4 Weight-Only (W4A16 AWQ / GPTQ) (Planned in release 2024.2)\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ----------------------------------------------------\\nFuriosa LLM provides a high-performance inference engine for LLM models, such as Llama 3.1 70B, 8B, GPT-J, and Bert. Furiosa LLM is designed to provide the state-of-the-art serving optimization for LLM models. The key features of Furiosa LLM include vLLM-compatible API, PagedAttention, continuous batching, HuggingFace hub support, and OpenAI-compatible API server. You can find further information at [Furiosa LLM](../furiosa_llm/intro.html#furiosallm) .\\nKubernetes Support [#](#kubernetes-support \"Link to this heading\") ------------------------------------------------------------------\\nKubernetes, an open-source platform designed to manage containerized applications and services, is extensively adopted by various companies due to its robust capabilities for deploying, scaling, and automating containerized workloads. FuriosaAI software stack also offers native integration with Kubernetes, allowing seamless deployment and management of AI applications within a Kubernetes environment.\\nFuriosaAI’s device plugin enables Kubernetes clusters to recognize FuriosaAI’s NPUs and allows NPUs to be scheduled for workloads and services that require them. This feature allows users to easily deploy AI workloads with FuriosaAI NPUs on Kubernetes, enabling efficient resource utilization and scaling.\\nYou can find more information about Kubernetes support in the [Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit) .\\n[previous\\nFuriosaAI RNGD](rngd.html \"previous page\") [next\\nSupported Models](supported_models.html \"next page\")\\nContents\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/overview/software_stack.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     FuriosaAI’s Software Stack\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#kernel-driver-firmware-and-pe-runtime\">\\n          Kernel Driver, Firmware, and PE Runtime\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-compiler\">\\n          Furiosa Compiler\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-runtime\">\\n          Furiosa Runtime\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-model-compressor-quantizer\">\\n          Furiosa Model Compressor (Quantizer)\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-llm\">\\n          Furiosa LLM\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#kubernetes-support\">\\n          Kubernetes Support\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"furiosaai-s-software-stack\">\\n     <span id=\"softwarestack\">\\n     </span>\\n     <h1>\\n      FuriosaAI’s Software Stack\\n      <a class=\"headerlink\" href=\"#furiosaai-s-software-stack\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      FuriosaAI provides the streamlined software stack to allow\\nFuriosaAI NPU to be used in various applications and environments.\\nHere, we outline the SW stack provided by FuriosaAI, explaining\\nthe roles of each component, together with guidelines and tutorials.\\nThe above diagram demonstrates the SW stack provided by FuriosaAI, by layers.\\n     </p>\\n     <figure class=\"align-center\">\\n      <a class=\"only-dark reference internal image-reference\" href=\"../_images/sw_stack.svg\">\\n       <img alt=\"FuriosaAI Software Stack\" class=\"only-dark\" src=\"../_images/sw_stack.svg\" style=\"width: 500px;\"/>\\n      </a>\\n     </figure>\\n     <figure class=\"align-center\">\\n      <a class=\"only-light reference internal image-reference\" href=\"../_images/sw_stack.svg\">\\n       <img alt=\"FuriosaAI Software Stack\" class=\"only-light\" src=\"../_images/sw_stack.svg\" style=\"width: 500px;\"/>\\n      </a>\\n     </figure>\\n     <p>\\n      The following outlines the key components.\\n     </p>\\n     <section id=\"kernel-driver-firmware-and-pe-runtime\">\\n      <h2>\\n       Kernel Driver, Firmware, and PE Runtime\\n       <a class=\"headerlink\" href=\"#kernel-driver-firmware-and-pe-runtime\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The kernel device driver enables the Linux operating system to recognize NPU devices and\\nexpose them as Linux device files. The firmware runs on the SoC within the RNGD card\\nand provides low-level APIs to the PE Runtime (PERT) that runs on the Processing Element (PE).\\nPERT is responsible for communicating with the host’s runtime and\\nscheduling, managing the resources of PEs to execute NPU tasks.\\n      </p>\\n     </section>\\n     <section id=\"furiosa-compiler\">\\n      <h2>\\n       Furiosa Compiler\\n       <a class=\"headerlink\" href=\"#furiosa-compiler\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Furiosa compiler analyzes, optimizes a model graph, and generates a NPU executable program.\\nThe operation passes involve graph-level optimization, operator fusion, memory allocation optimization, scheduling, and\\ndata movement minimization across layers.\\nWhen\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         torch.compile()\\n        </span>\\n       </code>\\n       backend,\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         FuriosaBackend\\n        </span>\\n       </code>\\n       is used or\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-llm\\n        </span>\\n       </code>\\n       is used,\\nthe Furiosa Compiler is transparently used to generate NPU executable programs for Runtime.\\n      </p>\\n     </section>\\n     <section id=\"furiosa-runtime\">\\n      <h2>\\n       Furiosa Runtime\\n       <a class=\"headerlink\" href=\"#furiosa-runtime\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Runtime loads multiple executable NPU programs generated by Furiosa compiler, and run them on the NPU.\\nA single model can be compiled into multiple executable programs according to model architectures and applications.\\nRuntime is responsible for scheduling NPU programs and managing computation and memory resource on NPUs and CPUs.\\nAlso, Runtime can use multiple NPUs and provides a single entry point to run the model on multiple NPUs.\\n      </p>\\n     </section>\\n     <section id=\"furiosa-model-compressor-quantizer\">\\n      <h2>\\n       Furiosa Model Compressor (Quantizer)\\n       <a class=\"headerlink\" href=\"#furiosa-model-compressor-quantizer\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Furiosa Model Compressor is a library as well as toolkit for model calibration and quantization.\\nModel quantization is a powerful technique to reduce memory footprint, computation cost, inference latency and power consumption.\\nFuriosa Model Compressor provides post-training quantization methods, such as\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         BF16 (W16A16)\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         INT8 Weight-Only (W8A16)\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         FP8 (W8A8)\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         INT8 SmoothQuant (W8A8)\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         INT4 Weight-Only (W4A16 AWQ / GPTQ) (Planned in release 2024.2)\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"furiosa-llm\">\\n      <h2>\\n       Furiosa LLM\\n       <a class=\"headerlink\" href=\"#furiosa-llm\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Furiosa LLM provides a high-performance inference engine for LLM models, such as Llama 3.1 70B, 8B, GPT-J, and Bert.\\nFuriosa LLM is designed to provide the state-of-the-art serving optimization for LLM models.\\nThe key features of Furiosa LLM include vLLM-compatible API, PagedAttention, continuous batching,\\nHuggingFace hub support, and OpenAI-compatible API server. You can find further information at\\n       <a class=\"reference internal\" href=\"../furiosa_llm/intro.html#furiosallm\">\\n        <span class=\"std std-ref\">\\n         Furiosa LLM\\n        </span>\\n       </a>\\n       .\\n      </p>\\n     </section>\\n     <section id=\"kubernetes-support\">\\n      <h2>\\n       Kubernetes Support\\n       <a class=\"headerlink\" href=\"#kubernetes-support\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Kubernetes, an open-source platform designed to manage containerized applications and services, is extensively adopted\\nby various companies due to its robust capabilities for deploying, scaling, and automating containerized workloads.\\nFuriosaAI software stack also offers native integration with Kubernetes,\\nallowing seamless deployment and management of AI applications within a Kubernetes environment.\\n      </p>\\n      <p>\\n       FuriosaAI’s device plugin enables Kubernetes clusters to recognize FuriosaAI’s NPUs and\\nallows NPUs to be scheduled for workloads and services that require them.\\nThis feature allows users to easily deploy AI workloads with FuriosaAI NPUs on Kubernetes,\\nenabling efficient resource utilization and scaling.\\n      </p>\\n      <p>\\n       You can find more information about Kubernetes support in the\\n       <a class=\"reference internal\" href=\"../cloud_native_toolkit/intro.html#cloudnativetoolkit\">\\n        <span class=\"std std-ref\">\\n         Cloud Native Toolkit\\n        </span>\\n       </a>\\n       .\\n      </p>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"rngd.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        FuriosaAI RNGD\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"supported_models.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Supported Models\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#kernel-driver-firmware-and-pe-runtime\">\\n         Kernel Driver, Firmware, and PE Runtime\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-compiler\">\\n         Furiosa Compiler\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-runtime\">\\n         Furiosa Runtime\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-model-compressor-quantizer\">\\n         Furiosa Model Compressor (Quantizer)\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-llm\">\\n         Furiosa LLM\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#kubernetes-support\">\\n         Kubernetes Support\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='da255daf-c8d3-430e-b976-ad096f3a9ad7', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/references/sampling_params.html'), name='sampling_params', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/furiosa_llm/references/sampling_params.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nSamplingParams\\n==============\\n\\n\\nContents\\n--------\\n\\n\\n* [`SamplingParams`](#furiosa_llm.SamplingParams)\\n\\n\\n\\n\\n\\nSamplingParams\\n[#](#samplingparams \"Link to this heading\")\\n==========================================================\\n\\n*class*\\nfuriosa\\\\_llm.\\n\\n\\nSamplingParams\\n\\n\\n(\\n\\n*\\\\**\\n,\\n*n\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*best\\\\_of\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*temperature\\n\\n\\n:\\n\\n\\n\\nfloat\\n\\n\\n\\n=\\n\\n\\n\\n1.0*\\n,\\n*top\\\\_p\\n\\n\\n:\\n\\n\\n\\nfloat\\n\\n\\n\\n=\\n\\n\\n\\n1.0*\\n,\\n*top\\\\_k\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n-1*\\n,\\n*use\\\\_beam\\\\_search\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*length\\\\_penalty\\n\\n\\n:\\n\\n\\n\\nfloat\\n\\n\\n\\n=\\n\\n\\n\\n1.0*\\n,\\n*early\\\\_stopping\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n|\\n\\n\\n\\nstr\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*max\\\\_tokens\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n16*\\n,\\n*min\\\\_tokens\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n0*\\n)\\n\\n[[source]](../../_modules/furiosa_llm/sampling_params.html#SamplingParams)\\n[#](#furiosa_llm.SamplingParams \"Link to this definition\")\\n\\nBases:\\n`object`\\n\\nSampling parameters for text generation.\\n\\nThe default parameters represents greedy search.\\n\\nParameters\\n:\\n\\n\\n* **n**\\n  – Number of output sequences to return for the given prompt.\\n* **best\\\\_of**\\n  – Number of output sequences that are generated from the prompt.\\n  From these\\n  best\\\\_of\\n  \\n  sequences, the top\\n  n\\n  \\n  sequences are returned.\\n  best\\\\_of\\n  \\n  must be greater than or equal to\\n  n\\n  \\n  . This is treated as\\n  the beam width when\\n  use\\\\_beam\\\\_search\\n  \\n  is True. By default,\\n  best\\\\_of\\n  \\n  is set to\\n  n\\n  \\n  .\\n* **temperature**\\n  – Float that controls the randomness of the sampling. Lower\\n  values make the model more deterministic, while higher values make\\n  the model more random. Zero means greedy sampling.\\n* **top\\\\_p**\\n  – Float that controls the cumulative probability of the top tokens\\n  to consider. Must be in (0, 1]. Set to 1 to consider all tokens.\\n* **top\\\\_k**\\n  – Integer that controls the number of top tokens to consider. Set\\n  to -1 to consider all tokens.\\n* **use\\\\_beam\\\\_search**\\n  – Whether to use beam search instead of sampling.\\n* **length\\\\_penalty**\\n  – Float that penalizes sequences based on their length.\\n  Used in beam search.\\n* **early\\\\_stopping**\\n  – Controls the stopping condition for beam search. It\\n  accepts the following values:\\n  True\\n  \\n  , where the generation stops as\\n  soon as there are\\n  best\\\\_of\\n  \\n  complete candidates;\\n  False\\n  \\n  , where an\\n  heuristic is applied and the generation stops when is it very\\n  unlikely to find better candidates;\\n  “never”\\n  \\n  , where the beam search\\n  procedure only stops when there cannot be better candidates\\n  (canonical beam search algorithm).\\n* **max\\\\_tokens**\\n  – Maximum number of tokens to generate per output sequence.\\n* **min\\\\_tokens**\\n  – Minimum number of tokens to generate per output sequence\\n  before EOS or stop\\\\_token\\\\_ids can be generated\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nLLM class](llm.html \"previous page\")\\n[next\\n\\nCloud Native Toolkit](../../cloud_native_toolkit/intro.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [`SamplingParams`](#furiosa_llm.SamplingParams)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/furiosa_llm/references/sampling_params.rst \"Download source file\") * .pdf\\nSamplingParams ==============\\nContents --------\\n* [`SamplingParams`](#furiosa_llm.SamplingParams)\\nSamplingParams [#](#samplingparams \"Link to this heading\") ==========================================================\\n*class* furiosa\\\\_llm.\\nSamplingParams\\n(\\n*\\\\** ,\\n*n\\n:\\nint\\n=\\n1* ,\\n*best\\\\_of\\n:\\nint\\n|\\nNone\\n=\\nNone* ,\\n*temperature\\n:\\nfloat\\n=\\n1.0* ,\\n*top\\\\_p\\n:\\nfloat\\n=\\n1.0* ,\\n*top\\\\_k\\n:\\nint\\n=\\n-1* ,\\n*use\\\\_beam\\\\_search\\n:\\nbool\\n=\\nFalse* ,\\n*length\\\\_penalty\\n:\\nfloat\\n=\\n1.0* ,\\n*early\\\\_stopping\\n:\\nbool\\n|\\nstr\\n=\\nFalse* ,\\n*max\\\\_tokens\\n:\\nint\\n=\\n16* ,\\n*min\\\\_tokens\\n:\\nint\\n=\\n0* )\\n[[source]](../../_modules/furiosa_llm/sampling_params.html#SamplingParams) [#](#furiosa_llm.SamplingParams \"Link to this definition\")\\nBases: `object`  Sampling parameters for text generation.\\nThe default parameters represents greedy search.\\nParameters :\\n* **n**   – Number of output sequences to return for the given prompt. * **best\\\\_of**   – Number of output sequences that are generated from the prompt.   From these   best\\\\_of      sequences, the top   n      sequences are returned.   best\\\\_of      must be greater than or equal to   n      . This is treated as   the beam width when   use\\\\_beam\\\\_search      is True. By default,   best\\\\_of      is set to   n      . * **temperature**   – Float that controls the randomness of the sampling. Lower   values make the model more deterministic, while higher values make   the model more random. Zero means greedy sampling. * **top\\\\_p**   – Float that controls the cumulative probability of the top tokens   to consider. Must be in (0, 1]. Set to 1 to consider all tokens. * **top\\\\_k**   – Integer that controls the number of top tokens to consider. Set   to -1 to consider all tokens. * **use\\\\_beam\\\\_search**   – Whether to use beam search instead of sampling. * **length\\\\_penalty**   – Float that penalizes sequences based on their length.   Used in beam search. * **early\\\\_stopping**   – Controls the stopping condition for beam search. It   accepts the following values:   True      , where the generation stops as   soon as there are   best\\\\_of      complete candidates;   False      , where an   heuristic is applied and the generation stops when is it very   unlikely to find better candidates;   “never”      , where the beam search   procedure only stops when there cannot be better candidates   (canonical beam search algorithm). * **max\\\\_tokens**   – Maximum number of tokens to generate per output sequence. * **min\\\\_tokens**   – Minimum number of tokens to generate per output sequence   before EOS or stop\\\\_token\\\\_ids can be generated\\n[previous\\nLLM class](llm.html \"previous page\") [next\\nCloud Native Toolkit](../../cloud_native_toolkit/intro.html \"next page\")\\nContents\\n* [`SamplingParams`](#furiosa_llm.SamplingParams)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/furiosa_llm/references/sampling_params.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     SamplingParams\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa_llm.SamplingParams\">\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            SamplingParams\\n           </span>\\n          </code>\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"samplingparams\">\\n     <span id=\"id1\">\\n     </span>\\n     <h1>\\n      SamplingParams\\n      <a class=\"headerlink\" href=\"#samplingparams\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <dl class=\"py class\">\\n      <dt class=\"sig sig-object py\" id=\"furiosa_llm.SamplingParams\">\\n       <em class=\"property\">\\n        <span class=\"pre\">\\n         class\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n       </em>\\n       <span class=\"sig-prename descclassname\">\\n        <span class=\"pre\">\\n         furiosa_llm.\\n        </span>\\n       </span>\\n       <span class=\"sig-name descname\">\\n        <span class=\"pre\">\\n         SamplingParams\\n        </span>\\n       </span>\\n       <span class=\"sig-paren\">\\n        (\\n       </span>\\n       <em class=\"sig-param\">\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          *\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          n\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          best_of\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          temperature\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          float\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1.0\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          top_p\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          float\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1.0\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          top_k\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          -1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          use_beam_search\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          length_penalty\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          float\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1.0\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          early_stopping\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          str\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          max_tokens\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          16\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          min_tokens\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          0\\n         </span>\\n        </span>\\n       </em>\\n       <span class=\"sig-paren\">\\n        )\\n       </span>\\n       <a class=\"reference internal\" href=\"../../_modules/furiosa_llm/sampling_params.html#SamplingParams\">\\n        <span class=\"viewcode-link\">\\n         <span class=\"pre\">\\n          [source]\\n         </span>\\n        </span>\\n       </a>\\n       <a class=\"headerlink\" href=\"#furiosa_llm.SamplingParams\" title=\"Link to this definition\">\\n        #\\n       </a>\\n      </dt>\\n      <dd>\\n       <p>\\n        Bases:\\n        <code class=\"xref py py-class docutils literal notranslate\">\\n         <span class=\"pre\">\\n          object\\n         </span>\\n        </code>\\n       </p>\\n       <p>\\n        Sampling parameters for text generation.\\n       </p>\\n       <p>\\n        The default parameters represents greedy search.\\n       </p>\\n       <dl class=\"field-list simple\">\\n        <dt class=\"field-odd\">\\n         Parameters\\n         <span class=\"colon\">\\n          :\\n         </span>\\n        </dt>\\n        <dd class=\"field-odd\">\\n         <ul class=\"simple\">\\n          <li>\\n           <p>\\n            <strong>\\n             n\\n            </strong>\\n            – Number of output sequences to return for the given prompt.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             best_of\\n            </strong>\\n            – Number of output sequences that are generated from the prompt.\\nFrom these\\n            <cite>\\n             best_of\\n            </cite>\\n            sequences, the top\\n            <cite>\\n             n\\n            </cite>\\n            sequences are returned.\\n            <cite>\\n             best_of\\n            </cite>\\n            must be greater than or equal to\\n            <cite>\\n             n\\n            </cite>\\n            . This is treated as\\nthe beam width when\\n            <cite>\\n             use_beam_search\\n            </cite>\\n            is True. By default,\\n            <cite>\\n             best_of\\n            </cite>\\n            is set to\\n            <cite>\\n             n\\n            </cite>\\n            .\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             temperature\\n            </strong>\\n            – Float that controls the randomness of the sampling. Lower\\nvalues make the model more deterministic, while higher values make\\nthe model more random. Zero means greedy sampling.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             top_p\\n            </strong>\\n            – Float that controls the cumulative probability of the top tokens\\nto consider. Must be in (0, 1]. Set to 1 to consider all tokens.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             top_k\\n            </strong>\\n            – Integer that controls the number of top tokens to consider. Set\\nto -1 to consider all tokens.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             use_beam_search\\n            </strong>\\n            – Whether to use beam search instead of sampling.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             length_penalty\\n            </strong>\\n            – Float that penalizes sequences based on their length.\\nUsed in beam search.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             early_stopping\\n            </strong>\\n            – Controls the stopping condition for beam search. It\\naccepts the following values:\\n            <cite>\\n             True\\n            </cite>\\n            , where the generation stops as\\nsoon as there are\\n            <cite>\\n             best_of\\n            </cite>\\n            complete candidates;\\n            <cite>\\n             False\\n            </cite>\\n            , where an\\nheuristic is applied and the generation stops when is it very\\nunlikely to find better candidates;\\n            <cite>\\n             “never”\\n            </cite>\\n            , where the beam search\\nprocedure only stops when there cannot be better candidates\\n(canonical beam search algorithm).\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             max_tokens\\n            </strong>\\n            – Maximum number of tokens to generate per output sequence.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             min_tokens\\n            </strong>\\n            – Minimum number of tokens to generate per output sequence\\nbefore EOS or stop_token_ids can be generated\\n           </p>\\n          </li>\\n         </ul>\\n        </dd>\\n       </dl>\\n      </dd>\\n     </dl>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"llm.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        LLM class\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../../cloud_native_toolkit/intro.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Cloud Native Toolkit\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa_llm.SamplingParams\">\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           SamplingParams\\n          </span>\\n         </code>\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='edfa6fb4-e88c-4fa8-a6aa-9986213aa6ab', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/device_management/furiosa_smi.html'), name='furiosa_smi', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/device_management/furiosa_smi.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nfuriosa-smi\\n===========\\n\\n\\nContents\\n--------\\n\\n\\n* [Installing\\n  `furiosa-smi`\\n  command](#installing-furiosa-smi-command)\\n  + [Synopsis](#synopsis)\\n  + [`furiosa-smi\\n    \\n    info`](#furiosa-smi-info)\\n  + [`furiosa-smi\\n    \\n    status`](#furiosa-smi-status)\\n  + [`furiosa-smi\\n    \\n    ps`](#furiosa-smi-ps)\\n  + [`furiosa-smi\\n    \\n    topo`](#furiosa-smi-topo)\\n\\n\\n\\n\\n\\nfuriosa-smi\\n[#](#furiosa-smi \"Link to this heading\")\\n====================================================\\n\\nThe\\n`furiosa-smi`\\ncommand provides a variety of subcommands and has the ability to obtain information or control the device.\\n\\nInstalling\\n`furiosa-smi`\\ncommand\\n[#](#installing-furiosa-smi-command \"Link to this heading\")\\n--------------------------------------------------------------------------------------------\\n\\nTo install the\\n`furiosa-smi`\\ncommand, you need to install\\n`furiosa-smi`\\nas following:\\n\\nThe minimum requirements for\\n`furiosa-smi`\\nare as follows:\\n\\n* Ubuntu 20.04 LTS (Debian bullseye) or later\\n* Root permission or sudo permission\\n* Configuring the APT server and installing device drivers (\\n  [Setting up APT server](../getting_started/prerequisites.html#aptsetup)\\n  )\\n\\nThen, please install the\\n`furiosa-smi`\\npackage as follows:\\n\\n```\\nsudo apt update\\nsudo apt install -y furiosa-smi\\n\\n```\\n\\nThis command installs packages\\n`furiosa-libsmi`\\nand\\n`furiosa-smi`\\n.\\n\\n### Synopsis [#](#synopsis \"Link to this heading\")\\n\\n```\\nfuriosa-smi <sub command> [option] ..\\n\\n```\\n\\n\\n\\n### `furiosa-smi info` [#](#furiosa-smi-info \"Link to this heading\")\\n\\nAfter installing the kernel driver, you can use the\\n`furiosa-smi`\\ncommand to check whether the NPU device is recognized.\\nCurrently, this command provides the\\n`furiosa-smi\\n\\ninfo`\\ncommand to output temperature, power consumption and PCI information of the NPU device.\\nIf the device is not visible with this command after mounting it on the machine, please install the driver.\\nIf you add the\\n`--full`\\noption to the\\n`info`\\ncommand, you can see the device’s UUID and serial number information together.\\n\\n```\\n$ furiosa-smi info\\n+------+--------+----------------+---------+---------+--------------+\\n| Arch | Device | Firmware       | Temp.   | Power   | PCI-BDF      |\\n+------+--------+----------------+---------+---------+--------------+\\n| rngd | npu0   | 0.0.15+af1daaa | 30.18°C | 53.00 W | 0000:17:00.0 |\\n+------+--------+----------------+---------+---------+--------------+\\n| rngd | npu1   | 0.0.15+af1daaa | 29.25°C | 53.00 W | 0000:2a:00.0 |\\n+------+--------+----------------+---------+---------+--------------+\\n\\n\\n$ furiosa-smi info --format full\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n| Arch | Device | UUID                                 | S/N        | Firmware       | Temp.   | Power   | Clock | PCI-BDF      | PCI-DEV |\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n| rngd | npu0   | 3E93AE7C-E8EA-4C62-BED6-AD2EC0461AE8 | RNGDXXXXXX | 0.0.15+af1daaa | 30.18°C | 53.00 W |   N/A | 0000:17:00.0 | 508:0   |\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n| rngd | npu1   | 176DAD0F-1510-475C-91D8-5F79551CF718 | RNGDXXXXXY | 0.0.15+af1daaa | 29.44°C | 53.00 W |   N/A | 0000:2a:00.0 | 506:0   |\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n\\n```\\n\\n\\n\\n### `furiosa-smi status` [#](#furiosa-smi-status \"Link to this heading\")\\n\\nThe\\n`status`\\nsubcommand provides information about the device files available on the NPU device.\\nYou can also check whether each core present in the NPU is in use or idle.\\n\\n```\\n$ furiosa-smi status\\n+------+--------+---------------+------------------+\\n| Arch | Device | Cores         | Core Utilization |\\n+------+--------+---------------+------------------+\\n|      |        | 0 (occupied), | Core 0: 0.00%,   |\\n|      |        | 1 (occupied), | Core 1: 0.00%,   |\\n|      |        | 2 (occupied), | Core 2: 0.00%,   |\\n| rngd | npu0   | 3 (occupied), | Core 3: 0.00%,   |\\n|      |        | 4 (occupied), | Core 4: 0.00%,   |\\n|      |        | 5 (occupied), | Core 5: 0.00%,   |\\n|      |        | 6 (occupied), | Core 6: 0.00%,   |\\n|      |        | 7 (occupied)  | Core 7: 0.00%    |\\n+------+--------+---------------+------------------+\\n|      |        | 0 (occupied), | Core 0: 0.00%,   |\\n|      |        | 1 (occupied), | Core 1: 0.00%,   |\\n|      |        | 2 (occupied), | Core 2: 0.00%,   |\\n| rngd | npu1   | 3 (occupied), | Core 3: 0.00%,   |\\n|      |        | 4 (occupied), | Core 4: 0.00%,   |\\n|      |        | 5 (occupied), | Core 5: 0.00%,   |\\n|      |        | 6 (occupied), | Core 6: 0.00%,   |\\n|      |        | 7 (occupied)  | Core 7: 0.00%    |\\n+------+--------+---------------+------------------+\\n\\n```\\n\\n\\n\\n### `furiosa-smi ps` [#](#furiosa-smi-ps \"Link to this heading\")\\n\\nThe\\n`ps`\\nsubcommand prints information about the OS process currently occupying the NPU device.\\n\\n```\\n$ furiosa-smi ps\\n+-----------+--------+------------------------------------------------------------+\\n| NPU       | PID    | CMD                                                        |\\n+-----------+--------+------------------------------------------------------------+\\n| npu0pe0-3 | 132529 | /usr/bin/python3 /usr/local/bin/uvicorn gptj:app           |\\n+-----------+--------+------------------------------------------------------------+\\n\\n```\\n\\n\\n\\n### `furiosa-smi topo` [#](#furiosa-smi-topo \"Link to this heading\")\\n\\nThe\\n`topo`\\nsubcommand shows the topology of the NPU device and its NUMA node.\\n\\n```\\n$ furiosa-smi topo\\n+--------+--------------+--------------+-----------+\\n| Device | npu0         | npu1         | NUMA node |\\n+--------+--------------+--------------+-----------+\\n| npu0   | Noc          | Interconnect | 0         |\\n+--------+--------------+--------------+-----------+\\n| npu1   | Interconnect | Noc          | 0         |\\n+--------+--------------+--------------+-----------+\\n\\nLegend:\\n\\n  Noc          = Connection within the same npu chip\\n  Bridge       = Devices communicating via one or more PCIe switches\\n  Cpu          = Devices communicating exclusively within a single CPU socket\\n  Interconnect = Devices communicating via inter-socket links (e.g., QPI, GMI)\\n  Unknown      = Connection type is unidentified\\n\\n```\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nCloud Native Toolkit](../cloud_native_toolkit/intro.html \"previous page\")\\n\\n\\n\\nContents\\n\\n* [Installing\\n  `furiosa-smi`\\n  command](#installing-furiosa-smi-command)\\n  + [Synopsis](#synopsis)\\n  + [`furiosa-smi\\n    \\n    info`](#furiosa-smi-info)\\n  + [`furiosa-smi\\n    \\n    status`](#furiosa-smi-status)\\n  + [`furiosa-smi\\n    \\n    ps`](#furiosa-smi-ps)\\n  + [`furiosa-smi\\n    \\n    topo`](#furiosa-smi-topo)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/device_management/furiosa_smi.rst \"Download source file\") * .pdf\\nfuriosa-smi ===========\\nContents --------\\n* [Installing   `furiosa-smi`   command](#installing-furiosa-smi-command)   + [Synopsis](#synopsis)   + [`furiosa-smi          info`](#furiosa-smi-info)   + [`furiosa-smi          status`](#furiosa-smi-status)   + [`furiosa-smi          ps`](#furiosa-smi-ps)   + [`furiosa-smi          topo`](#furiosa-smi-topo)\\nfuriosa-smi [#](#furiosa-smi \"Link to this heading\") ====================================================\\nThe `furiosa-smi` command provides a variety of subcommands and has the ability to obtain information or control the device.\\nInstalling `furiosa-smi` command [#](#installing-furiosa-smi-command \"Link to this heading\") --------------------------------------------------------------------------------------------\\nTo install the `furiosa-smi` command, you need to install `furiosa-smi` as following:\\nThe minimum requirements for `furiosa-smi` are as follows:\\n* Ubuntu 20.04 LTS (Debian bullseye) or later * Root permission or sudo permission * Configuring the APT server and installing device drivers (   [Setting up APT server](../getting_started/prerequisites.html#aptsetup)   )\\nThen, please install the `furiosa-smi` package as follows:\\n``` sudo apt update sudo apt install -y furiosa-smi\\n```\\nThis command installs packages `furiosa-libsmi` and `furiosa-smi` .\\n### Synopsis [#](#synopsis \"Link to this heading\")\\n``` furiosa-smi <sub command> [option] ..\\n```\\n### `furiosa-smi info` [#](#furiosa-smi-info \"Link to this heading\")\\nAfter installing the kernel driver, you can use the `furiosa-smi` command to check whether the NPU device is recognized. Currently, this command provides the `furiosa-smi\\ninfo` command to output temperature, power consumption and PCI information of the NPU device. If the device is not visible with this command after mounting it on the machine, please install the driver. If you add the `--full` option to the `info` command, you can see the device’s UUID and serial number information together.\\n``` $ furiosa-smi info +------+--------+----------------+---------+---------+--------------+ | Arch | Device | Firmware       | Temp.   | Power   | PCI-BDF      | +------+--------+----------------+---------+---------+--------------+ | rngd | npu0   | 0.0.15+af1daaa | 30.18°C | 53.00 W | 0000:17:00.0 | +------+--------+----------------+---------+---------+--------------+ | rngd | npu1   | 0.0.15+af1daaa | 29.25°C | 53.00 W | 0000:2a:00.0 | +------+--------+----------------+---------+---------+--------------+\\n$ furiosa-smi info --format full +------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+ | Arch | Device | UUID                                 | S/N        | Firmware       | Temp.   | Power   | Clock | PCI-BDF      | PCI-DEV | +------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+ | rngd | npu0   | 3E93AE7C-E8EA-4C62-BED6-AD2EC0461AE8 | RNGDXXXXXX | 0.0.15+af1daaa | 30.18°C | 53.00 W |   N/A | 0000:17:00.0 | 508:0   | +------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+ | rngd | npu1   | 176DAD0F-1510-475C-91D8-5F79551CF718 | RNGDXXXXXY | 0.0.15+af1daaa | 29.44°C | 53.00 W |   N/A | 0000:2a:00.0 | 506:0   | +------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n```\\n### `furiosa-smi status` [#](#furiosa-smi-status \"Link to this heading\")\\nThe `status` subcommand provides information about the device files available on the NPU device. You can also check whether each core present in the NPU is in use or idle.\\n``` $ furiosa-smi status +------+--------+---------------+------------------+ | Arch | Device | Cores         | Core Utilization | +------+--------+---------------+------------------+ |      |        | 0 (occupied), | Core 0: 0.00%,   | |      |        | 1 (occupied), | Core 1: 0.00%,   | |      |        | 2 (occupied), | Core 2: 0.00%,   | | rngd | npu0   | 3 (occupied), | Core 3: 0.00%,   | |      |        | 4 (occupied), | Core 4: 0.00%,   | |      |        | 5 (occupied), | Core 5: 0.00%,   | |      |        | 6 (occupied), | Core 6: 0.00%,   | |      |        | 7 (occupied)  | Core 7: 0.00%    | +------+--------+---------------+------------------+ |      |        | 0 (occupied), | Core 0: 0.00%,   | |      |        | 1 (occupied), | Core 1: 0.00%,   | |      |        | 2 (occupied), | Core 2: 0.00%,   | | rngd | npu1   | 3 (occupied), | Core 3: 0.00%,   | |      |        | 4 (occupied), | Core 4: 0.00%,   | |      |        | 5 (occupied), | Core 5: 0.00%,   | |      |        | 6 (occupied), | Core 6: 0.00%,   | |      |        | 7 (occupied)  | Core 7: 0.00%    | +------+--------+---------------+------------------+\\n```\\n### `furiosa-smi ps` [#](#furiosa-smi-ps \"Link to this heading\")\\nThe `ps` subcommand prints information about the OS process currently occupying the NPU device.\\n``` $ furiosa-smi ps +-----------+--------+------------------------------------------------------------+ | NPU       | PID    | CMD                                                        | +-----------+--------+------------------------------------------------------------+ | npu0pe0-3 | 132529 | /usr/bin/python3 /usr/local/bin/uvicorn gptj:app           | +-----------+--------+------------------------------------------------------------+\\n```\\n### `furiosa-smi topo` [#](#furiosa-smi-topo \"Link to this heading\")\\nThe `topo` subcommand shows the topology of the NPU device and its NUMA node.\\n``` $ furiosa-smi topo +--------+--------------+--------------+-----------+ | Device | npu0         | npu1         | NUMA node | +--------+--------------+--------------+-----------+ | npu0   | Noc          | Interconnect | 0         | +--------+--------------+--------------+-----------+ | npu1   | Interconnect | Noc          | 0         | +--------+--------------+--------------+-----------+\\nLegend:\\n  Noc          = Connection within the same npu chip   Bridge       = Devices communicating via one or more PCIe switches   Cpu          = Devices communicating exclusively within a single CPU socket   Interconnect = Devices communicating via inter-socket links (e.g., QPI, GMI)   Unknown      = Connection type is unidentified\\n```\\n[previous\\nCloud Native Toolkit](../cloud_native_toolkit/intro.html \"previous page\")\\nContents\\n* [Installing   `furiosa-smi`   command](#installing-furiosa-smi-command)   + [Synopsis](#synopsis)   + [`furiosa-smi          info`](#furiosa-smi-info)   + [`furiosa-smi          status`](#furiosa-smi-status)   + [`furiosa-smi          ps`](#furiosa-smi-ps)   + [`furiosa-smi          topo`](#furiosa-smi-topo)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/device_management/furiosa_smi.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     furiosa-smi\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#installing-furiosa-smi-command\">\\n          Installing\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            furiosa-smi\\n           </span>\\n          </code>\\n          command\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#synopsis\">\\n            Synopsis\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa-smi-info\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              furiosa-smi\\n             </span>\\n             <span class=\"pre\">\\n              info\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa-smi-status\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              furiosa-smi\\n             </span>\\n             <span class=\"pre\">\\n              status\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa-smi-ps\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              furiosa-smi\\n             </span>\\n             <span class=\"pre\">\\n              ps\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa-smi-topo\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              furiosa-smi\\n             </span>\\n             <span class=\"pre\">\\n              topo\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"furiosa-smi\">\\n     <span id=\"furiosasmi\">\\n     </span>\\n     <h1>\\n      furiosa-smi\\n      <a class=\"headerlink\" href=\"#furiosa-smi\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      The\\n      <code class=\"docutils literal notranslate\">\\n       <span class=\"pre\">\\n        furiosa-smi\\n       </span>\\n      </code>\\n      command provides a variety of subcommands and has the ability to obtain information or control the device.\\n     </p>\\n     <section id=\"installing-furiosa-smi-command\">\\n      <h2>\\n       Installing\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       command\\n       <a class=\"headerlink\" href=\"#installing-furiosa-smi-command\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       To install the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       command, you need to install\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       as following:\\n      </p>\\n      <p>\\n       The minimum requirements for\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       are as follows:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         Ubuntu 20.04 LTS (Debian bullseye) or later\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Root permission or sudo permission\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Configuring the APT server and installing device drivers (\\n         <a class=\"reference internal\" href=\"../getting_started/prerequisites.html#aptsetup\">\\n          <span class=\"std std-ref\">\\n           Setting up APT server\\n          </span>\\n         </a>\\n         )\\n        </p>\\n       </li>\\n      </ul>\\n      <p>\\n       Then, please install the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       package as follows:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>update\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>-y<span class=\"w\"> </span>furiosa-smi\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       This command installs packages\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-libsmi\\n        </span>\\n       </code>\\n       and\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       .\\n      </p>\\n      <section id=\"synopsis\">\\n       <h3>\\n        Synopsis\\n        <a class=\"headerlink\" href=\"#synopsis\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>furiosa-smi<span class=\"w\"> </span>&lt;sub<span class=\"w\"> </span>command&gt;<span class=\"w\"> </span><span class=\"o\">[</span>option<span class=\"o\">]</span><span class=\"w\"> </span>..\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"furiosa-smi-info\">\\n       <h3>\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n         <span class=\"pre\">\\n          info\\n         </span>\\n        </code>\\n        <a class=\"headerlink\" href=\"#furiosa-smi-info\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        After installing the kernel driver, you can use the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n        </code>\\n        command to check whether the NPU device is recognized.\\nCurrently, this command provides the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n         <span class=\"pre\">\\n          info\\n         </span>\\n        </code>\\n        command to output temperature, power consumption and PCI information of the NPU device.\\nIf the device is not visible with this command after mounting it on the machine, please install the driver.\\nIf you add the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          --full\\n         </span>\\n        </code>\\n        option to the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          info\\n         </span>\\n        </code>\\n        command, you can see the device’s UUID and serial number information together.\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>$<span class=\"w\"> </span>furiosa-smi<span class=\"w\"> </span>info\\n+------+--------+----------------+---------+---------+--------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>Arch<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Device<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Firmware<span class=\"w\">       </span><span class=\"p\">|</span><span class=\"w\"> </span>Temp.<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>Power<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>PCI-BDF<span class=\"w\">      </span><span class=\"p\">|</span>\\n+------+--------+----------------+---------+---------+--------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu0<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span>.0.15+af1daaa<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">30</span>.18°C<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">53</span>.00<span class=\"w\"> </span>W<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0000</span>:17:00.0<span class=\"w\"> </span><span class=\"p\">|</span>\\n+------+--------+----------------+---------+---------+--------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu1<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span>.0.15+af1daaa<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">29</span>.25°C<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">53</span>.00<span class=\"w\"> </span>W<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0000</span>:2a:00.0<span class=\"w\"> </span><span class=\"p\">|</span>\\n+------+--------+----------------+---------+---------+--------------+\\n\\n\\n$<span class=\"w\"> </span>furiosa-smi<span class=\"w\"> </span>info<span class=\"w\"> </span>--format<span class=\"w\"> </span>full\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>Arch<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Device<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>UUID<span class=\"w\">                                 </span><span class=\"p\">|</span><span class=\"w\"> </span>S/N<span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span>Firmware<span class=\"w\">       </span><span class=\"p\">|</span><span class=\"w\"> </span>Temp.<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>Power<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>Clock<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>PCI-BDF<span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\"> </span>PCI-DEV<span class=\"w\"> </span><span class=\"p\">|</span>\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu0<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>3E93AE7C-E8EA-4C62-BED6-AD2EC0461AE8<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>RNGDXXXXXX<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span>.0.15+af1daaa<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">30</span>.18°C<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">53</span>.00<span class=\"w\"> </span>W<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\">   </span>N/A<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0000</span>:17:00.0<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">508</span>:0<span class=\"w\">   </span><span class=\"p\">|</span>\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu1<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>176DAD0F-1510-475C-91D8-5F79551CF718<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>RNGDXXXXXY<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span>.0.15+af1daaa<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">29</span>.44°C<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">53</span>.00<span class=\"w\"> </span>W<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\">   </span>N/A<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0000</span>:2a:00.0<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">506</span>:0<span class=\"w\">   </span><span class=\"p\">|</span>\\n+------+--------+--------------------------------------+------------+----------------+---------+---------+-------+--------------+---------+\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"furiosa-smi-status\">\\n       <h3>\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n         <span class=\"pre\">\\n          status\\n         </span>\\n        </code>\\n        <a class=\"headerlink\" href=\"#furiosa-smi-status\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          status\\n         </span>\\n        </code>\\n        subcommand provides information about the device files available on the NPU device.\\nYou can also check whether each core present in the NPU is in use or idle.\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>$<span class=\"w\"> </span>furiosa-smi<span class=\"w\"> </span>status\\n+------+--------+---------------+------------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>Arch<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Device<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Cores<span class=\"w\">         </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span>Utilization<span class=\"w\"> </span><span class=\"p\">|</span>\\n+------+--------+---------------+------------------+\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">0</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">1</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">2</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">2</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu0<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">3</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">3</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">4</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">5</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">5</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">6</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">6</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">7</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span><span class=\"w\">  </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">7</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%<span class=\"w\">    </span><span class=\"p\">|</span>\\n+------+--------+---------------+------------------+\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">0</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">1</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">1</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">2</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">2</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\"> </span>rngd<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu1<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">3</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">3</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">4</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">4</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">5</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">5</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">6</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span>,<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">6</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%,<span class=\"w\">   </span><span class=\"p\">|</span>\\n<span class=\"p\">|</span><span class=\"w\">      </span><span class=\"p\">|</span><span class=\"w\">        </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">7</span><span class=\"w\"> </span><span class=\"o\">(</span>occupied<span class=\"o\">)</span><span class=\"w\">  </span><span class=\"p\">|</span><span class=\"w\"> </span>Core<span class=\"w\"> </span><span class=\"m\">7</span>:<span class=\"w\"> </span><span class=\"m\">0</span>.00%<span class=\"w\">    </span><span class=\"p\">|</span>\\n+------+--------+---------------+------------------+\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"furiosa-smi-ps\">\\n       <h3>\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n         <span class=\"pre\">\\n          ps\\n         </span>\\n        </code>\\n        <a class=\"headerlink\" href=\"#furiosa-smi-ps\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          ps\\n         </span>\\n        </code>\\n        subcommand prints information about the OS process currently occupying the NPU device.\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>$<span class=\"w\"> </span>furiosa-smi<span class=\"w\"> </span>ps\\n+-----------+--------+------------------------------------------------------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>NPU<span class=\"w\">       </span><span class=\"p\">|</span><span class=\"w\"> </span>PID<span class=\"w\">    </span><span class=\"p\">|</span><span class=\"w\"> </span>CMD<span class=\"w\">                                                        </span><span class=\"p\">|</span>\\n+-----------+--------+------------------------------------------------------------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>npu0pe0-3<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">132529</span><span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>/usr/bin/python3<span class=\"w\"> </span>/usr/local/bin/uvicorn<span class=\"w\"> </span>gptj:app<span class=\"w\">           </span><span class=\"p\">|</span>\\n+-----------+--------+------------------------------------------------------------+\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"furiosa-smi-topo\">\\n       <h3>\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          furiosa-smi\\n         </span>\\n         <span class=\"pre\">\\n          topo\\n         </span>\\n        </code>\\n        <a class=\"headerlink\" href=\"#furiosa-smi-topo\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          topo\\n         </span>\\n        </code>\\n        subcommand shows the topology of the NPU device and its NUMA node.\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>$<span class=\"w\"> </span>furiosa-smi<span class=\"w\"> </span>topo\\n+--------+--------------+--------------+-----------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>Device<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>npu0<span class=\"w\">         </span><span class=\"p\">|</span><span class=\"w\"> </span>npu1<span class=\"w\">         </span><span class=\"p\">|</span><span class=\"w\"> </span>NUMA<span class=\"w\"> </span>node<span class=\"w\"> </span><span class=\"p\">|</span>\\n+--------+--------------+--------------+-----------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>npu0<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>Noc<span class=\"w\">          </span><span class=\"p\">|</span><span class=\"w\"> </span>Interconnect<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span><span class=\"w\">         </span><span class=\"p\">|</span>\\n+--------+--------------+--------------+-----------+\\n<span class=\"p\">|</span><span class=\"w\"> </span>npu1<span class=\"w\">   </span><span class=\"p\">|</span><span class=\"w\"> </span>Interconnect<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>Noc<span class=\"w\">          </span><span class=\"p\">|</span><span class=\"w\"> </span><span class=\"m\">0</span><span class=\"w\">         </span><span class=\"p\">|</span>\\n+--------+--------------+--------------+-----------+\\n\\nLegend:\\n\\n<span class=\"w\">  </span><span class=\"nv\">Noc</span><span class=\"w\">          </span><span class=\"o\">=</span><span class=\"w\"> </span>Connection<span class=\"w\"> </span>within<span class=\"w\"> </span>the<span class=\"w\"> </span>same<span class=\"w\"> </span>npu<span class=\"w\"> </span>chip\\n<span class=\"w\">  </span><span class=\"nv\">Bridge</span><span class=\"w\">       </span><span class=\"o\">=</span><span class=\"w\"> </span>Devices<span class=\"w\"> </span>communicating<span class=\"w\"> </span>via<span class=\"w\"> </span>one<span class=\"w\"> </span>or<span class=\"w\"> </span>more<span class=\"w\"> </span>PCIe<span class=\"w\"> </span>switches\\n<span class=\"w\">  </span><span class=\"nv\">Cpu</span><span class=\"w\">          </span><span class=\"o\">=</span><span class=\"w\"> </span>Devices<span class=\"w\"> </span>communicating<span class=\"w\"> </span>exclusively<span class=\"w\"> </span>within<span class=\"w\"> </span>a<span class=\"w\"> </span>single<span class=\"w\"> </span>CPU<span class=\"w\"> </span>socket\\n<span class=\"w\">  </span><span class=\"nv\">Interconnect</span><span class=\"w\"> </span><span class=\"o\">=</span><span class=\"w\"> </span>Devices<span class=\"w\"> </span>communicating<span class=\"w\"> </span>via<span class=\"w\"> </span>inter-socket<span class=\"w\"> </span>links<span class=\"w\"> </span><span class=\"o\">(</span>e.g.,<span class=\"w\"> </span>QPI,<span class=\"w\"> </span>GMI<span class=\"o\">)</span>\\n<span class=\"w\">  </span><span class=\"nv\">Unknown</span><span class=\"w\">      </span><span class=\"o\">=</span><span class=\"w\"> </span>Connection<span class=\"w\"> </span><span class=\"nb\">type</span><span class=\"w\"> </span>is<span class=\"w\"> </span>unidentified\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../cloud_native_toolkit/intro.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Cloud Native Toolkit\\n       </p>\\n      </div>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#installing-furiosa-smi-command\">\\n         Installing\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           furiosa-smi\\n          </span>\\n         </code>\\n         command\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#synopsis\">\\n           Synopsis\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa-smi-info\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             furiosa-smi\\n            </span>\\n            <span class=\"pre\">\\n             info\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa-smi-status\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             furiosa-smi\\n            </span>\\n            <span class=\"pre\">\\n             status\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa-smi-ps\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             furiosa-smi\\n            </span>\\n            <span class=\"pre\">\\n             ps\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa-smi-topo\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             furiosa-smi\\n            </span>\\n            <span class=\"pre\">\\n             topo\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='e08e3845-eb5a-4b6f-8530-fb63f81ef7d0', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/references/llm.html'), name='llm', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/furiosa_llm/references/llm.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nLLM class\\n=========\\n\\n\\nContents\\n--------\\n\\n\\n* [`LLM`](#furiosa_llm.LLM)\\n  + [`LLM.generate()`](#furiosa_llm.LLM.generate)\\n  + [`LLM.get_splitted_gms()`](#furiosa_llm.LLM.get_splitted_gms)\\n\\n\\n\\n\\n\\nLLM class\\n[#](#llm-class \"Link to this heading\")\\n================================================\\n\\n*class*\\nfuriosa\\\\_llm.\\n\\n\\nLLM\\n\\n\\n(\\n\\n*pretrained\\\\_id\\n\\n\\n:\\n\\n\\n\\nstr*\\n,\\n*task\\\\_type\\n\\n\\n:\\n\\n\\n\\nstr\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*llm\\\\_config\\n\\n\\n:\\n\\n\\n\\nLLMConfig\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*qformat\\\\_path\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*qparam\\\\_path\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*prefill\\\\_quant\\\\_bin\\\\_path\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*decode\\\\_quant\\\\_bin\\\\_path\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*config\\n\\n\\n:\\n\\n\\n\\nDict\\n\\n[\\n\\n\\nstr\\n\\n,\\n\\n\\n\\nAny\\n\\n]\\n\\n\\n\\n\\n=\\n\\n\\n\\n{}*\\n,\\n*bucket\\\\_config\\n\\n\\n:\\n\\n\\n\\nBucketConfig\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*max\\\\_seq\\\\_len\\\\_to\\\\_capture\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n2048*\\n,\\n*tensor\\\\_parallel\\\\_size\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n4*\\n,\\n*pipeline\\\\_parallel\\\\_size\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*data\\\\_parallel\\\\_size\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*tokenizer\\n\\n\\n:\\n\\n\\n\\nPreTrainedTokenizer\\n\\n\\n|\\n\\n\\n\\nPreTrainedTokenizerFast\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*tokenizer\\\\_mode\\n\\n\\n:\\n\\n\\n\\nLiteral\\n\\n[\\n\\n\\n\\'auto\\'\\n\\n\\n,\\n\\n\\n\\n\\'slow\\'\\n\\n\\n]\\n\\n\\n\\n\\n=\\n\\n\\n\\n\\'auto\\'*\\n,\\n*seed\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*devices\\n\\n\\n:\\n\\n\\n\\nstr\\n\\n\\n|\\n\\n\\n\\nSequence\\n\\n[\\n\\n\\nDevice\\n\\n]\\n\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*param\\\\_file\\\\_path\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*param\\\\_saved\\\\_format\\n\\n\\n:\\n\\n\\n\\nLiteral\\n\\n[\\n\\n\\n\\'safetensors\\'\\n\\n\\n,\\n\\n\\n\\n\\'pt\\'\\n\\n\\n]\\n\\n\\n\\n\\n=\\n\\n\\n\\n\\'safetensors\\'*\\n,\\n*do\\\\_decompositions\\\\_for\\\\_model\\\\_rewrite\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*comp\\\\_supertask\\\\_kind\\n\\n\\n:\\n\\n\\n\\nLiteral\\n\\n[\\n\\n\\n\\'edf\\'\\n\\n\\n,\\n\\n\\n\\n\\'dfg\\'\\n\\n\\n,\\n\\n\\n\\n\\'fx\\'\\n\\n\\n]\\n\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*cache\\\\_dir\\n\\n\\n:\\n\\n\\n\\nPathLike\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nPosixPath(\\'/home/hyunsik/.cache/furiosa/llm\\')*\\n,\\n*backend\\n\\n\\n:\\n\\n\\n\\nLLMBackend\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*use\\\\_blockwise\\\\_compile\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nTrue*\\n,\\n*num\\\\_blocks\\\\_per\\\\_supertask\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*embed\\\\_all\\\\_constants\\\\_into\\\\_graph\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*paged\\\\_attention\\\\_num\\\\_blocks\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*paged\\\\_attention\\\\_block\\\\_size\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*kv\\\\_cache\\\\_sharing\\\\_across\\\\_beams\\\\_config\\n\\n\\n:\\n\\n\\n\\nKvCacheSharingAcrossBeamsConfig\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*scheduler\\\\_config\\n\\n\\n:\\n\\n\\n\\nSchedulerConfig\\n\\n\\n\\n=\\n\\n\\n\\nSchedulerConfig(npu\\\\_queue\\\\_limit=2,\\n\\nmax\\\\_processing\\\\_samples=65536,\\n\\nspare\\\\_blocks\\\\_ratio=0.2,\\n\\nis\\\\_offline=False)*\\n,\\n*packing\\\\_type\\n\\n\\n:\\n\\n\\n\\nLiteral\\n\\n[\\n\\n\\n\\'IDENTITY\\'\\n\\n\\n]\\n\\n\\n\\n\\n=\\n\\n\\n\\n\\'IDENTITY\\'*\\n,\\n*compiler\\\\_config\\\\_overrides\\n\\n\\n:\\n\\n\\n\\nMapping\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n\\n\\n=\\n\\n\\n\\nNone*\\n,\\n*use\\\\_random\\\\_weight\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*num\\\\_pipeline\\\\_builder\\\\_workers\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*num\\\\_compile\\\\_workers\\n\\n\\n:\\n\\n\\n\\nint\\n\\n\\n\\n=\\n\\n\\n\\n1*\\n,\\n*skip\\\\_engine\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n,\\n*\\\\**\\n,\\n*\\\\_cleanup\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nTrue*\\n,\\n*\\\\*\\\\*\\n\\n\\nkwargs*\\n)\\n\\n[[source]](../../_modules/furiosa_llm/api.html#LLM)\\n[#](#furiosa_llm.LLM \"Link to this definition\")\\n\\nBases:\\n`object`\\n\\nAn LLM for generating texts from given prompts and sampling parameters.\\n\\nParameters\\n:\\n\\n\\n* **pretrained\\\\_id**\\n  – The name of the pretrained model. This corresponds to\\n  pretrained\\\\_model\\\\_name\\\\_or\\\\_path in HuggingFace Transformers.\\n* **task\\\\_type**\\n  – The type of the task. This corresponds to task in HuggingFace Transformers.\\n  See\\n  <https://huggingface.co/docs/transformers/main/en/quicktour#pipeline>\\n  for more\\n  details.\\n* **llm\\\\_config**\\n  – The configuration for the LLM. This includes quantization and optimization\\n  configurations.\\n* **qformat\\\\_path**\\n  – The path to the quantization format file.\\n* **qparam\\\\_path**\\n  – The path to the quantization parameter file.\\n* **prefill\\\\_quant\\\\_bin\\\\_path**\\n  – The path to the quantziation prefill bin file.\\n* **decode\\\\_quant\\\\_bin\\\\_path**\\n  – The path to the quantziation decode bin file.\\n* **config**\\n  – The configuration for the HuggingFace Transformers model. This is a dictionary\\n  that includes the configuration for the model.\\n* **bucket\\\\_config**\\n  – Config for bucket generating policy. If not given, the model will use single one batch,\\n  max\\\\_seq\\\\_len\\\\_to\\\\_capture\\n  \\n  attention size bucket per\\n  each phase.\\n* **max\\\\_seq\\\\_len\\\\_to\\\\_capture**\\n  – Maximum sequence length covered by LLM engine. Sequence with larger context than this will not be covered.\\n  The default is 2048.\\n* **tensor\\\\_parallel\\\\_size**\\n  – The number of PEs for each tensor parallelism group. The default is 4.\\n* **pipeline\\\\_parallel\\\\_size**\\n  – The number of pipeline stages for pipeline parallelism. The default is 1,\\n  which means no pipeline parallelism.\\n* **data\\\\_parallel\\\\_size**\\n  – The size of the data parallelism group. If not given, it will be inferred from\\n  total avaialble PEs and other parallelism degrees.\\n* **tokenizer**\\n  – The name or path of a HuggingFace Transformers tokenizer.\\n* **tokenizer\\\\_mode**\\n  – The tokenizer mode. “auto” will use the fast tokenizer\\n  if available, and “slow” will always use the slow tokenizer.\\n* **seed**\\n  – The seed to initialize the random number generator for sampling.\\n* **devices**\\n  – The devices to run the model. It can be a single device or a list of devices.\\n  Each device can be either “cpu:X” or “cuda:X” where X is a specific device index.\\n  The default is “cpu:0”.\\n* **param\\\\_file\\\\_path**\\n  – The path to the parameter file to use for pipeline generation.\\n  If not specified, the parameters will be saved in a temporary file which will be\\n  used for pipeline generation.\\n* **param\\\\_saved\\\\_format**\\n  – The format of the parameter file. Only possible value is “safetensors” now.\\n  The default is “safetensors”.\\n* **do\\\\_decompositions\\\\_for\\\\_model\\\\_rewrite**\\n  – Whether to decompose some ops to describe various parallelism strategies\\n  with mppp config. When the value is True, mppp config that matches with the decomposed FX graph should be given.\\n* **comp\\\\_supertask\\\\_kind**\\n  – The format that pipeline’s supertask will be represented as.\\n  Possible values are “fx”,”dfg”, and “edf”, and the default is “fx”.\\n* **cache\\\\_dir**\\n  – The cache directory for all generated files for this LLM instance.\\n  When its value is\\n  `None`\\n  , caching is disabled. The default is “$HOME/.cache/furiosa/llm”.\\n* **backend**\\n  – The backend implementation to run forward() of a model for the LLM.\\n  The default is LLMBackend.TORCH\\\\_PIPELINE\\\\_RUNNER.\\n* **use\\\\_blockwise\\\\_compile**\\n  – If True, each task will be compiled in the unit of transformer block,\\n  and compilation result for transformer block is generated once and reused.\\n* **num\\\\_blocks\\\\_per\\\\_supertask**\\n  – The number of transformer blocks that will be merged into one supertask. This option is valid\\n  only when\\n  use\\\\_blockwise\\\\_compile=True\\n  \\n  . The default is 1.\\n* **embed\\\\_all\\\\_constants\\\\_into\\\\_graph**\\n  – Whether to embed constant tensors into graph or make them as input of the graph and save them as separate files.\\n* **paged\\\\_attention\\\\_num\\\\_blocks**\\n  – The maximum number of blocks that each k/v storage per layer can store. This argument must be given\\n  if model uses paged attention.\\n* **paged\\\\_attention\\\\_block\\\\_size**\\n  – The maximum number of tokens that can be stored in a single paged attention block. This argument must be given\\n  if model uses paged attention.\\n* **kv\\\\_cache\\\\_sharing\\\\_across\\\\_beams\\\\_config**\\n  – Configuration for sharing kv cache across beams. This argument must be given if and only if\\n  the model is optimized to share kv cache across beams. If this argument is given, decode phase buckets with batch size of\\n  `batch_size`\\n  \\\\*\\n  `kv_cache_sharing_across_beams_config.beam_width`\\n  will be created.\\n* **scheduler\\\\_config**\\n  – Configuration for the scheduler, allowing to maximum number of tasks which can be queued to HW, maximum number of samples\\n  that can be processed by the scheduler, and ratio of spare blocks that are reserved by scheduler.\\n* **packing\\\\_type**\\n  – Packing algorithm. Possible values are “IDENTITY” only for now\\n* **compiler\\\\_config\\\\_overrides**\\n  – Overrides for the compiler config. This is a dictionary that includes the configuration for the compiler.\\n* **use\\\\_random\\\\_weight**\\n  – If True, the model will be initialized with random weights.\\n* **num\\\\_pipeline\\\\_builder\\\\_workers**\\n  – number of workers used for building pipelines (except for compilation). The default is 1 (no parallelism).\\n  Setting this value larger than 1 reduces pipeline building time, especially for large models, but requires much more memory.\\n* **num\\\\_compile\\\\_workers**\\n  – number of workers used for compilation. The default is 1 (no parallelism).\\n* **skip\\\\_engine**\\n  – If True, the native runtime engine will not be initialized. This is useful when you need\\n  the pipelines for other purposes than running them with the engine.\\n\\n\\ngenerate\\n\\n\\n(\\n\\n*prompts:\\n\\nstr\\n\\n|\\n\\n~typing.List[str],\\n\\nsampling\\\\_params:\\n\\n~furiosa\\\\_llm.sampling\\\\_params.SamplingParams\\n\\n=\\n\\nSamplingParams(n=1,\\n\\nbest\\\\_of=1,\\n\\ntemperature=1.0,\\n\\ntop\\\\_p=1.0,\\n\\ntop\\\\_k=-1,\\n\\nuse\\\\_beam\\\\_search=False,\\n\\nlength\\\\_penalty=1.0,\\n\\nearly\\\\_stopping=False,\\n\\nmax\\\\_tokens=16min\\\\_tokens=0,\\n\\n,\\n\\nprompt\\\\_token\\\\_ids:\\n\\n~typing.List[int]\\n\\n|\\n\\n~typing.List[~typing.List[int]]\\n\\n|\\n\\nNone\\n\\n=\\n\\nNone*\\n)\\n\\n→\\n\\nRequestOutput\\n\\n\\n|\\n\\n\\n\\nList\\n\\n[\\n\\n\\nRequestOutput\\n\\n]\\n\\n\\n\\n\\n[[source]](../../_modules/furiosa_llm/api.html#LLM.generate)\\n[#](#furiosa_llm.LLM.generate \"Link to this definition\")\\n\\nGenerate texts from given prompts and sampling parameters.\\n\\nParameters\\n:\\n\\n\\n* **prompts**\\n  – The prompts to generate texts.\\n* **sampling\\\\_params**\\n  – The sampling parameters for generating texts.\\n* **prompt\\\\_token\\\\_ids**\\n  – The token ids of the prompts. If not given, the token ids are\\n  generated from the prompts using the tokenizer.\\n\\nReturns\\n:\\n\\n\\nA list of\\nRequestOutput\\n\\nobjects containing the generated\\ncompletions in the same order as the input prompts.\\n\\n\\n\\n\\n\\nget\\\\_splitted\\\\_gms\\n\\n\\n(\\n\\n*get\\\\_input\\\\_constants\\n\\n\\n:\\n\\n\\n\\nbool\\n\\n\\n\\n=\\n\\n\\n\\nFalse*\\n)\\n\\n→\\n\\nDict\\n\\n[\\n\\n\\nstr\\n\\n,\\n\\n\\n\\nTuple\\n\\n[\\n\\n\\nGraphModule\\n\\n,\\n\\n\\n\\n...\\n\\n\\n]\\n\\n\\n\\n|\\n\\n\\n\\nTuple\\n\\n[\\n\\n\\nTuple\\n\\n[\\n\\n\\nGraphModule\\n\\n,\\n\\n\\n\\nTuple\\n\\n[\\n\\n\\nTensor\\n\\n\\n|\\n\\n\\n\\nNone\\n\\n,\\n\\n\\n\\n...\\n\\n\\n]\\n\\n\\n]\\n\\n\\n,\\n\\n\\n\\n...\\n\\n\\n]\\n\\n\\n]\\n\\n\\n\\n\\n[[source]](../../_modules/furiosa_llm/api.html#LLM.get_splitted_gms)\\n[#](#furiosa_llm.LLM.get_splitted_gms \"Link to this definition\")\\n\\nGet sub GraphModules for each pipeline.\\n\\nReturns\\n:\\n\\n\\nDictionary whose key is the pipeline name and value is the tuple containing\\n`GraphModule``s\\n\\n(computation\\n\\nsupertasks)\\n\\nand\\n\\nsome\\n\\nadditional\\n\\ninformation\\n\\nif\\n\\nnecessary.\\n\\nif\\n\\n``get_input_constants==False`\\n, each value is just a tuple of\\n`GraphModule``s\\n\\nin\\n\\nthe\\n\\npipeline.\\n\\nOtherwise,\\n\\neach\\n\\nvalue\\n\\nis\\n\\na\\n\\ntuple\\n\\nwhose\\n\\nelement\\n\\nis\\n\\n``GraphModule`\\nin the pipeline and list of input constant tensors,\\nwhich were originally constant tensors, but converted to input. The list of input constant tensors has same length as corresponding\\n`GraphModule`\\n’s number of inputs\\nwith each element exactly corresponding to the input of the\\n`GraphModule`\\nwith same index, but elements with original input tensor indexes are\\n`None`\\n.\\n\\n\\nReturn type\\n:\\n\\n\\nDict[str, Union[Tuple[GraphModule, …], Tuple[Tuple[GraphModule, Tuple[Optional[torch.Tensor], …]], …],],]\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nReferences](../references.html \"previous page\")\\n[next\\n\\nSamplingParams](sampling_params.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [`LLM`](#furiosa_llm.LLM)\\n  + [`LLM.generate()`](#furiosa_llm.LLM.generate)\\n  + [`LLM.get_splitted_gms()`](#furiosa_llm.LLM.get_splitted_gms)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/furiosa_llm/references/llm.rst \"Download source file\") * .pdf\\nLLM class =========\\nContents --------\\n* [`LLM`](#furiosa_llm.LLM)   + [`LLM.generate()`](#furiosa_llm.LLM.generate)   + [`LLM.get_splitted_gms()`](#furiosa_llm.LLM.get_splitted_gms)\\nLLM class [#](#llm-class \"Link to this heading\") ================================================\\n*class* furiosa\\\\_llm.\\nLLM\\n(\\n*pretrained\\\\_id\\n:\\nstr* ,\\n*task\\\\_type\\n:\\nstr\\n|\\nNone\\n=\\nNone* ,\\n*llm\\\\_config\\n:\\nLLMConfig\\n|\\nNone\\n=\\nNone* ,\\n*qformat\\\\_path\\n:\\nPathLike\\n|\\nNone\\n=\\nNone* ,\\n*qparam\\\\_path\\n:\\nPathLike\\n|\\nNone\\n=\\nNone* ,\\n*prefill\\\\_quant\\\\_bin\\\\_path\\n:\\nPathLike\\n|\\nNone\\n=\\nNone* ,\\n*decode\\\\_quant\\\\_bin\\\\_path\\n:\\nPathLike\\n|\\nNone\\n=\\nNone* ,\\n*config\\n:\\nDict\\n[\\nstr\\n,\\nAny\\n]\\n=\\n{}* ,\\n*bucket\\\\_config\\n:\\nBucketConfig\\n|\\nNone\\n=\\nNone* ,\\n*max\\\\_seq\\\\_len\\\\_to\\\\_capture\\n:\\nint\\n=\\n2048* ,\\n*tensor\\\\_parallel\\\\_size\\n:\\nint\\n=\\n4* ,\\n*pipeline\\\\_parallel\\\\_size\\n:\\nint\\n=\\n1* ,\\n*data\\\\_parallel\\\\_size\\n:\\nint\\n|\\nNone\\n=\\nNone* ,\\n*tokenizer\\n:\\nPreTrainedTokenizer\\n|\\nPreTrainedTokenizerFast\\n|\\nNone\\n=\\nNone* ,\\n*tokenizer\\\\_mode\\n:\\nLiteral\\n[\\n\\'auto\\'\\n,\\n\\'slow\\'\\n]\\n=\\n\\'auto\\'* ,\\n*seed\\n:\\nint\\n|\\nNone\\n=\\nNone* ,\\n*devices\\n:\\nstr\\n|\\nSequence\\n[\\nDevice\\n]\\n|\\nNone\\n=\\nNone* ,\\n*param\\\\_file\\\\_path\\n:\\nPathLike\\n|\\nNone\\n=\\nNone* ,\\n*param\\\\_saved\\\\_format\\n:\\nLiteral\\n[\\n\\'safetensors\\'\\n,\\n\\'pt\\'\\n]\\n=\\n\\'safetensors\\'* ,\\n*do\\\\_decompositions\\\\_for\\\\_model\\\\_rewrite\\n:\\nbool\\n=\\nFalse* ,\\n*comp\\\\_supertask\\\\_kind\\n:\\nLiteral\\n[\\n\\'edf\\'\\n,\\n\\'dfg\\'\\n,\\n\\'fx\\'\\n]\\n|\\nNone\\n=\\nNone* ,\\n*cache\\\\_dir\\n:\\nPathLike\\n|\\nNone\\n=\\nPosixPath(\\'/home/hyunsik/.cache/furiosa/llm\\')* ,\\n*backend\\n:\\nLLMBackend\\n|\\nNone\\n=\\nNone* ,\\n*use\\\\_blockwise\\\\_compile\\n:\\nbool\\n=\\nTrue* ,\\n*num\\\\_blocks\\\\_per\\\\_supertask\\n:\\nint\\n=\\n1* ,\\n*embed\\\\_all\\\\_constants\\\\_into\\\\_graph\\n:\\nbool\\n=\\nFalse* ,\\n*paged\\\\_attention\\\\_num\\\\_blocks\\n:\\nint\\n|\\nNone\\n=\\nNone* ,\\n*paged\\\\_attention\\\\_block\\\\_size\\n:\\nint\\n=\\n1* ,\\n*kv\\\\_cache\\\\_sharing\\\\_across\\\\_beams\\\\_config\\n:\\nKvCacheSharingAcrossBeamsConfig\\n|\\nNone\\n=\\nNone* ,\\n*scheduler\\\\_config\\n:\\nSchedulerConfig\\n=\\nSchedulerConfig(npu\\\\_queue\\\\_limit=2,\\nmax\\\\_processing\\\\_samples=65536,\\nspare\\\\_blocks\\\\_ratio=0.2,\\nis\\\\_offline=False)* ,\\n*packing\\\\_type\\n:\\nLiteral\\n[\\n\\'IDENTITY\\'\\n]\\n=\\n\\'IDENTITY\\'* ,\\n*compiler\\\\_config\\\\_overrides\\n:\\nMapping\\n|\\nNone\\n=\\nNone* ,\\n*use\\\\_random\\\\_weight\\n:\\nbool\\n=\\nFalse* ,\\n*num\\\\_pipeline\\\\_builder\\\\_workers\\n:\\nint\\n=\\n1* ,\\n*num\\\\_compile\\\\_workers\\n:\\nint\\n=\\n1* ,\\n*skip\\\\_engine\\n:\\nbool\\n=\\nFalse* ,\\n*\\\\** ,\\n*\\\\_cleanup\\n:\\nbool\\n=\\nTrue* ,\\n*\\\\*\\\\*\\nkwargs* )\\n[[source]](../../_modules/furiosa_llm/api.html#LLM) [#](#furiosa_llm.LLM \"Link to this definition\")\\nBases: `object`  An LLM for generating texts from given prompts and sampling parameters.\\nParameters :\\n* **pretrained\\\\_id**   – The name of the pretrained model. This corresponds to   pretrained\\\\_model\\\\_name\\\\_or\\\\_path in HuggingFace Transformers. * **task\\\\_type**   – The type of the task. This corresponds to task in HuggingFace Transformers.   See   <https://huggingface.co/docs/transformers/main/en/quicktour#pipeline>   for more   details. * **llm\\\\_config**   – The configuration for the LLM. This includes quantization and optimization   configurations. * **qformat\\\\_path**   – The path to the quantization format file. * **qparam\\\\_path**   – The path to the quantization parameter file. * **prefill\\\\_quant\\\\_bin\\\\_path**   – The path to the quantziation prefill bin file. * **decode\\\\_quant\\\\_bin\\\\_path**   – The path to the quantziation decode bin file. * **config**   – The configuration for the HuggingFace Transformers model. This is a dictionary   that includes the configuration for the model. * **bucket\\\\_config**   – Config for bucket generating policy. If not given, the model will use single one batch,   max\\\\_seq\\\\_len\\\\_to\\\\_capture      attention size bucket per   each phase. * **max\\\\_seq\\\\_len\\\\_to\\\\_capture**   – Maximum sequence length covered by LLM engine. Sequence with larger context than this will not be covered.   The default is 2048. * **tensor\\\\_parallel\\\\_size**   – The number of PEs for each tensor parallelism group. The default is 4. * **pipeline\\\\_parallel\\\\_size**   – The number of pipeline stages for pipeline parallelism. The default is 1,   which means no pipeline parallelism. * **data\\\\_parallel\\\\_size**   – The size of the data parallelism group. If not given, it will be inferred from   total avaialble PEs and other parallelism degrees. * **tokenizer**   – The name or path of a HuggingFace Transformers tokenizer. * **tokenizer\\\\_mode**   – The tokenizer mode. “auto” will use the fast tokenizer   if available, and “slow” will always use the slow tokenizer. * **seed**   – The seed to initialize the random number generator for sampling. * **devices**   – The devices to run the model. It can be a single device or a list of devices.   Each device can be either “cpu:X” or “cuda:X” where X is a specific device index.   The default is “cpu:0”. * **param\\\\_file\\\\_path**   – The path to the parameter file to use for pipeline generation.   If not specified, the parameters will be saved in a temporary file which will be   used for pipeline generation. * **param\\\\_saved\\\\_format**   – The format of the parameter file. Only possible value is “safetensors” now.   The default is “safetensors”. * **do\\\\_decompositions\\\\_for\\\\_model\\\\_rewrite**   – Whether to decompose some ops to describe various parallelism strategies   with mppp config. When the value is True, mppp config that matches with the decomposed FX graph should be given. * **comp\\\\_supertask\\\\_kind**   – The format that pipeline’s supertask will be represented as.   Possible values are “fx”,”dfg”, and “edf”, and the default is “fx”. * **cache\\\\_dir**   – The cache directory for all generated files for this LLM instance.   When its value is   `None`   , caching is disabled. The default is “$HOME/.cache/furiosa/llm”. * **backend**   – The backend implementation to run forward() of a model for the LLM.   The default is LLMBackend.TORCH\\\\_PIPELINE\\\\_RUNNER. * **use\\\\_blockwise\\\\_compile**   – If True, each task will be compiled in the unit of transformer block,   and compilation result for transformer block is generated once and reused. * **num\\\\_blocks\\\\_per\\\\_supertask**   – The number of transformer blocks that will be merged into one supertask. This option is valid   only when   use\\\\_blockwise\\\\_compile=True      . The default is 1. * **embed\\\\_all\\\\_constants\\\\_into\\\\_graph**   – Whether to embed constant tensors into graph or make them as input of the graph and save them as separate files. * **paged\\\\_attention\\\\_num\\\\_blocks**   – The maximum number of blocks that each k/v storage per layer can store. This argument must be given   if model uses paged attention. * **paged\\\\_attention\\\\_block\\\\_size**   – The maximum number of tokens that can be stored in a single paged attention block. This argument must be given   if model uses paged attention. * **kv\\\\_cache\\\\_sharing\\\\_across\\\\_beams\\\\_config**   – Configuration for sharing kv cache across beams. This argument must be given if and only if   the model is optimized to share kv cache across beams. If this argument is given, decode phase buckets with batch size of   `batch_size`   \\\\*   `kv_cache_sharing_across_beams_config.beam_width`   will be created. * **scheduler\\\\_config**   – Configuration for the scheduler, allowing to maximum number of tasks which can be queued to HW, maximum number of samples   that can be processed by the scheduler, and ratio of spare blocks that are reserved by scheduler. * **packing\\\\_type**   – Packing algorithm. Possible values are “IDENTITY” only for now * **compiler\\\\_config\\\\_overrides**   – Overrides for the compiler config. This is a dictionary that includes the configuration for the compiler. * **use\\\\_random\\\\_weight**   – If True, the model will be initialized with random weights. * **num\\\\_pipeline\\\\_builder\\\\_workers**   – number of workers used for building pipelines (except for compilation). The default is 1 (no parallelism).   Setting this value larger than 1 reduces pipeline building time, especially for large models, but requires much more memory. * **num\\\\_compile\\\\_workers**   – number of workers used for compilation. The default is 1 (no parallelism). * **skip\\\\_engine**   – If True, the native runtime engine will not be initialized. This is useful when you need   the pipelines for other purposes than running them with the engine.\\ngenerate\\n(\\n*prompts:\\nstr\\n|\\n~typing.List[str],\\nsampling\\\\_params:\\n~furiosa\\\\_llm.sampling\\\\_params.SamplingParams\\n=\\nSamplingParams(n=1,\\nbest\\\\_of=1,\\ntemperature=1.0,\\ntop\\\\_p=1.0,\\ntop\\\\_k=-1,\\nuse\\\\_beam\\\\_search=False,\\nlength\\\\_penalty=1.0,\\nearly\\\\_stopping=False,\\nmax\\\\_tokens=16min\\\\_tokens=0,\\n,\\nprompt\\\\_token\\\\_ids:\\n~typing.List[int]\\n|\\n~typing.List[~typing.List[int]]\\n|\\nNone\\n=\\nNone* )\\n→\\nRequestOutput\\n|\\nList\\n[\\nRequestOutput\\n]\\n[[source]](../../_modules/furiosa_llm/api.html#LLM.generate) [#](#furiosa_llm.LLM.generate \"Link to this definition\")\\nGenerate texts from given prompts and sampling parameters.\\nParameters :\\n* **prompts**   – The prompts to generate texts. * **sampling\\\\_params**   – The sampling parameters for generating texts. * **prompt\\\\_token\\\\_ids**   – The token ids of the prompts. If not given, the token ids are   generated from the prompts using the tokenizer.\\nReturns :\\nA list of RequestOutput\\nobjects containing the generated completions in the same order as the input prompts.\\nget\\\\_splitted\\\\_gms\\n(\\n*get\\\\_input\\\\_constants\\n:\\nbool\\n=\\nFalse* )\\n→\\nDict\\n[\\nstr\\n,\\nTuple\\n[\\nGraphModule\\n,\\n...\\n]\\n|\\nTuple\\n[\\nTuple\\n[\\nGraphModule\\n,\\nTuple\\n[\\nTensor\\n|\\nNone\\n,\\n...\\n]\\n]\\n,\\n...\\n]\\n]\\n[[source]](../../_modules/furiosa_llm/api.html#LLM.get_splitted_gms) [#](#furiosa_llm.LLM.get_splitted_gms \"Link to this definition\")\\nGet sub GraphModules for each pipeline.\\nReturns :\\nDictionary whose key is the pipeline name and value is the tuple containing `GraphModule``s\\n(computation\\nsupertasks)\\nand\\nsome\\nadditional\\ninformation\\nif\\nnecessary.\\nif\\n``get_input_constants==False` , each value is just a tuple of `GraphModule``s\\nin\\nthe\\npipeline.\\nOtherwise,\\neach\\nvalue\\nis\\na\\ntuple\\nwhose\\nelement\\nis\\n``GraphModule` in the pipeline and list of input constant tensors, which were originally constant tensors, but converted to input. The list of input constant tensors has same length as corresponding `GraphModule` ’s number of inputs with each element exactly corresponding to the input of the `GraphModule` with same index, but elements with original input tensor indexes are `None` .\\nReturn type :\\nDict[str, Union[Tuple[GraphModule, …], Tuple[Tuple[GraphModule, Tuple[Optional[torch.Tensor], …]], …],],]\\n[previous\\nReferences](../references.html \"previous page\") [next\\nSamplingParams](sampling_params.html \"next page\")\\nContents\\n* [`LLM`](#furiosa_llm.LLM)   + [`LLM.generate()`](#furiosa_llm.LLM.generate)   + [`LLM.get_splitted_gms()`](#furiosa_llm.LLM.get_splitted_gms)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/furiosa_llm/references/llm.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     LLM class\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM\">\\n          <code class=\"docutils literal notranslate\">\\n           <span class=\"pre\">\\n            LLM\\n           </span>\\n          </code>\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM.generate\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              LLM.generate()\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM.get_splitted_gms\">\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              LLM.get_splitted_gms()\\n             </span>\\n            </code>\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"llm-class\">\\n     <h1>\\n      LLM class\\n      <a class=\"headerlink\" href=\"#llm-class\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <dl class=\"py class\">\\n      <dt class=\"sig sig-object py\" id=\"furiosa_llm.LLM\">\\n       <em class=\"property\">\\n        <span class=\"pre\">\\n         class\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n       </em>\\n       <span class=\"sig-prename descclassname\">\\n        <span class=\"pre\">\\n         furiosa_llm.\\n        </span>\\n       </span>\\n       <span class=\"sig-name descname\">\\n        <span class=\"pre\">\\n         LLM\\n        </span>\\n       </span>\\n       <span class=\"sig-paren\">\\n        (\\n       </span>\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          pretrained_id\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          str\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          task_type\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          str\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          llm_config\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          LLMConfig\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          qformat_path\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          qparam_path\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          prefill_quant_bin_path\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          decode_quant_bin_path\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          config\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Dict\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"pre\">\\n          str\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          Any\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          {}\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bucket_config\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          BucketConfig\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          max_seq_len_to_capture\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          2048\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          tensor_parallel_size\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          4\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          pipeline_parallel_size\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          data_parallel_size\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          tokenizer\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PreTrainedTokenizer\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          PreTrainedTokenizerFast\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          tokenizer_mode\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Literal\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'auto\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'slow\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          \\'auto\\'\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          seed\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          devices\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          str\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          Sequence\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"pre\">\\n          Device\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          param_file_path\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          param_saved_format\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Literal\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'safetensors\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'pt\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          \\'safetensors\\'\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          do_decompositions_for_model_rewrite\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          comp_supertask_kind\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Literal\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'edf\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'dfg\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'fx\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          cache_dir\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          PathLike\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          PosixPath(\\'/home/hyunsik/.cache/furiosa/llm\\')\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          backend\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          LLMBackend\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          use_blockwise_compile\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          True\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          num_blocks_per_supertask\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          embed_all_constants_into_graph\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          paged_attention_num_blocks\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          paged_attention_block_size\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          kv_cache_sharing_across_beams_config\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          KvCacheSharingAcrossBeamsConfig\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          scheduler_config\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          SchedulerConfig\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          SchedulerConfig(npu_queue_limit=2,\\n         </span>\\n         <span class=\"pre\">\\n          max_processing_samples=65536,\\n         </span>\\n         <span class=\"pre\">\\n          spare_blocks_ratio=0.2,\\n         </span>\\n         <span class=\"pre\">\\n          is_offline=False)\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          packing_type\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Literal\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           [\\n          </span>\\n         </span>\\n         <span class=\"s\">\\n          <span class=\"pre\">\\n           \\'IDENTITY\\'\\n          </span>\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           ]\\n          </span>\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          \\'IDENTITY\\'\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          compiler_config_overrides\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          Mapping\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"p\">\\n          <span class=\"pre\">\\n           |\\n          </span>\\n         </span>\\n         <span class=\"w\">\\n         </span>\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          None\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          use_random_weight\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          num_pipeline_builder_workers\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          num_compile_workers\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          int\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          1\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          skip_engine\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          False\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          *\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          _cleanup\\n         </span>\\n        </span>\\n        <span class=\"p\">\\n         <span class=\"pre\">\\n          :\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          bool\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          =\\n         </span>\\n        </span>\\n        <span class=\"w\">\\n        </span>\\n        <span class=\"default_value\">\\n         <span class=\"pre\">\\n          True\\n         </span>\\n        </span>\\n       </em>\\n       ,\\n       <em class=\"sig-param\">\\n        <span class=\"o\">\\n         <span class=\"pre\">\\n          **\\n         </span>\\n        </span>\\n        <span class=\"n\">\\n         <span class=\"pre\">\\n          kwargs\\n         </span>\\n        </span>\\n       </em>\\n       <span class=\"sig-paren\">\\n        )\\n       </span>\\n       <a class=\"reference internal\" href=\"../../_modules/furiosa_llm/api.html#LLM\">\\n        <span class=\"viewcode-link\">\\n         <span class=\"pre\">\\n          [source]\\n         </span>\\n        </span>\\n       </a>\\n       <a class=\"headerlink\" href=\"#furiosa_llm.LLM\" title=\"Link to this definition\">\\n        #\\n       </a>\\n      </dt>\\n      <dd>\\n       <p>\\n        Bases:\\n        <code class=\"xref py py-class docutils literal notranslate\">\\n         <span class=\"pre\">\\n          object\\n         </span>\\n        </code>\\n       </p>\\n       <p>\\n        An LLM for generating texts from given prompts and sampling parameters.\\n       </p>\\n       <dl class=\"field-list simple\">\\n        <dt class=\"field-odd\">\\n         Parameters\\n         <span class=\"colon\">\\n          :\\n         </span>\\n        </dt>\\n        <dd class=\"field-odd\">\\n         <ul class=\"simple\">\\n          <li>\\n           <p>\\n            <strong>\\n             pretrained_id\\n            </strong>\\n            – The name of the pretrained model. This corresponds to\\npretrained_model_name_or_path in HuggingFace Transformers.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             task_type\\n            </strong>\\n            – The type of the task. This corresponds to task in HuggingFace Transformers.\\nSee\\n            <a class=\"reference external\" href=\"https://huggingface.co/docs/transformers/main/en/quicktour#pipeline\">\\n             https://huggingface.co/docs/transformers/main/en/quicktour#pipeline\\n            </a>\\n            for more\\ndetails.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             llm_config\\n            </strong>\\n            – The configuration for the LLM. This includes quantization and optimization\\nconfigurations.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             qformat_path\\n            </strong>\\n            – The path to the quantization format file.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             qparam_path\\n            </strong>\\n            – The path to the quantization parameter file.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             prefill_quant_bin_path\\n            </strong>\\n            – The path to the quantziation prefill bin file.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             decode_quant_bin_path\\n            </strong>\\n            – The path to the quantziation decode bin file.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             config\\n            </strong>\\n            – The configuration for the HuggingFace Transformers model. This is a dictionary\\nthat includes the configuration for the model.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             bucket_config\\n            </strong>\\n            – Config for bucket generating policy. If not given, the model will use single one batch,\\n            <cite>\\n             max_seq_len_to_capture\\n            </cite>\\n            attention size bucket per\\neach phase.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             max_seq_len_to_capture\\n            </strong>\\n            – Maximum sequence length covered by LLM engine. Sequence with larger context than this will not be covered.\\nThe default is 2048.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             tensor_parallel_size\\n            </strong>\\n            – The number of PEs for each tensor parallelism group. The default is 4.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             pipeline_parallel_size\\n            </strong>\\n            – The number of pipeline stages for pipeline parallelism. The default is 1,\\nwhich means no pipeline parallelism.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             data_parallel_size\\n            </strong>\\n            – The size of the data parallelism group. If not given, it will be inferred from\\ntotal avaialble PEs and other parallelism degrees.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             tokenizer\\n            </strong>\\n            – The name or path of a HuggingFace Transformers tokenizer.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             tokenizer_mode\\n            </strong>\\n            – The tokenizer mode. “auto” will use the fast tokenizer\\nif available, and “slow” will always use the slow tokenizer.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             seed\\n            </strong>\\n            – The seed to initialize the random number generator for sampling.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             devices\\n            </strong>\\n            – The devices to run the model. It can be a single device or a list of devices.\\nEach device can be either “cpu:X” or “cuda:X” where X is a specific device index.\\nThe default is “cpu:0”.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             param_file_path\\n            </strong>\\n            – The path to the parameter file to use for pipeline generation.\\nIf not specified, the parameters will be saved in a temporary file which will be\\nused for pipeline generation.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             param_saved_format\\n            </strong>\\n            – The format of the parameter file. Only possible value is “safetensors” now.\\nThe default is “safetensors”.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             do_decompositions_for_model_rewrite\\n            </strong>\\n            – Whether to decompose some ops to describe various parallelism strategies\\nwith mppp config. When the value is True, mppp config that matches with the decomposed FX graph should be given.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             comp_supertask_kind\\n            </strong>\\n            – The format that pipeline’s supertask will be represented as.\\nPossible values are “fx”,”dfg”, and “edf”, and the default is “fx”.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             cache_dir\\n            </strong>\\n            – The cache directory for all generated files for this LLM instance.\\nWhen its value is\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              None\\n             </span>\\n            </code>\\n            , caching is disabled. The default is “$HOME/.cache/furiosa/llm”.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             backend\\n            </strong>\\n            – The backend implementation to run forward() of a model for the LLM.\\nThe default is LLMBackend.TORCH_PIPELINE_RUNNER.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             use_blockwise_compile\\n            </strong>\\n            – If True, each task will be compiled in the unit of transformer block,\\nand compilation result for transformer block is generated once and reused.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             num_blocks_per_supertask\\n            </strong>\\n            – The number of transformer blocks that will be merged into one supertask. This option is valid\\nonly when\\n            <cite>\\n             use_blockwise_compile=True\\n            </cite>\\n            . The default is 1.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             embed_all_constants_into_graph\\n            </strong>\\n            – Whether to embed constant tensors into graph or make them as input of the graph and save them as separate files.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             paged_attention_num_blocks\\n            </strong>\\n            – The maximum number of blocks that each k/v storage per layer can store. This argument must be given\\nif model uses paged attention.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             paged_attention_block_size\\n            </strong>\\n            – The maximum number of tokens that can be stored in a single paged attention block. This argument must be given\\nif model uses paged attention.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             kv_cache_sharing_across_beams_config\\n            </strong>\\n            – Configuration for sharing kv cache across beams. This argument must be given if and only if\\nthe model is optimized to share kv cache across beams. If this argument is given, decode phase buckets with batch size of\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              batch_size\\n             </span>\\n            </code>\\n            *\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              kv_cache_sharing_across_beams_config.beam_width\\n             </span>\\n            </code>\\n            will be created.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             scheduler_config\\n            </strong>\\n            – Configuration for the scheduler, allowing to maximum number of tasks which can be queued to HW, maximum number of samples\\nthat can be processed by the scheduler, and ratio of spare blocks that are reserved by scheduler.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             packing_type\\n            </strong>\\n            – Packing algorithm. Possible values are “IDENTITY” only for now\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             compiler_config_overrides\\n            </strong>\\n            – Overrides for the compiler config. This is a dictionary that includes the configuration for the compiler.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             use_random_weight\\n            </strong>\\n            – If True, the model will be initialized with random weights.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             num_pipeline_builder_workers\\n            </strong>\\n            – number of workers used for building pipelines (except for compilation). The default is 1 (no parallelism).\\nSetting this value larger than 1 reduces pipeline building time, especially for large models, but requires much more memory.\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             num_compile_workers\\n            </strong>\\n            – number of workers used for compilation. The default is 1 (no parallelism).\\n           </p>\\n          </li>\\n          <li>\\n           <p>\\n            <strong>\\n             skip_engine\\n            </strong>\\n            – If True, the native runtime engine will not be initialized. This is useful when you need\\nthe pipelines for other purposes than running them with the engine.\\n           </p>\\n          </li>\\n         </ul>\\n        </dd>\\n       </dl>\\n       <dl class=\"py method\">\\n        <dt class=\"sig sig-object py\" id=\"furiosa_llm.LLM.generate\">\\n         <span class=\"sig-name descname\">\\n          <span class=\"pre\">\\n           generate\\n          </span>\\n         </span>\\n         <span class=\"sig-paren\">\\n          (\\n         </span>\\n         <em class=\"sig-param\">\\n          <span class=\"pre\">\\n           prompts:\\n          </span>\\n          <span class=\"pre\">\\n           str\\n          </span>\\n          <span class=\"pre\">\\n           |\\n          </span>\\n          <span class=\"pre\">\\n           ~typing.List[str],\\n          </span>\\n          <span class=\"pre\">\\n           sampling_params:\\n          </span>\\n          <span class=\"pre\">\\n           ~furiosa_llm.sampling_params.SamplingParams\\n          </span>\\n          <span class=\"pre\">\\n           =\\n          </span>\\n          <span class=\"pre\">\\n           SamplingParams(n=1,\\n          </span>\\n          <span class=\"pre\">\\n           best_of=1,\\n          </span>\\n          <span class=\"pre\">\\n           temperature=1.0,\\n          </span>\\n          <span class=\"pre\">\\n           top_p=1.0,\\n          </span>\\n          <span class=\"pre\">\\n           top_k=-1,\\n          </span>\\n          <span class=\"pre\">\\n           use_beam_search=False,\\n          </span>\\n          <span class=\"pre\">\\n           length_penalty=1.0,\\n          </span>\\n          <span class=\"pre\">\\n           early_stopping=False,\\n          </span>\\n          <span class=\"pre\">\\n           max_tokens=16min_tokens=0,\\n          </span>\\n          <span class=\"pre\">\\n           ,\\n          </span>\\n          <span class=\"pre\">\\n           prompt_token_ids:\\n          </span>\\n          <span class=\"pre\">\\n           ~typing.List[int]\\n          </span>\\n          <span class=\"pre\">\\n           |\\n          </span>\\n          <span class=\"pre\">\\n           ~typing.List[~typing.List[int]]\\n          </span>\\n          <span class=\"pre\">\\n           |\\n          </span>\\n          <span class=\"pre\">\\n           None\\n          </span>\\n          <span class=\"pre\">\\n           =\\n          </span>\\n          <span class=\"pre\">\\n           None\\n          </span>\\n         </em>\\n         <span class=\"sig-paren\">\\n          )\\n         </span>\\n         <span class=\"sig-return\">\\n          <span class=\"sig-return-icon\">\\n           →\\n          </span>\\n          <span class=\"sig-return-typehint\">\\n           <span class=\"pre\">\\n            RequestOutput\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             |\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"pre\">\\n            List\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            RequestOutput\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n          </span>\\n         </span>\\n         <a class=\"reference internal\" href=\"../../_modules/furiosa_llm/api.html#LLM.generate\">\\n          <span class=\"viewcode-link\">\\n           <span class=\"pre\">\\n            [source]\\n           </span>\\n          </span>\\n         </a>\\n         <a class=\"headerlink\" href=\"#furiosa_llm.LLM.generate\" title=\"Link to this definition\">\\n          #\\n         </a>\\n        </dt>\\n        <dd>\\n         <p>\\n          Generate texts from given prompts and sampling parameters.\\n         </p>\\n         <dl class=\"field-list simple\">\\n          <dt class=\"field-odd\">\\n           Parameters\\n           <span class=\"colon\">\\n            :\\n           </span>\\n          </dt>\\n          <dd class=\"field-odd\">\\n           <ul class=\"simple\">\\n            <li>\\n             <p>\\n              <strong>\\n               prompts\\n              </strong>\\n              – The prompts to generate texts.\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              <strong>\\n               sampling_params\\n              </strong>\\n              – The sampling parameters for generating texts.\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              <strong>\\n               prompt_token_ids\\n              </strong>\\n              – The token ids of the prompts. If not given, the token ids are\\ngenerated from the prompts using the tokenizer.\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n          <dt class=\"field-even\">\\n           Returns\\n           <span class=\"colon\">\\n            :\\n           </span>\\n          </dt>\\n          <dd class=\"field-even\">\\n           <p>\\n            A list of\\n            <cite>\\n             RequestOutput\\n            </cite>\\n            objects containing the generated\\ncompletions in the same order as the input prompts.\\n           </p>\\n          </dd>\\n         </dl>\\n        </dd>\\n       </dl>\\n       <dl class=\"py method\">\\n        <dt class=\"sig sig-object py\" id=\"furiosa_llm.LLM.get_splitted_gms\">\\n         <span class=\"sig-name descname\">\\n          <span class=\"pre\">\\n           get_splitted_gms\\n          </span>\\n         </span>\\n         <span class=\"sig-paren\">\\n          (\\n         </span>\\n         <em class=\"sig-param\">\\n          <span class=\"n\">\\n           <span class=\"pre\">\\n            get_input_constants\\n           </span>\\n          </span>\\n          <span class=\"p\">\\n           <span class=\"pre\">\\n            :\\n           </span>\\n          </span>\\n          <span class=\"w\">\\n          </span>\\n          <span class=\"n\">\\n           <span class=\"pre\">\\n            bool\\n           </span>\\n          </span>\\n          <span class=\"w\">\\n          </span>\\n          <span class=\"o\">\\n           <span class=\"pre\">\\n            =\\n           </span>\\n          </span>\\n          <span class=\"w\">\\n          </span>\\n          <span class=\"default_value\">\\n           <span class=\"pre\">\\n            False\\n           </span>\\n          </span>\\n         </em>\\n         <span class=\"sig-paren\">\\n          )\\n         </span>\\n         <span class=\"sig-return\">\\n          <span class=\"sig-return-icon\">\\n           →\\n          </span>\\n          <span class=\"sig-return-typehint\">\\n           <span class=\"pre\">\\n            Dict\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            str\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ,\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"pre\">\\n            Tuple\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            GraphModule\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ,\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ...\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             |\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"pre\">\\n            Tuple\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            Tuple\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            GraphModule\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ,\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"pre\">\\n            Tuple\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             [\\n            </span>\\n           </span>\\n           <span class=\"pre\">\\n            Tensor\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             |\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"pre\">\\n            None\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ,\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ...\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ,\\n            </span>\\n           </span>\\n           <span class=\"w\">\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ...\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n           <span class=\"p\">\\n            <span class=\"pre\">\\n             ]\\n            </span>\\n           </span>\\n          </span>\\n         </span>\\n         <a class=\"reference internal\" href=\"../../_modules/furiosa_llm/api.html#LLM.get_splitted_gms\">\\n          <span class=\"viewcode-link\">\\n           <span class=\"pre\">\\n            [source]\\n           </span>\\n          </span>\\n         </a>\\n         <a class=\"headerlink\" href=\"#furiosa_llm.LLM.get_splitted_gms\" title=\"Link to this definition\">\\n          #\\n         </a>\\n        </dt>\\n        <dd>\\n         <p>\\n          Get sub GraphModules for each pipeline.\\n         </p>\\n         <dl class=\"field-list simple\">\\n          <dt class=\"field-odd\">\\n           Returns\\n           <span class=\"colon\">\\n            :\\n           </span>\\n          </dt>\\n          <dd class=\"field-odd\">\\n           <p>\\n            Dictionary whose key is the pipeline name and value is the tuple containing\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              GraphModule``s\\n             </span>\\n             <span class=\"pre\">\\n              (computation\\n             </span>\\n             <span class=\"pre\">\\n              supertasks)\\n             </span>\\n             <span class=\"pre\">\\n              and\\n             </span>\\n             <span class=\"pre\">\\n              some\\n             </span>\\n             <span class=\"pre\">\\n              additional\\n             </span>\\n             <span class=\"pre\">\\n              information\\n             </span>\\n             <span class=\"pre\">\\n              if\\n             </span>\\n             <span class=\"pre\">\\n              necessary.\\n             </span>\\n             <span class=\"pre\">\\n              if\\n             </span>\\n             <span class=\"pre\">\\n              ``get_input_constants==False\\n             </span>\\n            </code>\\n            , each value is just a tuple of\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              GraphModule``s\\n             </span>\\n             <span class=\"pre\">\\n              in\\n             </span>\\n             <span class=\"pre\">\\n              the\\n             </span>\\n             <span class=\"pre\">\\n              pipeline.\\n             </span>\\n             <span class=\"pre\">\\n              Otherwise,\\n             </span>\\n             <span class=\"pre\">\\n              each\\n             </span>\\n             <span class=\"pre\">\\n              value\\n             </span>\\n             <span class=\"pre\">\\n              is\\n             </span>\\n             <span class=\"pre\">\\n              a\\n             </span>\\n             <span class=\"pre\">\\n              tuple\\n             </span>\\n             <span class=\"pre\">\\n              whose\\n             </span>\\n             <span class=\"pre\">\\n              element\\n             </span>\\n             <span class=\"pre\">\\n              is\\n             </span>\\n             <span class=\"pre\">\\n              ``GraphModule\\n             </span>\\n            </code>\\n            in the pipeline  and list of input constant tensors,\\nwhich were originally constant tensors, but converted to input. The list of input constant tensors has same length as corresponding\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              GraphModule\\n             </span>\\n            </code>\\n            ’s number of inputs\\nwith each element exactly corresponding to the input of the\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              GraphModule\\n             </span>\\n            </code>\\n            with same index, but elements with original input tensor indexes are\\n            <code class=\"docutils literal notranslate\">\\n             <span class=\"pre\">\\n              None\\n             </span>\\n            </code>\\n            .\\n           </p>\\n          </dd>\\n          <dt class=\"field-even\">\\n           Return type\\n           <span class=\"colon\">\\n            :\\n           </span>\\n          </dt>\\n          <dd class=\"field-even\">\\n           <p>\\n            Dict[str, Union[Tuple[GraphModule, …], Tuple[Tuple[GraphModule, Tuple[Optional[torch.Tensor], …]], …],],]\\n           </p>\\n          </dd>\\n         </dl>\\n        </dd>\\n       </dl>\\n      </dd>\\n     </dl>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../references.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        References\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"sampling_params.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        SamplingParams\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM\">\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           LLM\\n          </span>\\n         </code>\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM.generate\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             LLM.generate()\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#furiosa_llm.LLM.get_splitted_gms\">\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             LLM.get_splitted_gms()\\n            </span>\\n           </code>\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='85efd72a-7fd9-4895-a0c7-090891c1e2cf', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/references.html'), name='references', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/furiosa_llm/references.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nReferences\\n==========\\n\\n\\n\\n\\n\\nReferences\\n[#](#references \"Link to this heading\")\\n==================================================\\n\\n\\nReferences\\n\\n\\n* [LLM class](references/llm.html)\\n* [SamplingParams](references/sampling_params.html)\\n\\n\\n\\n[previous\\n\\nOpenAI Compatible Server](furiosa-llm-serve.html \"previous page\")\\n[next\\n\\nLLM class](references/llm.html \"next page\")\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/furiosa_llm/references.rst \"Download source file\") * .pdf\\nReferences ==========\\nReferences [#](#references \"Link to this heading\") ==================================================\\nReferences\\n* [LLM class](references/llm.html) * [SamplingParams](references/sampling_params.html)\\n[previous\\nOpenAI Compatible Server](furiosa-llm-serve.html \"previous page\") [next\\nLLM class](references/llm.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/furiosa_llm/references.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     References\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"references\">\\n     <h1>\\n      References\\n      <a class=\"headerlink\" href=\"#references\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <div class=\"toctree-wrapper compound\">\\n      <p aria-level=\"2\" class=\"caption\" role=\"heading\">\\n       <span class=\"caption-text\">\\n        References\\n       </span>\\n      </p>\\n      <ul>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"references/llm.html\">\\n         LLM class\\n        </a>\\n       </li>\\n       <li class=\"toctree-l1\">\\n        <a class=\"reference internal\" href=\"references/sampling_params.html\">\\n         SamplingParams\\n        </a>\\n       </li>\\n      </ul>\\n     </div>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"furiosa-llm-serve.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        OpenAI Compatible Server\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"references/llm.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        LLM class\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='fe9686e2-f00f-4e68-87fa-80abbaf03e2b', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/kubernetes/metrics_exporter.html'), name='metrics_exporter', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/cloud_native_toolkit/kubernetes/metrics_exporter.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstalling Furiosa Metrics Exporter\\n===================================\\n\\n\\nContents\\n--------\\n\\n\\n* [Furiosa Metrics Exporter](#furiosa-metrics-exporter)\\n  + [Metrics](#metrics)\\n  + [Deploying Furiosa Metrics Exporter with Helm](#deploying-furiosa-metrics-exporter-with-helm)\\n\\n\\n\\n\\n\\nInstalling Furiosa Metrics Exporter\\n[#](#installing-furiosa-metrics-exporter \"Link to this heading\")\\n====================================================================================================\\n\\nFuriosa Metrics Exporter\\n[#](#furiosa-metrics-exporter \"Link to this heading\")\\n------------------------------------------------------------------------------\\n\\nThe Furiosa metrics exporter exposes collection of metrics related to\\nFuriosaAI NPU devices in\\n[Prometheus](https://prometheus.io/)\\nformat.\\nIn a Kubernetes cluster, you can scrape the metrics provided by furiosa-metrics-exporter\\nusing Prometheus and visualize them with a Grafana dashboard.\\nThis can be easily set up using the\\n[Prometheus Chart](https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus)\\nand\\n[Grafana](https://github.com/grafana/helm-charts/tree/main/charts/grafana)\\nHelm charts, along with the furiosa-metrics-exporter Helm chart.\\n\\n### Metrics [#](#metrics \"Link to this heading\")\\n\\nThe exporter is composed of chain of collectors, each collector is responsible\\nfor collecting specific metrics from the Furiosa NPU devices.\\nThe following table shows the available collectors and metrics:\\n\\n\\nNPU Metrics\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n\\n\\n\\n| Collector Name | Metric | Type | Metric Labels | Description |\\n| --- | --- | --- | --- | --- |\\n| Liveness | furiosa\\\\_npu\\\\_alive | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name | The liveness of the Furiosa NPU device. |\\n| Error | furiosa\\\\_npu\\\\_error | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The error count of the Furiosa NPU device. |\\n| Temperature | furiosa\\\\_npu\\\\_hw\\\\_temperature | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The temperature of the Furiosa NPU device. |\\n| Power | furiosa\\\\_npu\\\\_hw\\\\_power | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The power consumption of the Furiosa NPU device. |\\n| Core Utilization | furiosa\\\\_npu\\\\_core\\\\_utilization | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name | The core utilization of the Furiosa NPU device. |\\n\\nAll metrics share common metric labels such as arch, core, device, kubernetes\\\\_node\\\\_name, and uuid.\\nThe following table describes the common metric labels:\\n\\n\\nCommon NPU Metrics Label\\n\\n[#](#id2 \"Link to this table\")\\n\\n\\n| Common Metric Label | Description |\\n| --- | --- |\\n| arch | The architecture of the Furiosa NPU device. e.g. warboy, rngd |\\n| core | The core number of the Furiosa NPU device. e.g. 0, 1, 2, 3, 4, 5, 6, 7, 0-1, 2-3, 0-3, 4-5, 6-7, 4-7, 0-7 |\\n| device | The device name of the Furiosa NPU device. e.g. npu0 |\\n| kubernetes\\\\_node\\\\_name | The name of the Kubernetes node where the exporter is running, this attribute can be missing if the exporter is running on the host machine or in a naked container. |\\n| uuid | The UUID of the Furiosa NPU device. |\\n\\nThe metric label “label” is used to describe additional attributes specific to each metric.\\nThis approach helps avoid having too many metric definitions and effectively aggregates metrics that share common characteristics.\\n\\n\\nNPU Metrics Type\\n\\n[#](#id3 \"Link to this table\")\\n\\n\\n\\n| Metric Type | Label Attribute | Description |\\n| --- | --- | --- |\\n| Error | axi\\\\_post\\\\_error | Indicates count of axi post error. |\\n| Error | axi\\\\_fetch\\\\_error | Indicates count of axi fetch error. |\\n| Error | axi\\\\_discard\\\\_error | Indicates count of axi discard error. |\\n| Error | axi\\\\_doorbell\\\\_done | Indicates count of axi doorbell done error. |\\n| Error | pcie\\\\_post\\\\_error | Indicates count of PCIe post error. |\\n| Error | pcie\\\\_fetch\\\\_error | Indicates count of PCIe fetch error. |\\n| Error | pcie\\\\_discard\\\\_error | Indicates count of PCIe discard error. |\\n| Error | pcie\\\\_doorbell\\\\_done | Indicates count of PCIe doorbell done error. |\\n| Error | device\\\\_error | Total count of device error. |\\n| Temperature | peak | The highest temperature observed from SoC sensors |\\n| Temperature | ambient | The temperature observed from sensors attached to the board |\\n| Power | rms | Root Mean Square (RMS) value of the power consumed by the device, providing an average power consumption metric over a period of time. |\\n\\nThe following shows real-world example of the metrics:\\n\\n```\\n#liveness\\nfuriosa_npu_alive{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 1\\n\\n#error\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_post_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_fetch_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_discard_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_doorbell_done\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_post_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_fetch_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_discard_error\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_doorbell_done\",uuid=\"uuid\"} 0\\nfuriosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"device_error\",uuid=\"uuid\"} 0\\n\\n#temperature\\nfuriosa_npu_hw_temperature{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"peak\",uuid=\"uuid\"} 39\\nfuriosa_npu_hw_temperature{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"ambient\",uuid=\"uuid\"} 35\\n\\n#power\\nfuriosa_npu_hw_power{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"rms\",uuid=\"uuid\"} 4795000\\n\\n#core utilization\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"0\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"1\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"2\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"3\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"4\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"5\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"6\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\nfuriosa_npu_core_utilization{arch=\"rngd\",core=\"7\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\n\\n```\\n\\n\\n\\n### Deploying Furiosa Metrics Exporter with Helm [#](#deploying-furiosa-metrics-exporter-with-helm \"Link to this heading\")\\n\\nThe Furiosa metrics exporter helm chart is available at\\n[furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts)\\n. To configure deployment as you need, you can modify\\n`charts/furiosa-metrics-exporter/values.yaml`\\n.\\nFor example, the Furiosa metrics exporter Helm chart automatically creates a Service Object with Prometheus annotations to enable metric scraping automatically. You can modify the values.yaml to change the port or disable the Prometheus annotations if needed.\\nYou can deploy the Furiosa Metrics Exporter by running the following commands:\\n\\n```\\nhelm repo add furiosa https://furiosa-ai.github.io/helm-charts\\nhelm repo update\\nhelm install furiosa-metrics-exporter furiosa/furiosa-metrics-exporter -n kube-system\\n\\n```\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nInstalling Furiosa Device Plugin](device_plugin.html \"previous page\")\\n[next\\n\\nScheduling NPUs](scheduling_npus.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Furiosa Metrics Exporter](#furiosa-metrics-exporter)\\n  + [Metrics](#metrics)\\n  + [Deploying Furiosa Metrics Exporter with Helm](#deploying-furiosa-metrics-exporter-with-helm)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/cloud_native_toolkit/kubernetes/metrics_exporter.rst \"Download source file\") * .pdf\\nInstalling Furiosa Metrics Exporter ===================================\\nContents --------\\n* [Furiosa Metrics Exporter](#furiosa-metrics-exporter)   + [Metrics](#metrics)   + [Deploying Furiosa Metrics Exporter with Helm](#deploying-furiosa-metrics-exporter-with-helm)\\nInstalling Furiosa Metrics Exporter [#](#installing-furiosa-metrics-exporter \"Link to this heading\") ====================================================================================================\\nFuriosa Metrics Exporter [#](#furiosa-metrics-exporter \"Link to this heading\") ------------------------------------------------------------------------------\\nThe Furiosa metrics exporter exposes collection of metrics related to FuriosaAI NPU devices in [Prometheus](https://prometheus.io/) format. In a Kubernetes cluster, you can scrape the metrics provided by furiosa-metrics-exporter using Prometheus and visualize them with a Grafana dashboard. This can be easily set up using the [Prometheus Chart](https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus) and [Grafana](https://github.com/grafana/helm-charts/tree/main/charts/grafana) Helm charts, along with the furiosa-metrics-exporter Helm chart.\\n### Metrics [#](#metrics \"Link to this heading\")\\nThe exporter is composed of chain of collectors, each collector is responsible for collecting specific metrics from the Furiosa NPU devices. The following table shows the available collectors and metrics:\\nNPU Metrics\\n[#](#id1 \"Link to this table\")\\n| Collector Name | Metric | Type | Metric Labels | Description | | --- | --- | --- | --- | --- | | Liveness | furiosa\\\\_npu\\\\_alive | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name | The liveness of the Furiosa NPU device. | | Error | furiosa\\\\_npu\\\\_error | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The error count of the Furiosa NPU device. | | Temperature | furiosa\\\\_npu\\\\_hw\\\\_temperature | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The temperature of the Furiosa NPU device. | | Power | furiosa\\\\_npu\\\\_hw\\\\_power | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name, label | The power consumption of the Furiosa NPU device. | | Core Utilization | furiosa\\\\_npu\\\\_core\\\\_utilization | guage | arch, core, device, uuid, kubernetes\\\\_node\\\\_name | The core utilization of the Furiosa NPU device. |\\nAll metrics share common metric labels such as arch, core, device, kubernetes\\\\_node\\\\_name, and uuid. The following table describes the common metric labels:\\nCommon NPU Metrics Label\\n[#](#id2 \"Link to this table\")\\n| Common Metric Label | Description | | --- | --- | | arch | The architecture of the Furiosa NPU device. e.g. warboy, rngd | | core | The core number of the Furiosa NPU device. e.g. 0, 1, 2, 3, 4, 5, 6, 7, 0-1, 2-3, 0-3, 4-5, 6-7, 4-7, 0-7 | | device | The device name of the Furiosa NPU device. e.g. npu0 | | kubernetes\\\\_node\\\\_name | The name of the Kubernetes node where the exporter is running, this attribute can be missing if the exporter is running on the host machine or in a naked container. | | uuid | The UUID of the Furiosa NPU device. |\\nThe metric label “label” is used to describe additional attributes specific to each metric. This approach helps avoid having too many metric definitions and effectively aggregates metrics that share common characteristics.\\nNPU Metrics Type\\n[#](#id3 \"Link to this table\")\\n| Metric Type | Label Attribute | Description | | --- | --- | --- | | Error | axi\\\\_post\\\\_error | Indicates count of axi post error. | | Error | axi\\\\_fetch\\\\_error | Indicates count of axi fetch error. | | Error | axi\\\\_discard\\\\_error | Indicates count of axi discard error. | | Error | axi\\\\_doorbell\\\\_done | Indicates count of axi doorbell done error. | | Error | pcie\\\\_post\\\\_error | Indicates count of PCIe post error. | | Error | pcie\\\\_fetch\\\\_error | Indicates count of PCIe fetch error. | | Error | pcie\\\\_discard\\\\_error | Indicates count of PCIe discard error. | | Error | pcie\\\\_doorbell\\\\_done | Indicates count of PCIe doorbell done error. | | Error | device\\\\_error | Total count of device error. | | Temperature | peak | The highest temperature observed from SoC sensors | | Temperature | ambient | The temperature observed from sensors attached to the board | | Power | rms | Root Mean Square (RMS) value of the power consumed by the device, providing an average power consumption metric over a period of time. |\\nThe following shows real-world example of the metrics:\\n``` #liveness furiosa_npu_alive{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 1\\n#error furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_post_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_fetch_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_discard_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"axi_doorbell_done\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_post_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_fetch_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_discard_error\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"pcie_doorbell_done\",uuid=\"uuid\"} 0 furiosa_npu_error{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"device_error\",uuid=\"uuid\"} 0\\n#temperature furiosa_npu_hw_temperature{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"peak\",uuid=\"uuid\"} 39 furiosa_npu_hw_temperature{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"ambient\",uuid=\"uuid\"} 35\\n#power furiosa_npu_hw_power{arch=\"rngd\",core=\"0-7\",device=\"npu0\",kubernetes_node_name=\"node\",label=\"rms\",uuid=\"uuid\"} 4795000\\n#core utilization furiosa_npu_core_utilization{arch=\"rngd\",core=\"0\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"1\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"2\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"3\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"4\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"5\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"6\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90 furiosa_npu_core_utilization{arch=\"rngd\",core=\"7\",device=\"npu0\",kubernetes_node_name=\"node\",uuid=\"uuid\"} 90\\n```\\n### Deploying Furiosa Metrics Exporter with Helm [#](#deploying-furiosa-metrics-exporter-with-helm \"Link to this heading\")\\nThe Furiosa metrics exporter helm chart is available at [furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts) . To configure deployment as you need, you can modify `charts/furiosa-metrics-exporter/values.yaml` . For example, the Furiosa metrics exporter Helm chart automatically creates a Service Object with Prometheus annotations to enable metric scraping automatically. You can modify the values.yaml to change the port or disable the Prometheus annotations if needed. You can deploy the Furiosa Metrics Exporter by running the following commands:\\n``` helm repo add furiosa https://furiosa-ai.github.io/helm-charts helm repo update helm install furiosa-metrics-exporter furiosa/furiosa-metrics-exporter -n kube-system\\n```\\n[previous\\nInstalling Furiosa Device Plugin](device_plugin.html \"previous page\") [next\\nScheduling NPUs](scheduling_npus.html \"next page\")\\nContents\\n* [Furiosa Metrics Exporter](#furiosa-metrics-exporter)   + [Metrics](#metrics)   + [Deploying Furiosa Metrics Exporter with Helm](#deploying-furiosa-metrics-exporter-with-helm)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/cloud_native_toolkit/kubernetes/metrics_exporter.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Installing Furiosa Metrics Exporter\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-metrics-exporter\">\\n          Furiosa Metrics Exporter\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#metrics\">\\n            Metrics\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-metrics-exporter-with-helm\">\\n            Deploying Furiosa Metrics Exporter with Helm\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"installing-furiosa-metrics-exporter\">\\n     <span id=\"metricsexporter\">\\n     </span>\\n     <h1>\\n      Installing Furiosa Metrics Exporter\\n      <a class=\"headerlink\" href=\"#installing-furiosa-metrics-exporter\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <section id=\"furiosa-metrics-exporter\">\\n      <h2>\\n       Furiosa Metrics Exporter\\n       <a class=\"headerlink\" href=\"#furiosa-metrics-exporter\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The Furiosa metrics exporter exposes collection of metrics related to\\nFuriosaAI NPU devices in\\n       <a class=\"reference external\" href=\"https://prometheus.io/\">\\n        Prometheus\\n       </a>\\n       format.\\nIn a Kubernetes cluster, you can scrape the metrics provided by furiosa-metrics-exporter\\nusing Prometheus and visualize them with a Grafana dashboard.\\nThis can be easily set up using the\\n       <a class=\"reference external\" href=\"https://github.com/prometheus-community/helm-charts/tree/main/charts/prometheus\">\\n        Prometheus Chart\\n       </a>\\n       and\\n       <a class=\"reference external\" href=\"https://github.com/grafana/helm-charts/tree/main/charts/grafana\">\\n        Grafana\\n       </a>\\n       Helm charts, along with the furiosa-metrics-exporter Helm chart.\\n      </p>\\n      <section id=\"metrics\">\\n       <h3>\\n        Metrics\\n        <a class=\"headerlink\" href=\"#metrics\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The exporter is composed of chain of collectors, each collector is responsible\\nfor collecting specific metrics from the Furiosa NPU devices.\\nThe following table shows the available collectors and metrics:\\n       </p>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table table-center\" id=\"id1\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           NPU Metrics\\n          </span>\\n          <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 16.7%\"/>\\n          <col style=\"width: 16.7%\"/>\\n          <col style=\"width: 16.7%\"/>\\n          <col style=\"width: 16.7%\"/>\\n          <col style=\"width: 33.3%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             Collector Name\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Metric\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Type\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Metric Labels\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Description\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Liveness\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa_npu_alive\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             guage\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             arch, core, device, uuid, kubernetes_node_name\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The liveness of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa_npu_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             guage\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             arch, core, device, uuid, kubernetes_node_name, label\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The error count of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Temperature\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa_npu_hw_temperature\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             guage\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             arch, core, device, uuid, kubernetes_node_name, label\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The temperature of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Power\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa_npu_hw_power\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             guage\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             arch, core, device, uuid, kubernetes_node_name, label\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The power consumption of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Core Utilization\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             furiosa_npu_core_utilization\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             guage\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             arch, core, device, uuid, kubernetes_node_name\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The core utilization of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n       <p>\\n        All metrics share common metric labels such as arch, core, device, kubernetes_node_name, and uuid.\\nThe following table describes the common metric labels:\\n       </p>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table table-center\" id=\"id2\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           Common NPU Metrics Label\\n          </span>\\n          <a class=\"headerlink\" href=\"#id2\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 25.0%\"/>\\n          <col style=\"width: 75.0%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             Common Metric Label\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Description\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             arch\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The architecture of the Furiosa NPU device. e.g. warboy, rngd\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             core\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The core number of the Furiosa NPU device. e.g. 0, 1, 2, 3, 4, 5, 6, 7, 0-1, 2-3, 0-3, 4-5, 6-7, 4-7, 0-7\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             device\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The device name of the Furiosa NPU device. e.g. npu0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             kubernetes_node_name\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The name of the Kubernetes node where the exporter is running, this attribute can be missing if the exporter is running on the host machine or in a naked container.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             uuid\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The UUID of the Furiosa NPU device.\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n       <p>\\n        The metric label “label” is used to describe additional attributes specific to each metric.\\nThis approach helps avoid having too many metric definitions and effectively aggregates metrics that share common characteristics.\\n       </p>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table table-center\" id=\"id3\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           NPU Metrics Type\\n          </span>\\n          <a class=\"headerlink\" href=\"#id3\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 23.8%\"/>\\n          <col style=\"width: 28.6%\"/>\\n          <col style=\"width: 47.6%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             Metric Type\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Label Attribute\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Description\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             axi_post_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of axi post error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             axi_fetch_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of axi fetch error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             axi_discard_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of axi discard error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             axi_doorbell_done\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of axi doorbell done error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             pcie_post_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of PCIe post error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             pcie_fetch_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of PCIe fetch error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             pcie_discard_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of PCIe discard error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             pcie_doorbell_done\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Indicates count of PCIe doorbell done error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             device_error\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Total count of device error.\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Temperature\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             peak\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The highest temperature observed from SoC sensors\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             Temperature\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             ambient\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             The temperature observed from sensors attached to the board\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             Power\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             rms\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Root Mean Square (RMS) value of the power consumed by the device, providing an average power consumption metric over a period of time.\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n       <p>\\n        The following shows real-world example of the metrics:\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"c1\">#liveness</span>\\nfuriosa_npu_alive<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">1</span>\\n\\n<span class=\"c1\">#error</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"axi_post_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"axi_fetch_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"axi_discard_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"axi_doorbell_done\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"pcie_post_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"pcie_fetch_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"pcie_discard_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"pcie_doorbell_done\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\nfuriosa_npu_error<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"device_error\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">0</span>\\n\\n<span class=\"c1\">#temperature</span>\\nfuriosa_npu_hw_temperature<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"peak\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">39</span>\\nfuriosa_npu_hw_temperature<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"ambient\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">35</span>\\n\\n<span class=\"c1\">#power</span>\\nfuriosa_npu_hw_power<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0-7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,label<span class=\"o\">=</span><span class=\"s2\">\"rms\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">4795000</span>\\n\\n<span class=\"c1\">#core utilization</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"0\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"1\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"2\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"3\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"4\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"5\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"6\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\nfuriosa_npu_core_utilization<span class=\"o\">{</span><span class=\"nv\">arch</span><span class=\"o\">=</span><span class=\"s2\">\"rngd\"</span>,core<span class=\"o\">=</span><span class=\"s2\">\"7\"</span>,device<span class=\"o\">=</span><span class=\"s2\">\"npu0\"</span>,kubernetes_node_name<span class=\"o\">=</span><span class=\"s2\">\"node\"</span>,uuid<span class=\"o\">=</span><span class=\"s2\">\"uuid\"</span><span class=\"o\">}</span><span class=\"w\"> </span><span class=\"m\">90</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n      <section id=\"deploying-furiosa-metrics-exporter-with-helm\">\\n       <h3>\\n        Deploying Furiosa Metrics Exporter with Helm\\n        <a class=\"headerlink\" href=\"#deploying-furiosa-metrics-exporter-with-helm\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The Furiosa metrics exporter helm chart is available at\\n        <a class=\"github reference external\" href=\"https://github.com/furiosa-ai/helm-charts\">\\n         furiosa-ai/helm-charts\\n        </a>\\n        . To configure deployment as you need, you can modify\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          charts/furiosa-metrics-exporter/values.yaml\\n         </span>\\n        </code>\\n        .\\nFor example, the Furiosa metrics exporter Helm chart automatically creates a Service Object with Prometheus annotations to enable metric scraping automatically. You can modify the values.yaml to change the port or disable the Prometheus annotations if needed.\\nYou can deploy the Furiosa Metrics Exporter by running the following commands:\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>helm<span class=\"w\"> </span>repo<span class=\"w\"> </span>add<span class=\"w\"> </span>furiosa<span class=\"w\"> </span>https://furiosa-ai.github.io/helm-charts\\nhelm<span class=\"w\"> </span>repo<span class=\"w\"> </span>update\\nhelm<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-metrics-exporter<span class=\"w\"> </span>furiosa/furiosa-metrics-exporter<span class=\"w\"> </span>-n<span class=\"w\"> </span>kube-system\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"device_plugin.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Device Plugin\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"scheduling_npus.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Scheduling NPUs\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-metrics-exporter\">\\n         Furiosa Metrics Exporter\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#metrics\">\\n           Metrics\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-metrics-exporter-with-helm\">\\n           Deploying Furiosa Metrics Exporter with Helm\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='a1f21dc2-1473-410f-a3ae-e46d451a9c0e', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/kubernetes/feature_discovery.html'), name='feature_discovery', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/cloud_native_toolkit/kubernetes/feature_discovery.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstalling Furiosa Feature Discovery\\n====================================\\n\\n\\nContents\\n--------\\n\\n\\n* [Furiosa Feature discovery and NFD](#furiosa-feature-discovery-and-nfd)\\n  + [Labels](#labels)\\n  + [Deploying Furiosa Feature Discovery with Helm](#deploying-furiosa-feature-discovery-with-helm)\\n\\n\\n\\n\\n\\nInstalling Furiosa Feature Discovery\\n[#](#installing-furiosa-feature-discovery \"Link to this heading\")\\n======================================================================================================\\n\\nFuriosa Feature discovery and NFD\\n[#](#furiosa-feature-discovery-and-nfd \"Link to this heading\")\\n------------------------------------------------------------------------------------------------\\n\\nThe Furiosa feature discovery automatically labels Kubernetes nodes with information\\nabout FuriosaAI NPU properties, such as the NPU family, count, and driver versions.\\nUsing these labels, you can schedule your Kubernetes workloads based on specific NPU requirements.\\n\\nThe Furiosa feature Discovery leverage NFD(Node Feature Discovery) which is a tool that detects\\nhardware features and labels Kubernetes nodes. It is recommended to use NFD and\\nFuriosa Feature Discovery to ensure that the Cloud Native Toolkit is deployed only on nodes\\nequipped with FuriosaAI NPUs.\\n\\n### Labels [#](#labels \"Link to this heading\")\\n\\nThe followings are the labels that the Furiosa Feature Discovery attaches and what they mean.\\n\\n\\nLabels\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n\\n| Label | Value | Description |\\n| --- | --- | --- |\\n| furiosa.ai/npu.count | n | # of NPU devices |\\n| furiosa.ai/npu.family | warboy, rngd | Chip family |\\n| furiosa.ai/npu.product | warboy, rngd, rngd-s, rngd-max | Chip product name |\\n| furiosa.ai/npu.driver.version | x.y.z | NPU device driver version |\\n| furiosa.ai/npu.driver.version.major | x | NPU device driver version major part |\\n| furiosa.ai/npu.driver.version.minor | y | NPU device driver version minor part |\\n| furiosa.ai/npu.driver.version.patch | z | NPU device driver version patch part |\\n| furiosa.ai/npu.driver.version.metadata | abcxyz | NPU device driver version metadata |\\n\\n\\n\\n### Deploying Furiosa Feature Discovery with Helm [#](#deploying-furiosa-feature-discovery-with-helm \"Link to this heading\")\\n\\nWith the helm chart you can easily install Furiosa feature discovery and NFD into your Kubernetes cluster.\\nFollowing command shows how to install them.\\nThe Furiosa device plugin helm chart is available at\\n[furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts)\\n. To configure deployment as you need, you can modify\\n`charts/furiosa-feature-discovery/values.yaml`\\n.\\n\\n```\\nhelm repo add furiosa https://furiosa-ai.github.io/helm-charts\\nhelm repo update\\nhelm install furiosa-feature-discovery furiosa/furiosa-feature-discovery -n kube-system\\n\\n```\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nKubernetes Support](../kubernetes.html \"previous page\")\\n[next\\n\\nInstalling Furiosa Device Plugin](device_plugin.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Furiosa Feature discovery and NFD](#furiosa-feature-discovery-and-nfd)\\n  + [Labels](#labels)\\n  + [Deploying Furiosa Feature Discovery with Helm](#deploying-furiosa-feature-discovery-with-helm)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/cloud_native_toolkit/kubernetes/feature_discovery.rst \"Download source file\") * .pdf\\nInstalling Furiosa Feature Discovery ====================================\\nContents --------\\n* [Furiosa Feature discovery and NFD](#furiosa-feature-discovery-and-nfd)   + [Labels](#labels)   + [Deploying Furiosa Feature Discovery with Helm](#deploying-furiosa-feature-discovery-with-helm)\\nInstalling Furiosa Feature Discovery [#](#installing-furiosa-feature-discovery \"Link to this heading\") ======================================================================================================\\nFuriosa Feature discovery and NFD [#](#furiosa-feature-discovery-and-nfd \"Link to this heading\") ------------------------------------------------------------------------------------------------\\nThe Furiosa feature discovery automatically labels Kubernetes nodes with information about FuriosaAI NPU properties, such as the NPU family, count, and driver versions. Using these labels, you can schedule your Kubernetes workloads based on specific NPU requirements.\\nThe Furiosa feature Discovery leverage NFD(Node Feature Discovery) which is a tool that detects hardware features and labels Kubernetes nodes. It is recommended to use NFD and Furiosa Feature Discovery to ensure that the Cloud Native Toolkit is deployed only on nodes equipped with FuriosaAI NPUs.\\n### Labels [#](#labels \"Link to this heading\")\\nThe followings are the labels that the Furiosa Feature Discovery attaches and what they mean.\\nLabels\\n[#](#id1 \"Link to this table\")\\n| Label | Value | Description | | --- | --- | --- | | furiosa.ai/npu.count | n | # of NPU devices | | furiosa.ai/npu.family | warboy, rngd | Chip family | | furiosa.ai/npu.product | warboy, rngd, rngd-s, rngd-max | Chip product name | | furiosa.ai/npu.driver.version | x.y.z | NPU device driver version | | furiosa.ai/npu.driver.version.major | x | NPU device driver version major part | | furiosa.ai/npu.driver.version.minor | y | NPU device driver version minor part | | furiosa.ai/npu.driver.version.patch | z | NPU device driver version patch part | | furiosa.ai/npu.driver.version.metadata | abcxyz | NPU device driver version metadata |\\n### Deploying Furiosa Feature Discovery with Helm [#](#deploying-furiosa-feature-discovery-with-helm \"Link to this heading\")\\nWith the helm chart you can easily install Furiosa feature discovery and NFD into your Kubernetes cluster. Following command shows how to install them. The Furiosa device plugin helm chart is available at [furiosa-ai/helm-charts](https://github.com/furiosa-ai/helm-charts) . To configure deployment as you need, you can modify `charts/furiosa-feature-discovery/values.yaml` .\\n``` helm repo add furiosa https://furiosa-ai.github.io/helm-charts helm repo update helm install furiosa-feature-discovery furiosa/furiosa-feature-discovery -n kube-system\\n```\\n[previous\\nKubernetes Support](../kubernetes.html \"previous page\") [next\\nInstalling Furiosa Device Plugin](device_plugin.html \"next page\")\\nContents\\n* [Furiosa Feature discovery and NFD](#furiosa-feature-discovery-and-nfd)   + [Labels](#labels)   + [Deploying Furiosa Feature Discovery with Helm](#deploying-furiosa-feature-discovery-with-helm)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/cloud_native_toolkit/kubernetes/feature_discovery.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Installing Furiosa Feature Discovery\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-feature-discovery-and-nfd\">\\n          Furiosa Feature discovery and NFD\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#labels\">\\n            Labels\\n           </a>\\n          </li>\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-feature-discovery-with-helm\">\\n            Deploying Furiosa Feature Discovery with Helm\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"installing-furiosa-feature-discovery\">\\n     <span id=\"featurediscovery\">\\n     </span>\\n     <h1>\\n      Installing Furiosa Feature Discovery\\n      <a class=\"headerlink\" href=\"#installing-furiosa-feature-discovery\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <section id=\"furiosa-feature-discovery-and-nfd\">\\n      <h2>\\n       Furiosa Feature discovery and NFD\\n       <a class=\"headerlink\" href=\"#furiosa-feature-discovery-and-nfd\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The Furiosa feature discovery automatically labels Kubernetes nodes with information\\nabout FuriosaAI NPU properties, such as the NPU family, count, and driver versions.\\nUsing these labels, you can schedule your Kubernetes workloads based on specific NPU requirements.\\n      </p>\\n      <p>\\n       The Furiosa feature Discovery leverage NFD(Node Feature Discovery) which is a tool that detects\\nhardware features and labels Kubernetes nodes. It is recommended to use NFD and\\nFuriosa Feature Discovery to ensure that the Cloud Native Toolkit is deployed only on nodes\\nequipped with FuriosaAI NPUs.\\n      </p>\\n      <section id=\"labels\">\\n       <h3>\\n        Labels\\n        <a class=\"headerlink\" href=\"#labels\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        The followings are the labels that the Furiosa Feature Discovery attaches and what they mean.\\n       </p>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table table-center\" id=\"id1\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           Labels\\n          </span>\\n          <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 23.6%\"/>\\n          <col style=\"width: 29.1%\"/>\\n          <col style=\"width: 47.3%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             Label\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Value\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Description\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.count\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             n\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             # of NPU devices\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.family\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             warboy, rngd\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Chip family\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.product\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             warboy, rngd, rngd-s, rngd-max\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             Chip product name\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.driver.version\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             x.y.z\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             NPU device driver version\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.driver.version.major\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             x\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             NPU device driver version major part\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.driver.version.minor\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             y\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             NPU device driver version minor part\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.driver.version.patch\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             z\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             NPU device driver version patch part\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa.ai/npu.driver.version.metadata\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             abcxyz\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             NPU device driver version metadata\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n      </section>\\n      <section id=\"deploying-furiosa-feature-discovery-with-helm\">\\n       <h3>\\n        Deploying Furiosa Feature Discovery with Helm\\n        <a class=\"headerlink\" href=\"#deploying-furiosa-feature-discovery-with-helm\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        With the helm chart you can easily install Furiosa feature discovery and NFD into your Kubernetes cluster.\\nFollowing command shows how to install them.\\nThe Furiosa device plugin helm chart is available at\\n        <a class=\"github reference external\" href=\"https://github.com/furiosa-ai/helm-charts\">\\n         furiosa-ai/helm-charts\\n        </a>\\n        . To configure deployment as you need, you can modify\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          charts/furiosa-feature-discovery/values.yaml\\n         </span>\\n        </code>\\n        .\\n       </p>\\n       <div class=\"highlight-sh notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>helm<span class=\"w\"> </span>repo<span class=\"w\"> </span>add<span class=\"w\"> </span>furiosa<span class=\"w\"> </span>https://furiosa-ai.github.io/helm-charts\\nhelm<span class=\"w\"> </span>repo<span class=\"w\"> </span>update\\nhelm<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-feature-discovery<span class=\"w\"> </span>furiosa/furiosa-feature-discovery<span class=\"w\"> </span>-n<span class=\"w\"> </span>kube-system\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../kubernetes.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Kubernetes Support\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"device_plugin.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Device Plugin\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-feature-discovery-and-nfd\">\\n         Furiosa Feature discovery and NFD\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#labels\">\\n           Labels\\n          </a>\\n         </li>\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#deploying-furiosa-feature-discovery-with-helm\">\\n           Deploying Furiosa Feature Discovery with Helm\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='a53038c2-0668-4963-875e-79abe9c99e2c', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/whatsnew/index.html'), name='index', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/whatsnew/index.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWhat’s New\\n==========\\n\\n\\nContents\\n--------\\n\\n\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)\\n  + [Highlights](#highlights)\\n\\n\\n\\n\\n\\nWhat’s New\\n[#](#what-s-new \"Link to this heading\")\\n==================================================\\n\\nThis page describes the changes and functionality available in\\nin the latest releases of Furiosa SDK 2024.1.0.\\n\\nFuriosa SDK 2024.1.0 (2024-10-11)\\n[#](#furiosa-sdk-2024-1-0-2024-10-11 \"Link to this heading\")\\n----------------------------------------------------------------------------------------------\\n\\n2024.1.0 is the first SDK release for RNGD. This release is alpha release,\\nand the features and APIs described in this document may change in the future.\\n\\n### Highlights [#](#highlights \"Link to this heading\")\\n\\n* Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B\\n* Furiosa Quantizer supports the following quantization methods:\\n  \\n  + BF16 (W16A16)\\n  + INT8 Weight-Only (W8A16)\\n  + FP8 (W8A8)\\n  + INT8 SmoothQuant (W8A8)\\n* Furiosa LLM\\n  \\n  + Efficient KV cache management with PagedAttention\\n  + Continuous batching support in serving\\n  + OpenAI-compatible API server\\n  + Greedy search and beam search\\n  + Pipeline Parallelism and Data Parallelism across multiple NPUs\\n* `furiosa-mlperf`\\n  command\\n  \\n  + Server and Offline scenarios\\n  + BERT, GPT-J, LLaMA 3.1 benchmarks\\n* System Management Interface\\n  \\n  + System Management Interface Library and CLI for Furiosa NPU family\\n* Cloud Native Toolkit\\n  \\n  + Kubernetes integration for managing and monitoring the Furiosa NPU family\\n\\n\\nComponent version\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n| Package name | Version |\\n| --- | --- |\\n| furiosa-compiler | 2024.1.0 |\\n| furiosa-device-plugin | 2024.1.0 |\\n| furiosa-driver-rngd | 2024.1.0 |\\n| furiosa-feature-discovery | 2024.1.0 |\\n| furiosa-firmware-image-tools | 2024.1.0 |\\n| furiosa-firmware-image-rngd | 0.0.19 |\\n| furiosa-libsmi | 2024.1.0 |\\n| furiosa-llm | 2024.1.0 |\\n| furiosa-llm-models | 2024.1.0 |\\n| furiosa-mlperf | 2024.1.0 |\\n| furiosa-mlperf-resources | 2024.1.0 |\\n| furiosa-model-compressor | 2024.1.0 |\\n| furiosa-model-compressor-impl | 2024.1.0 |\\n| furiosa-native-compiler | 2024.1.0 |\\n| furiosa-native-runtime | 2024.1.0 |\\n| furiosa-smi | 2024.1.0 |\\n| furiosa-torch-ext | 2024.1.0 |\\n\\n\\n\\n\\n\\n\\n[previous\\n\\nSupported Models](../overview/supported_models.html \"previous page\")\\n[next\\n\\nRoadmap](../overview/roadmap.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)\\n  + [Highlights](#highlights)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/whatsnew/index.rst \"Download source file\") * .pdf\\nWhat’s New ==========\\nContents --------\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nWhat’s New [#](#what-s-new \"Link to this heading\") ==================================================\\nThis page describes the changes and functionality available in in the latest releases of Furiosa SDK 2024.1.0.\\nFuriosa SDK 2024.1.0 (2024-10-11) [#](#furiosa-sdk-2024-1-0-2024-10-11 \"Link to this heading\") ----------------------------------------------------------------------------------------------\\n2024.1.0 is the first SDK release for RNGD. This release is alpha release, and the features and APIs described in this document may change in the future.\\n### Highlights [#](#highlights \"Link to this heading\")\\n* Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B * Furiosa Quantizer supports the following quantization methods:      + BF16 (W16A16)   + INT8 Weight-Only (W8A16)   + FP8 (W8A8)   + INT8 SmoothQuant (W8A8) * Furiosa LLM      + Efficient KV cache management with PagedAttention   + Continuous batching support in serving   + OpenAI-compatible API server   + Greedy search and beam search   + Pipeline Parallelism and Data Parallelism across multiple NPUs * `furiosa-mlperf`   command      + Server and Offline scenarios   + BERT, GPT-J, LLaMA 3.1 benchmarks * System Management Interface      + System Management Interface Library and CLI for Furiosa NPU family * Cloud Native Toolkit      + Kubernetes integration for managing and monitoring the Furiosa NPU family\\nComponent version\\n[#](#id1 \"Link to this table\")\\n| Package name | Version | | --- | --- | | furiosa-compiler | 2024.1.0 | | furiosa-device-plugin | 2024.1.0 | | furiosa-driver-rngd | 2024.1.0 | | furiosa-feature-discovery | 2024.1.0 | | furiosa-firmware-image-tools | 2024.1.0 | | furiosa-firmware-image-rngd | 0.0.19 | | furiosa-libsmi | 2024.1.0 | | furiosa-llm | 2024.1.0 | | furiosa-llm-models | 2024.1.0 | | furiosa-mlperf | 2024.1.0 | | furiosa-mlperf-resources | 2024.1.0 | | furiosa-model-compressor | 2024.1.0 | | furiosa-model-compressor-impl | 2024.1.0 | | furiosa-native-compiler | 2024.1.0 | | furiosa-native-runtime | 2024.1.0 | | furiosa-smi | 2024.1.0 | | furiosa-torch-ext | 2024.1.0 |\\n[previous\\nSupported Models](../overview/supported_models.html \"previous page\") [next\\nRoadmap](../overview/roadmap.html \"next page\")\\nContents\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/whatsnew/index.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     What’s New\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#furiosa-sdk-2024-1-0-2024-10-11\">\\n          Furiosa SDK 2024.1.0 (2024-10-11)\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#highlights\">\\n            Highlights\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"what-s-new\">\\n     <span id=\"whatsnew\">\\n     </span>\\n     <h1>\\n      What’s New\\n      <a class=\"headerlink\" href=\"#what-s-new\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      This page describes the changes and functionality available in\\nin the latest releases of Furiosa SDK 2024.1.0.\\n     </p>\\n     <section id=\"furiosa-sdk-2024-1-0-2024-10-11\">\\n      <h2>\\n       Furiosa SDK 2024.1.0 (2024-10-11)\\n       <a class=\"headerlink\" href=\"#furiosa-sdk-2024-1-0-2024-10-11\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       2024.1.0 is the first SDK release for RNGD. This release is alpha release,\\nand the features and APIs described in this document may change in the future.\\n      </p>\\n      <section id=\"highlights\">\\n       <h3>\\n        Highlights\\n        <a class=\"headerlink\" href=\"#highlights\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <ul class=\"simple\">\\n        <li>\\n         <p>\\n          Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B\\n         </p>\\n        </li>\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           Furiosa Quantizer supports the following quantization methods:\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              BF16 (W16A16)\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              INT8 Weight-Only (W8A16)\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              FP8 (W8A8)\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              INT8 SmoothQuant (W8A8)\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           Furiosa LLM\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              Efficient KV cache management with PagedAttention\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              Continuous batching support in serving\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              OpenAI-compatible API server\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              Greedy search and beam search\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              Pipeline Parallelism and Data Parallelism across multiple NPUs\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           <code class=\"docutils literal notranslate\">\\n            <span class=\"pre\">\\n             furiosa-mlperf\\n            </span>\\n           </code>\\n           command\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              Server and Offline scenarios\\n             </p>\\n            </li>\\n            <li>\\n             <p>\\n              BERT, GPT-J, LLaMA 3.1 benchmarks\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           System Management Interface\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              System Management Interface Library and CLI for Furiosa NPU family\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n        <li>\\n         <dl class=\"simple\">\\n          <dt>\\n           Cloud Native Toolkit\\n          </dt>\\n          <dd>\\n           <ul>\\n            <li>\\n             <p>\\n              Kubernetes integration for managing and monitoring the Furiosa NPU family\\n             </p>\\n            </li>\\n           </ul>\\n          </dd>\\n         </dl>\\n        </li>\\n       </ul>\\n       <div class=\"pst-scrollable-table-container\">\\n        <table class=\"table\" id=\"id1\">\\n         <caption>\\n          <span class=\"caption-text\">\\n           Component version\\n          </span>\\n          <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n           #\\n          </a>\\n         </caption>\\n         <colgroup>\\n          <col style=\"width: 80.0%\"/>\\n          <col style=\"width: 20.0%\"/>\\n         </colgroup>\\n         <thead>\\n          <tr class=\"row-odd\">\\n           <th class=\"head\">\\n            <p>\\n             Package name\\n            </p>\\n           </th>\\n           <th class=\"head\">\\n            <p>\\n             Version\\n            </p>\\n           </th>\\n          </tr>\\n         </thead>\\n         <tbody>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-compiler\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-device-plugin\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-driver-rngd\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-feature-discovery\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-firmware-image-tools\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-firmware-image-rngd\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             0.0.19\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-libsmi\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-llm\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-llm-models\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-mlperf\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-mlperf-resources\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-model-compressor\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-model-compressor-impl\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-native-compiler\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-native-runtime\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-odd\">\\n           <td>\\n            <p>\\n             furiosa-smi\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n          <tr class=\"row-even\">\\n           <td>\\n            <p>\\n             furiosa-torch-ext\\n            </p>\\n           </td>\\n           <td>\\n            <p>\\n             2024.1.0\\n            </p>\\n           </td>\\n          </tr>\\n         </tbody>\\n        </table>\\n       </div>\\n      </section>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../overview/supported_models.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Supported Models\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../overview/roadmap.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Roadmap\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#furiosa-sdk-2024-1-0-2024-10-11\">\\n         Furiosa SDK 2024.1.0 (2024-10-11)\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#highlights\">\\n           Highlights\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='56ae0c48-fbd4-4d43-b6f7-395542108fa7', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/getting_started/furiosa_llm.html'), name='furiosa_llm', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/getting_started/furiosa_llm.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nQuick Start with Furiosa LLM\\n============================\\n\\n\\nContents\\n--------\\n\\n\\n* [Installing Furiosa LLM](#installing-furiosa-llm)\\n  + [Offline Batch Inference with Furiosa LLM](#offline-batch-inference-with-furiosa-llm)\\n* [Launching the OpenAI-Compatible Server](#launching-the-openai-compatible-server)\\n* [Running Furiosa LLM in container environment](#running-furiosa-llm-in-container-environment)\\n\\n\\n\\n\\n\\nQuick Start with Furiosa LLM\\n[#](#quick-start-with-furiosa-llm \"Link to this heading\")\\n======================================================================================\\n\\nFuriosa LLM is a serving framework for LLM models that utilizes FuriosaAI’s NPU.\\nIt provides a Python API compatible with vLLM and a server compatible with the OpenAI API.\\nThis document explains how to install and use Furiosa LLM.\\n\\nWarning\\n\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n\\n\\nInstalling Furiosa LLM\\n[#](#installing-furiosa-llm \"Link to this heading\")\\n--------------------------------------------------------------------------\\n\\nThe minimum requirements for Furiosa LLM are as follows:\\n\\n* Ubuntu 20.04 LTS (Debian bullseye) or later\\n* Administrator privileges on system (root)\\n* [Setting up APT server](prerequisites.html#aptsetup)\\n  and\\n  [Installing Prerequisites](prerequisites.html#installingprerequisites)\\n* Python 3.8, 3.9, or 3.10\\n* Enough storage space for model weights; e.g., about 100GB for Llama 3.1 70B model\\n\\nThen, please install the\\n`furiosa-compiler`\\npackage as follows:\\n\\n```\\nsudo apt install -y furiosa-compiler\\n\\n```\\n\\nAlso, you need to create a Python virtual environment depending on your environment.\\n\\nNote\\n\\nNote that some models, such as meta-llama/Meta-Llama-3.1-8B require you to accept their license,\\nhence, you need to create a HuggingFace account, accept the model’s license, and generate a token.\\nUsually, you can create your token at\\n<https://huggingface.co/settings/tokens>\\n.\\nOnce you get a token, you can authenticate on the HuggingFace Hub as following:\\n\\n```\\nhuggingface-cli login --token $HF_TOKEN\\n\\n```\\n\\n\\nThen, you can install the Furiosa LLM with the following command:\\n\\n```\\npip install furiosa-llm\\n\\n```\\n\\n\\n### Offline Batch Inference with Furiosa LLM [#](#offline-batch-inference-with-furiosa-llm \"Link to this heading\")\\n\\nIn this section, we will explain how to perform offline LLM inference using the Python API of Furiosa LLM.\\nFirst, import the\\n`LLM`\\nclass and\\n`SamplingParams`\\nfrom the furiosa\\\\_llm module.\\n`LLM`\\nclass is used to load LLM models and provides the core API for LLM inference.\\n`SamplingParams`\\nallows to specify various parameters for text generation.\\n\\n```\\nfrom furiosa_llm import LLM, SamplingParams\\n\\n```\\n\\nNext, we will load an LLM model using the LLM class.\\nThe following example loads the meta-llama/Meta-Llama-3.1-8B model from the HuggingFace Hub\\nand performs quantization. The model will be loaded into the memory and ready for inference.\\n\\n```\\nllm = LLM(model=\"meta-llama/Llama-3.1-8B-Instruct\")\\n\\n```\\n\\nAfter loading the model, you can perform LLM inference by calling the\\n`generate`\\nmethod.\\n\\n```\\nprompts = [\\n  \"\"\\n]\\nsampling_params = SamplingParams(temperature=0.0)\\n\\n```\\n\\n\\n\\n\\nLaunching the OpenAI-Compatible Server\\n[#](#launching-the-openai-compatible-server \"Link to this heading\")\\n----------------------------------------------------------------------------------------------------------\\n\\nYou can find more details at\\n[OpenAI Compatible Server](../furiosa_llm/furiosa-llm-serve.html#openaiserver)\\n.\\n\\n\\nRunning Furiosa LLM in container environment\\n[#](#running-furiosa-llm-in-container-environment \"Link to this heading\")\\n----------------------------------------------------------------------------------------------------------------------\\n\\nFuriosaAI provides an image for running\\n`furiosa-llm`\\nin a containerized environment.\\nBy using the containerized version, you can run environments that utilize\\n`furiosa-llm`\\nwithout installing the FuriosaAI Software Stack on your host system,\\nor you can execute it within a Kubernetes environment.\\n\\nTo run the\\n`furiosa-llm`\\ncontainer, you can use the following command:\\n\\n```\\n$ docker run -it --rm --privileged furiosa-llm:2024.1.0 bash\\n\\n(container) # python\\n\\n```\\n\\n\\nWarning\\n\\nThe example above uses the\\n`--privileged`\\noption for simplicity, but it is not recommended for security reasons.\\nIf you are using Kubernetes, please refer to the following page for the recommended method:\\n[Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n\\n\\n\\n\\n\\n[previous\\n\\nInstalling Prerequisites](prerequisites.html \"previous page\")\\n[next\\n\\nRunning MLPerf™ Inference Benchmark](furiosa_mlperf.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Installing Furiosa LLM](#installing-furiosa-llm)\\n  + [Offline Batch Inference with Furiosa LLM](#offline-batch-inference-with-furiosa-llm)\\n* [Launching the OpenAI-Compatible Server](#launching-the-openai-compatible-server)\\n* [Running Furiosa LLM in container environment](#running-furiosa-llm-in-container-environment)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/getting_started/furiosa_llm.rst \"Download source file\") * .pdf\\nQuick Start with Furiosa LLM ============================\\nContents --------\\n* [Installing Furiosa LLM](#installing-furiosa-llm)   + [Offline Batch Inference with Furiosa LLM](#offline-batch-inference-with-furiosa-llm) * [Launching the OpenAI-Compatible Server](#launching-the-openai-compatible-server) * [Running Furiosa LLM in container environment](#running-furiosa-llm-in-container-environment)\\nQuick Start with Furiosa LLM [#](#quick-start-with-furiosa-llm \"Link to this heading\") ======================================================================================\\nFuriosa LLM is a serving framework for LLM models that utilizes FuriosaAI’s NPU. It provides a Python API compatible with vLLM and a server compatible with the OpenAI API. This document explains how to install and use Furiosa LLM.\\nWarning\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version, and the features and APIs described in this document may change in the future.\\nInstalling Furiosa LLM [#](#installing-furiosa-llm \"Link to this heading\") --------------------------------------------------------------------------\\nThe minimum requirements for Furiosa LLM are as follows:\\n* Ubuntu 20.04 LTS (Debian bullseye) or later * Administrator privileges on system (root) * [Setting up APT server](prerequisites.html#aptsetup)   and   [Installing Prerequisites](prerequisites.html#installingprerequisites) * Python 3.8, 3.9, or 3.10 * Enough storage space for model weights; e.g., about 100GB for Llama 3.1 70B model\\nThen, please install the `furiosa-compiler` package as follows:\\n``` sudo apt install -y furiosa-compiler\\n```\\nAlso, you need to create a Python virtual environment depending on your environment.\\nNote\\nNote that some models, such as meta-llama/Meta-Llama-3.1-8B require you to accept their license, hence, you need to create a HuggingFace account, accept the model’s license, and generate a token. Usually, you can create your token at <https://huggingface.co/settings/tokens> .\\nOnce you get a token, you can authenticate on the HuggingFace Hub as following:\\n``` huggingface-cli login --token $HF_TOKEN\\n```\\nThen, you can install the Furiosa LLM with the following command:\\n``` pip install furiosa-llm\\n```\\n### Offline Batch Inference with Furiosa LLM [#](#offline-batch-inference-with-furiosa-llm \"Link to this heading\")\\nIn this section, we will explain how to perform offline LLM inference using the Python API of Furiosa LLM. First, import the `LLM` class and `SamplingParams` from the furiosa\\\\_llm module. `LLM` class is used to load LLM models and provides the core API for LLM inference. `SamplingParams` allows to specify various parameters for text generation.\\n``` from furiosa_llm import LLM, SamplingParams\\n```\\nNext, we will load an LLM model using the LLM class. The following example loads the meta-llama/Meta-Llama-3.1-8B model from the HuggingFace Hub and performs quantization. The model will be loaded into the memory and ready for inference.\\n``` llm = LLM(model=\"meta-llama/Llama-3.1-8B-Instruct\")\\n```\\nAfter loading the model, you can perform LLM inference by calling the `generate` method.\\n``` prompts = [   \"\" ]\\nsampling_params = SamplingParams(temperature=0.0)\\n```\\nLaunching the OpenAI-Compatible Server [#](#launching-the-openai-compatible-server \"Link to this heading\") ----------------------------------------------------------------------------------------------------------\\nYou can find more details at [OpenAI Compatible Server](../furiosa_llm/furiosa-llm-serve.html#openaiserver) .\\nRunning Furiosa LLM in container environment [#](#running-furiosa-llm-in-container-environment \"Link to this heading\") ----------------------------------------------------------------------------------------------------------------------\\nFuriosaAI provides an image for running `furiosa-llm` in a containerized environment. By using the containerized version, you can run environments that utilize `furiosa-llm` without installing the FuriosaAI Software Stack on your host system, or you can execute it within a Kubernetes environment.\\nTo run the `furiosa-llm` container, you can use the following command:\\n``` $ docker run -it --rm --privileged furiosa-llm:2024.1.0 bash\\n(container) # python\\n```\\nWarning\\nThe example above uses the `--privileged` option for simplicity, but it is not recommended for security reasons. If you are using Kubernetes, please refer to the following page for the recommended method: [Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit)\\n[previous\\nInstalling Prerequisites](prerequisites.html \"previous page\") [next\\nRunning MLPerf™ Inference Benchmark](furiosa_mlperf.html \"next page\")\\nContents\\n* [Installing Furiosa LLM](#installing-furiosa-llm)   + [Offline Batch Inference with Furiosa LLM](#offline-batch-inference-with-furiosa-llm) * [Launching the OpenAI-Compatible Server](#launching-the-openai-compatible-server) * [Running Furiosa LLM in container environment](#running-furiosa-llm-in-container-environment)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/getting_started/furiosa_llm.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Quick Start with Furiosa LLM\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#installing-furiosa-llm\">\\n          Installing Furiosa LLM\\n         </a>\\n         <ul class=\"nav section-nav flex-column\">\\n          <li class=\"toc-h3 nav-item toc-entry\">\\n           <a class=\"reference internal nav-link\" href=\"#offline-batch-inference-with-furiosa-llm\">\\n            Offline Batch Inference with Furiosa LLM\\n           </a>\\n          </li>\\n         </ul>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#launching-the-openai-compatible-server\">\\n          Launching the OpenAI-Compatible Server\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#running-furiosa-llm-in-container-environment\">\\n          Running Furiosa LLM in container environment\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"quick-start-with-furiosa-llm\">\\n     <span id=\"gettingstartedfuriosallm\">\\n     </span>\\n     <h1>\\n      Quick Start with Furiosa LLM\\n      <a class=\"headerlink\" href=\"#quick-start-with-furiosa-llm\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      Furiosa LLM is a serving framework for LLM models that utilizes FuriosaAI’s NPU.\\nIt provides a Python API compatible with vLLM and a server compatible with the OpenAI API.\\nThis document explains how to install and use Furiosa LLM.\\n     </p>\\n     <div class=\"admonition warning\">\\n      <p class=\"admonition-title\">\\n       Warning\\n      </p>\\n      <p>\\n       This document is based on Furiosa SDK 2024.1.0 (alpha) version,\\nand the features and APIs described in this document may change in the future.\\n      </p>\\n     </div>\\n     <section id=\"installing-furiosa-llm\">\\n      <h2>\\n       Installing Furiosa LLM\\n       <a class=\"headerlink\" href=\"#installing-furiosa-llm\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The minimum requirements for Furiosa LLM are as follows:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         Ubuntu 20.04 LTS (Debian bullseye) or later\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Administrator privileges on system (root)\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         <a class=\"reference internal\" href=\"prerequisites.html#aptsetup\">\\n          <span class=\"std std-ref\">\\n           Setting up APT server\\n          </span>\\n         </a>\\n         and\\n         <a class=\"reference internal\" href=\"prerequisites.html#installingprerequisites\">\\n          <span class=\"std std-ref\">\\n           Installing Prerequisites\\n          </span>\\n         </a>\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Python 3.8, 3.9, or 3.10\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Enough storage space for model weights; e.g., about 100GB for Llama 3.1 70B model\\n        </p>\\n       </li>\\n      </ul>\\n      <p>\\n       Then, please install the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-compiler\\n        </span>\\n       </code>\\n       package as follows:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>-y<span class=\"w\"> </span>furiosa-compiler\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       Also, you need to create a Python virtual environment depending on your environment.\\n      </p>\\n      <div class=\"admonition note\">\\n       <p class=\"admonition-title\">\\n        Note\\n       </p>\\n       <p>\\n        Note that some models, such as meta-llama/Meta-Llama-3.1-8B require you to accept their license,\\nhence, you need to create a HuggingFace account, accept the model’s license, and generate a token.\\nUsually, you can create your token at\\n        <a class=\"reference external\" href=\"https://huggingface.co/settings/tokens\">\\n         https://huggingface.co/settings/tokens\\n        </a>\\n        .\\nOnce you get a token, you can authenticate on the HuggingFace Hub as following:\\n       </p>\\n       <div class=\"highlight-default notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span>huggingface-cli login --token $HF_TOKEN\\n</pre>\\n        </div>\\n       </div>\\n      </div>\\n      <p>\\n       Then, you can install the Furiosa LLM with the following command:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>pip<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-llm\\n</pre>\\n       </div>\\n      </div>\\n      <section id=\"offline-batch-inference-with-furiosa-llm\">\\n       <h3>\\n        Offline Batch Inference with Furiosa LLM\\n        <a class=\"headerlink\" href=\"#offline-batch-inference-with-furiosa-llm\" title=\"Link to this heading\">\\n         #\\n        </a>\\n       </h3>\\n       <p>\\n        In this section, we will explain how to perform offline LLM inference using the Python API of Furiosa LLM.\\nFirst, import the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          LLM\\n         </span>\\n        </code>\\n        class and\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          SamplingParams\\n         </span>\\n        </code>\\n        from the furiosa_llm module.\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          LLM\\n         </span>\\n        </code>\\n        class is used to load LLM models and provides the core API for LLM inference.\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          SamplingParams\\n         </span>\\n        </code>\\n        allows to specify various parameters for text generation.\\n       </p>\\n       <div class=\"highlight-python notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"kn\">from</span> <span class=\"nn\">furiosa_llm</span> <span class=\"kn\">import</span> <span class=\"n\">LLM</span><span class=\"p\">,</span> <span class=\"n\">SamplingParams</span>\\n</pre>\\n        </div>\\n       </div>\\n       <p>\\n        Next, we will load an LLM model using the LLM class.\\nThe following example loads the meta-llama/Meta-Llama-3.1-8B model from the HuggingFace Hub\\nand performs quantization. The model will be loaded into the memory and ready for inference.\\n       </p>\\n       <div class=\"highlight-python notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">llm</span> <span class=\"o\">=</span> <span class=\"n\">LLM</span><span class=\"p\">(</span><span class=\"n\">model</span><span class=\"o\">=</span><span class=\"s2\">\"meta-llama/Llama-3.1-8B-Instruct\"</span><span class=\"p\">)</span>\\n</pre>\\n        </div>\\n       </div>\\n       <p>\\n        After loading the model, you can perform LLM inference by calling the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          generate\\n         </span>\\n        </code>\\n        method.\\n       </p>\\n       <div class=\"highlight-python notranslate\">\\n        <div class=\"highlight\">\\n         <pre><span></span><span class=\"n\">prompts</span> <span class=\"o\">=</span> <span class=\"p\">[</span>\\n  <span class=\"s2\">\"\"</span>\\n<span class=\"p\">]</span>\\n<span class=\"n\">sampling_params</span> <span class=\"o\">=</span> <span class=\"n\">SamplingParams</span><span class=\"p\">(</span><span class=\"n\">temperature</span><span class=\"o\">=</span><span class=\"mf\">0.0</span><span class=\"p\">)</span>\\n</pre>\\n        </div>\\n       </div>\\n      </section>\\n     </section>\\n     <section id=\"launching-the-openai-compatible-server\">\\n      <h2>\\n       Launching the OpenAI-Compatible Server\\n       <a class=\"headerlink\" href=\"#launching-the-openai-compatible-server\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       You can find more details at\\n       <a class=\"reference internal\" href=\"../furiosa_llm/furiosa-llm-serve.html#openaiserver\">\\n        <span class=\"std std-ref\">\\n         OpenAI Compatible Server\\n        </span>\\n       </a>\\n       .\\n      </p>\\n     </section>\\n     <section id=\"running-furiosa-llm-in-container-environment\">\\n      <h2>\\n       Running Furiosa LLM in container environment\\n       <a class=\"headerlink\" href=\"#running-furiosa-llm-in-container-environment\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       FuriosaAI provides an image for running\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-llm\\n        </span>\\n       </code>\\n       in a containerized environment.\\nBy using the containerized version, you can run environments that utilize\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-llm\\n        </span>\\n       </code>\\n       without installing the FuriosaAI Software Stack on your host system,\\nor you can execute it within a Kubernetes environment.\\n      </p>\\n      <p>\\n       To run the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-llm\\n        </span>\\n       </code>\\n       container, you can use the following command:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>$<span class=\"w\"> </span>docker<span class=\"w\"> </span>run<span class=\"w\"> </span>-it<span class=\"w\"> </span>--rm<span class=\"w\"> </span>--privileged<span class=\"w\"> </span>furiosa-llm:2024.1.0<span class=\"w\"> </span>bash\\n\\n<span class=\"o\">(</span>container<span class=\"o\">)</span><span class=\"w\"> </span><span class=\"c1\"># python</span>\\n</pre>\\n       </div>\\n      </div>\\n      <div class=\"admonition warning\">\\n       <p class=\"admonition-title\">\\n        Warning\\n       </p>\\n       <p>\\n        The example above uses the\\n        <code class=\"docutils literal notranslate\">\\n         <span class=\"pre\">\\n          --privileged\\n         </span>\\n        </code>\\n        option for simplicity, but it is not recommended for security reasons.\\nIf you are using Kubernetes, please refer to the following page for the recommended method:\\n        <a class=\"reference internal\" href=\"../cloud_native_toolkit/intro.html#cloudnativetoolkit\">\\n         <span class=\"std std-ref\">\\n          Cloud Native Toolkit\\n         </span>\\n        </a>\\n       </p>\\n      </div>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"prerequisites.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Prerequisites\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"furiosa_mlperf.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Running MLPerf™ Inference Benchmark\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#installing-furiosa-llm\">\\n         Installing Furiosa LLM\\n        </a>\\n        <ul class=\"nav section-nav flex-column\">\\n         <li class=\"toc-h3 nav-item toc-entry\">\\n          <a class=\"reference internal nav-link\" href=\"#offline-batch-inference-with-furiosa-llm\">\\n           Offline Batch Inference with Furiosa LLM\\n          </a>\\n         </li>\\n        </ul>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#launching-the-openai-compatible-server\">\\n         Launching the OpenAI-Compatible Server\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#running-furiosa-llm-in-container-environment\">\\n         Running Furiosa LLM in container environment\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='79971985-74d0-445e-8c78-a80a93ef215b', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/intro.html'), name='intro', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/cloud_native_toolkit/intro.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nCloud Native Toolkit\\n====================\\n\\n\\n\\n\\n\\nCloud Native Toolkit\\n[#](#cloud-native-toolkit \"Link to this heading\")\\n======================================================================\\n\\nFuriosaAI Cloud Native Toolkit is a software stack to enable FuriosaAI’s NPU product in Kubernetes and Container ecosystem.\\n\\n\\n\\n[previous\\n\\nSamplingParams](../furiosa_llm/references/sampling_params.html \"previous page\")\\n[next\\n\\nKubernetes Support](kubernetes.html \"next page\")\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/cloud_native_toolkit/intro.rst \"Download source file\") * .pdf\\nCloud Native Toolkit ====================\\nCloud Native Toolkit [#](#cloud-native-toolkit \"Link to this heading\") ======================================================================\\nFuriosaAI Cloud Native Toolkit is a software stack to enable FuriosaAI’s NPU product in Kubernetes and Container ecosystem.\\n[previous\\nSamplingParams](../furiosa_llm/references/sampling_params.html \"previous page\") [next\\nKubernetes Support](kubernetes.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/cloud_native_toolkit/intro.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Cloud Native Toolkit\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"cloud-native-toolkit\">\\n     <span id=\"cloudnativetoolkit\">\\n     </span>\\n     <h1>\\n      Cloud Native Toolkit\\n      <a class=\"headerlink\" href=\"#cloud-native-toolkit\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      FuriosaAI Cloud Native Toolkit is a software stack to enable FuriosaAI’s NPU product in Kubernetes and Container ecosystem.\\n     </p>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../furiosa_llm/references/sampling_params.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        SamplingParams\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"kubernetes.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Kubernetes Support\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='ccf0c765-aa95-4b97-bf6b-fe5650ff8858', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/rngd.html'), name='rngd', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/overview/rngd.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nFuriosaAI RNGD\\n==============\\n\\n\\n\\n\\n\\nFuriosaAI RNGD\\n[#](#furiosaai-rngd \"Link to this heading\")\\n==========================================================\\n\\nFuriosaAI’s second-generation Neural Processing Unit (NPU), RNGD, is a chip designed for deep learning inference,\\nsupporting high-performance Large Language Models (LLM), Multi-Modal LLM, Vision models,\\nand other deep learning models.\\n\\n\\nRNGD is based the Tensor Contraction Processor (TCP) architecture which\\nutilizes TSMC’s 5nm process node, and operates at 1.0 GHz. It offers 512 TOPS and 1024 TOPS of INT8 and INT4\\nperformance respectively. RNGD is configured with two HBM3 modules providing a memory bandwidth of 1.5 TB/s,\\nand supports PCIe Gen5 x16. For multi-tenant environments like Kubernetes and virtual environment,\\na single RNGD chip can work as 2, 4, 8 individual NPUs, each fully isolated with its own cores and memory bandwidth.\\nRNGD supports Single Root IO Virtualization (SR-IOV) and virtualization for multi-instance NPUs.\\n\\nPlease refer to the followings to learn more about TCP architecture and RNGD:\\n\\n* [TCP: A Tensor Contraction Processor for AI Workloads, ACM/IEEE ISCA 2024](https://ieeexplore.ieee.org/document/10609575)\\n  (\\n  [PDF](https://furiosa.ai/download/FuriosaAI-tensor-contraction-processor-isca24)\\n  )\\n* [FuriosaAI RNGD: A Tensor Contraction Processor for Sustainable AI Computing, Hotchips 2024](https://hc2024.hotchips.org/#clip=8jnhm5vdlsow)\\n* [Tensor Contraction Processor: The first future-proof AI chip architecture](https://furiosa.ai/blog/tensor-contraction-processor-ai-chip-architecture)\\n\\n\\nRNGD Hardware Specification\\n\\n[#](#id1 \"Link to this table\")\\n\\n\\n| Architecture | Tensor Contraction Processor |\\n| --- | --- |\\n| Process Node | TSMC 5nm |\\n| Frequency | 1.0GHz |\\n| BF16 | 256TFLOPS |\\n| FP8 | 512TFLOPS |\\n| INT8 | 512TOPS |\\n| INT4 | 1024TOPS |\\n| Memory Bandwidth | HBM3 1.5TB/s |\\n| Memory Capacity | HBM3 48GB |\\n| On-Chip SRAM | 256MB |\\n| Interconnect Interface | PCIe Gen5 x16 |\\n| Thermal Solution | Passive |\\n| Thermal Design Power (TDP) | 150W |\\n| Power Connector | 12VHPWR |\\n| Form Factor | PCIe dual-slot full-height 3/4 Length |\\n| Multi-Instance Support | 8 |\\n| Virtualization Support | Yes |\\n| SR-IOV | 8 Virtual Functions |\\n| ECC Memory Support | Yes |\\n| Secure Boot with Root of Trust | Yes |\\n\\n\\n\\n\\n[previous\\n\\nFuriosaAI Developer Center](../index.html \"previous page\")\\n[next\\n\\nFuriosaAI’s Software Stack](software_stack.html \"next page\")\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/overview/rngd.rst \"Download source file\") * .pdf\\nFuriosaAI RNGD ==============\\nFuriosaAI RNGD [#](#furiosaai-rngd \"Link to this heading\") ==========================================================\\nFuriosaAI’s second-generation Neural Processing Unit (NPU), RNGD, is a chip designed for deep learning inference, supporting high-performance Large Language Models (LLM), Multi-Modal LLM, Vision models, and other deep learning models.\\nRNGD is based the Tensor Contraction Processor (TCP) architecture which utilizes TSMC’s 5nm process node, and operates at 1.0 GHz. It offers 512 TOPS and 1024 TOPS of INT8 and INT4 performance respectively. RNGD is configured with two HBM3 modules providing a memory bandwidth of 1.5 TB/s, and supports PCIe Gen5 x16. For multi-tenant environments like Kubernetes and virtual environment, a single RNGD chip can work as 2, 4, 8 individual NPUs, each fully isolated with its own cores and memory bandwidth. RNGD supports Single Root IO Virtualization (SR-IOV) and virtualization for multi-instance NPUs.\\nPlease refer to the followings to learn more about TCP architecture and RNGD:\\n* [TCP: A Tensor Contraction Processor for AI Workloads, ACM/IEEE ISCA 2024](https://ieeexplore.ieee.org/document/10609575)   (   [PDF](https://furiosa.ai/download/FuriosaAI-tensor-contraction-processor-isca24)   ) * [FuriosaAI RNGD: A Tensor Contraction Processor for Sustainable AI Computing, Hotchips 2024](https://hc2024.hotchips.org/#clip=8jnhm5vdlsow) * [Tensor Contraction Processor: The first future-proof AI chip architecture](https://furiosa.ai/blog/tensor-contraction-processor-ai-chip-architecture)\\nRNGD Hardware Specification\\n[#](#id1 \"Link to this table\")\\n| Architecture | Tensor Contraction Processor | | --- | --- | | Process Node | TSMC 5nm | | Frequency | 1.0GHz | | BF16 | 256TFLOPS | | FP8 | 512TFLOPS | | INT8 | 512TOPS | | INT4 | 1024TOPS | | Memory Bandwidth | HBM3 1.5TB/s | | Memory Capacity | HBM3 48GB | | On-Chip SRAM | 256MB | | Interconnect Interface | PCIe Gen5 x16 | | Thermal Solution | Passive | | Thermal Design Power (TDP) | 150W | | Power Connector | 12VHPWR | | Form Factor | PCIe dual-slot full-height 3/4 Length | | Multi-Instance Support | 8 | | Virtualization Support | Yes | | SR-IOV | 8 Virtual Functions | | ECC Memory Support | Yes | | Secure Boot with Root of Trust | Yes |\\n[previous\\nFuriosaAI Developer Center](../index.html \"previous page\") [next\\nFuriosaAI’s Software Stack](software_stack.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/overview/rngd.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     FuriosaAI RNGD\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"furiosaai-rngd\">\\n     <span id=\"rngd\">\\n     </span>\\n     <h1>\\n      FuriosaAI RNGD\\n      <a class=\"headerlink\" href=\"#furiosaai-rngd\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      FuriosaAI’s second-generation Neural Processing Unit (NPU), RNGD, is a chip designed for deep learning inference,\\nsupporting high-performance Large Language Models (LLM), Multi-Modal LLM, Vision models,\\nand other deep learning models.\\n     </p>\\n     <figure class=\"align-center\">\\n      <a class=\"only-dark reference internal image-reference\" href=\"../_images/rngd_card.webp\">\\n       <img alt=\"FuriosaAI RNGD\" class=\"only-dark\" src=\"../_images/rngd_card.webp\" style=\"width: 650px;\"/>\\n      </a>\\n     </figure>\\n     <figure class=\"align-center\">\\n      <a class=\"only-light reference internal image-reference\" href=\"../_images/rngd_card.webp\">\\n       <img alt=\"FuriosaAI RNGD\" class=\"only-light\" src=\"../_images/rngd_card.webp\" style=\"width: 650px;\"/>\\n      </a>\\n     </figure>\\n     <p>\\n      RNGD is based the Tensor Contraction Processor (TCP) architecture which\\nutilizes TSMC’s 5nm process node, and operates at 1.0 GHz. It offers 512 TOPS and 1024 TOPS of INT8 and INT4\\nperformance respectively. RNGD is configured with two HBM3 modules providing a memory bandwidth of 1.5 TB/s,\\nand supports PCIe Gen5 x16. For multi-tenant environments like Kubernetes and virtual environment,\\na single RNGD chip can work as 2, 4, 8 individual NPUs, each fully isolated with its own cores and memory bandwidth.\\nRNGD supports Single Root IO Virtualization (SR-IOV) and virtualization for multi-instance NPUs.\\n     </p>\\n     <p>\\n      Please refer to the followings to learn more about TCP architecture and RNGD:\\n     </p>\\n     <ul class=\"simple\">\\n      <li>\\n       <p>\\n        <a class=\"reference external\" href=\"https://ieeexplore.ieee.org/document/10609575\">\\n         TCP: A Tensor Contraction Processor for AI Workloads, ACM/IEEE ISCA 2024\\n        </a>\\n        (\\n        <a class=\"reference external\" href=\"https://furiosa.ai/download/FuriosaAI-tensor-contraction-processor-isca24\">\\n         PDF\\n        </a>\\n        )\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        <a class=\"reference external\" href=\"https://hc2024.hotchips.org/#clip=8jnhm5vdlsow\">\\n         FuriosaAI RNGD: A Tensor Contraction Processor for Sustainable AI Computing, Hotchips 2024\\n        </a>\\n       </p>\\n      </li>\\n      <li>\\n       <p>\\n        <a class=\"reference external\" href=\"https://furiosa.ai/blog/tensor-contraction-processor-ai-chip-architecture\">\\n         Tensor Contraction Processor: The first future-proof AI chip architecture\\n        </a>\\n       </p>\\n      </li>\\n     </ul>\\n     <div class=\"pst-scrollable-table-container\">\\n      <table class=\"table table-center\" id=\"id1\">\\n       <caption>\\n        <span class=\"caption-text\">\\n         RNGD Hardware Specification\\n        </span>\\n        <a class=\"headerlink\" href=\"#id1\" title=\"Link to this table\">\\n         #\\n        </a>\\n       </caption>\\n       <colgroup>\\n        <col style=\"width: 40.0%\"/>\\n        <col style=\"width: 60.0%\"/>\\n       </colgroup>\\n       <tbody>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Architecture\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           Tensor Contraction Processor\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Process Node\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           TSMC 5nm\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Frequency\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           1.0GHz\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           BF16\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           256TFLOPS\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           FP8\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           512TFLOPS\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           INT8\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           512TOPS\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           INT4\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           1024TOPS\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Memory Bandwidth\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           HBM3 1.5TB/s\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Memory Capacity\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           HBM3 48GB\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           On-Chip SRAM\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           256MB\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Interconnect Interface\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           PCIe Gen5 x16\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Thermal Solution\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           Passive\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Thermal Design Power (TDP)\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           150W\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Power Connector\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           12VHPWR\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Form Factor\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           PCIe dual-slot full-height 3/4 Length\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Multi-Instance Support\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           8\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           Virtualization Support\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           Yes\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           SR-IOV\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           8 Virtual Functions\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-odd\">\\n         <td>\\n          <p>\\n           ECC Memory Support\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           Yes\\n          </p>\\n         </td>\\n        </tr>\\n        <tr class=\"row-even\">\\n         <td>\\n          <p>\\n           Secure Boot with Root of Trust\\n          </p>\\n         </td>\\n         <td>\\n          <p>\\n           Yes\\n          </p>\\n         </td>\\n        </tr>\\n       </tbody>\\n      </table>\\n     </div>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../index.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        FuriosaAI Developer Center\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"software_stack.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        FuriosaAI’s Software Stack\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='a214fb49-b797-4d38-b877-597b6bb059eb', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/getting_started/prerequisites.html'), name='prerequisites', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../_sources/getting_started/prerequisites.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nInstalling Prerequisites\\n========================\\n\\n\\nContents\\n--------\\n\\n\\n* [Requirements](#requirements)\\n* [Verifying if the system has devices](#verifying-if-the-system-has-devices)\\n* [Setting up APT server](#setting-up-apt-server)\\n* [Installing Pre-requisite Packages](#installing-pre-requisite-packages)\\n* [Checking NPU devices](#checking-npu-devices)\\n* [Upgrading Device Firmware](#upgrading-device-firmware)\\n\\n\\n\\n\\n\\nInstalling Prerequisites\\n[#](#installing-prerequisites \"Link to this heading\")\\n==============================================================================\\n\\nWe will explain how to install the prerequisite packages necessary for FuriosaAI software stack.\\nThe prerequisite packages include device driver, firmware, and PE Runtime.\\nThese packages are available in package format for installation on Debian and Ubuntu systems.\\n\\nRequirements\\n[#](#requirements \"Link to this heading\")\\n------------------------------------------------------\\n\\nThe minimum requirements are as follows:\\n\\n* Ubuntu 20.04 LTS (or Debian bullseye) or later\\n* Administrator privileges on system (root)\\n\\nVerifying if the system has devices\\n[#](#verifying-if-the-system-has-devices \"Link to this heading\")\\n----------------------------------------------------------------------------------------------------\\n\\nYou can verify the proper installation of FuriosaAI’s devices on your machine by running the following commands:\\n\\n```\\nlspci -nn | grep FuriosaAI\\n\\n```\\n\\nIf the device is properly installed, you should see the PCI information as shown below.\\n\\n```\\n4e:00.0 Processing accelerators [1200]: FuriosaAI, Inc. Device [1ed2:0001] (rev 01)\\n\\n```\\n\\nIf the\\n`lspci`\\ncommand is not available, please install the following packages and run the commands to update PCIe ID database:\\n\\n```\\nsudo apt update\\nsudo apt install -y pciutils\\nsudo update-pciids\\n\\n```\\n\\n\\n\\nSetting up APT server\\n[#](#setting-up-apt-server \"Link to this heading\")\\n------------------------------------------------------------------------\\n\\nTo use the APT server provided by FuriosaAI, you must configure it on Ubuntu or Debian Linux as outlined below.\\n\\n1. Install the required packages and register the signing key.\\n\\n```\\nsudo apt update\\nsudo apt install -y curl gnupg\\ncurl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/cloud.google.gpg\\n\\n```\\n\\n2. Configure the APT server according to the instructions provided for the Linux distribution versions.\\n\\n> ```\\n> echo \"deb [arch=$(dpkg --print-architecture)] http://asia-northeast3-apt.pkg.dev/projects/furiosa-ai $(. /etc/os-release && echo \"$VERSION_CODENAME\") main\" | sudo tee /etc/apt/sources.list.d/furiosa.list\\n> \\n> ```\\n\\n\\nInstalling Pre-requisite Packages\\n[#](#installing-pre-requisite-packages \"Link to this heading\")\\n------------------------------------------------------------------------------------------------\\n\\nIf you have registered the APT server as described above, you will be able to install the required packages: the device driver and PE Runtime.\\n\\n```\\nsudo apt update\\nsudo apt install furiosa-pert-rngd furiosa-driver-rngd\\n\\n```\\n\\n[furiosa-smi](../device_management/furiosa_smi.html#furiosasmi)\\nis an useful CLI tool for listing and managing FuriosaAI NPUs.\\n\\n```\\nsudo apt install furiosa-smi\\n\\n```\\n\\n\\n\\nChecking NPU devices\\n[#](#checking-npu-devices \"Link to this heading\")\\n----------------------------------------------------------------------\\n\\nOnce the device driver and\\n[furiosa-smi](../device_management/furiosa_smi.html#furiosasmi)\\nare successfully installed,\\nyou can check the list of NPU devices as following command:\\n\\n```\\nfuriosa-smi info\\n\\n```\\n\\nOutput:\\n\\n```\\n+------+--------+----------------+---------+---------+--------------+\\n| Arch | Device | Firmware       | Temp.   | Power   | PCI-BDF      |\\n+------+--------+----------------+---------+---------+--------------+\\n| rngd | npu0   | 0.0.16+b4a67ca | 28.88°C | 38.00 W | 0000:4e:00.0 |\\n+------+--------+----------------+---------+---------+--------------+\\n\\n```\\n\\nPlease refer to\\n[furiosa-smi](../device_management/furiosa_smi.html#furiosasmi)\\nto learn more about\\n`furiosa-smi`\\ncommand.\\n\\n\\nUpgrading Device Firmware\\n[#](#upgrading-device-firmware \"Link to this heading\")\\n--------------------------------------------------------------------------------\\n\\nUpgrading firmware versions can improve the performance and stability of the devices.\\nIf there is newer firmware in the latest release, you can upgrade them using the following methods:\\n\\n```\\nsudo apt install furiosa-firmware-tools-rngd\\nsudo apt install furiosa-firmware-image-rngd\\n\\n```\\n\\nInstalling the\\n`furiosa-firmware-image-rngd`\\npackage will automatically upgrade the firmware.\\nThe process takes approximately 3 to 5 minutes per device to complete.\\n\\n\\n\\n\\n[previous\\n\\nRoadmap](../overview/roadmap.html \"previous page\")\\n[next\\n\\nQuick Start with Furiosa LLM](furiosa_llm.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Requirements](#requirements)\\n* [Verifying if the system has devices](#verifying-if-the-system-has-devices)\\n* [Setting up APT server](#setting-up-apt-server)\\n* [Installing Pre-requisite Packages](#installing-pre-requisite-packages)\\n* [Checking NPU devices](#checking-npu-devices)\\n* [Upgrading Device Firmware](#upgrading-device-firmware)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../_sources/getting_started/prerequisites.rst \"Download source file\") * .pdf\\nInstalling Prerequisites ========================\\nContents --------\\n* [Requirements](#requirements) * [Verifying if the system has devices](#verifying-if-the-system-has-devices) * [Setting up APT server](#setting-up-apt-server) * [Installing Pre-requisite Packages](#installing-pre-requisite-packages) * [Checking NPU devices](#checking-npu-devices) * [Upgrading Device Firmware](#upgrading-device-firmware)\\nInstalling Prerequisites [#](#installing-prerequisites \"Link to this heading\") ==============================================================================\\nWe will explain how to install the prerequisite packages necessary for FuriosaAI software stack. The prerequisite packages include device driver, firmware, and PE Runtime. These packages are available in package format for installation on Debian and Ubuntu systems.\\nRequirements [#](#requirements \"Link to this heading\") ------------------------------------------------------\\nThe minimum requirements are as follows:\\n* Ubuntu 20.04 LTS (or Debian bullseye) or later * Administrator privileges on system (root)\\nVerifying if the system has devices [#](#verifying-if-the-system-has-devices \"Link to this heading\") ----------------------------------------------------------------------------------------------------\\nYou can verify the proper installation of FuriosaAI’s devices on your machine by running the following commands:\\n``` lspci -nn | grep FuriosaAI\\n```\\nIf the device is properly installed, you should see the PCI information as shown below.\\n``` 4e:00.0 Processing accelerators [1200]: FuriosaAI, Inc. Device [1ed2:0001] (rev 01)\\n```\\nIf the `lspci` command is not available, please install the following packages and run the commands to update PCIe ID database:\\n``` sudo apt update sudo apt install -y pciutils sudo update-pciids\\n```\\nSetting up APT server [#](#setting-up-apt-server \"Link to this heading\") ------------------------------------------------------------------------\\nTo use the APT server provided by FuriosaAI, you must configure it on Ubuntu or Debian Linux as outlined below.\\n1. Install the required packages and register the signing key.\\n``` sudo apt update sudo apt install -y curl gnupg curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo gpg --dearmor -o /etc/apt/trusted.gpg.d/cloud.google.gpg\\n```\\n2. Configure the APT server according to the instructions provided for the Linux distribution versions.\\n> ``` > echo \"deb [arch=$(dpkg --print-architecture)] http://asia-northeast3-apt.pkg.dev/projects/furiosa-ai $(. /etc/os-release && echo \"$VERSION_CODENAME\") main\" | sudo tee /etc/apt/sources.list.d/furiosa.list >  > ```\\nInstalling Pre-requisite Packages [#](#installing-pre-requisite-packages \"Link to this heading\") ------------------------------------------------------------------------------------------------\\nIf you have registered the APT server as described above, you will be able to install the required packages: the device driver and PE Runtime.\\n``` sudo apt update sudo apt install furiosa-pert-rngd furiosa-driver-rngd\\n```\\n[furiosa-smi](../device_management/furiosa_smi.html#furiosasmi) is an useful CLI tool for listing and managing FuriosaAI NPUs.\\n``` sudo apt install furiosa-smi\\n```\\nChecking NPU devices [#](#checking-npu-devices \"Link to this heading\") ----------------------------------------------------------------------\\nOnce the device driver and [furiosa-smi](../device_management/furiosa_smi.html#furiosasmi) are successfully installed, you can check the list of NPU devices as following command:\\n``` furiosa-smi info\\n```\\nOutput:\\n``` +------+--------+----------------+---------+---------+--------------+ | Arch | Device | Firmware       | Temp.   | Power   | PCI-BDF      | +------+--------+----------------+---------+---------+--------------+ | rngd | npu0   | 0.0.16+b4a67ca | 28.88°C | 38.00 W | 0000:4e:00.0 | +------+--------+----------------+---------+---------+--------------+\\n```\\nPlease refer to [furiosa-smi](../device_management/furiosa_smi.html#furiosasmi) to learn more about `furiosa-smi` command.\\nUpgrading Device Firmware [#](#upgrading-device-firmware \"Link to this heading\") --------------------------------------------------------------------------------\\nUpgrading firmware versions can improve the performance and stability of the devices. If there is newer firmware in the latest release, you can upgrade them using the following methods:\\n``` sudo apt install furiosa-firmware-tools-rngd sudo apt install furiosa-firmware-image-rngd\\n```\\nInstalling the `furiosa-firmware-image-rngd` package will automatically upgrade the firmware. The process takes approximately 3 to 5 minutes per device to complete.\\n[previous\\nRoadmap](../overview/roadmap.html \"previous page\") [next\\nQuick Start with Furiosa LLM](furiosa_llm.html \"next page\")\\nContents\\n* [Requirements](#requirements) * [Verifying if the system has devices](#verifying-if-the-system-has-devices) * [Setting up APT server](#setting-up-apt-server) * [Installing Pre-requisite Packages](#installing-pre-requisite-packages) * [Checking NPU devices](#checking-npu-devices) * [Upgrading Device Firmware](#upgrading-device-firmware)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../_sources/getting_started/prerequisites.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Installing Prerequisites\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#requirements\">\\n          Requirements\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#verifying-if-the-system-has-devices\">\\n          Verifying if the system has devices\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#setting-up-apt-server\">\\n          Setting up APT server\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#installing-pre-requisite-packages\">\\n          Installing Pre-requisite Packages\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#checking-npu-devices\">\\n          Checking NPU devices\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#upgrading-device-firmware\">\\n          Upgrading Device Firmware\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"installing-prerequisites\">\\n     <span id=\"installingprerequisites\">\\n     </span>\\n     <h1>\\n      Installing Prerequisites\\n      <a class=\"headerlink\" href=\"#installing-prerequisites\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      We will explain how to install the prerequisite packages necessary for FuriosaAI software stack.\\nThe prerequisite packages include device driver, firmware, and PE Runtime.\\nThese packages are available in package format for installation on Debian and Ubuntu systems.\\n     </p>\\n     <section id=\"requirements\">\\n      <h2>\\n       Requirements\\n       <a class=\"headerlink\" href=\"#requirements\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       The minimum requirements are as follows:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         Ubuntu 20.04 LTS (or Debian bullseye) or later\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         Administrator privileges on system (root)\\n        </p>\\n       </li>\\n      </ul>\\n     </section>\\n     <section id=\"verifying-if-the-system-has-devices\">\\n      <h2>\\n       Verifying if the system has devices\\n       <a class=\"headerlink\" href=\"#verifying-if-the-system-has-devices\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       You can verify the proper installation of FuriosaAI’s devices on your machine by running the following commands:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>lspci<span class=\"w\"> </span>-nn<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>grep<span class=\"w\"> </span>FuriosaAI\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       If the device is properly installed, you should see the PCI information as shown below.\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>4e:00.0<span class=\"w\"> </span>Processing<span class=\"w\"> </span>accelerators<span class=\"w\"> </span><span class=\"o\">[</span><span class=\"m\">1200</span><span class=\"o\">]</span>:<span class=\"w\"> </span>FuriosaAI,<span class=\"w\"> </span>Inc.<span class=\"w\"> </span>Device<span class=\"w\"> </span><span class=\"o\">[</span>1ed2:0001<span class=\"o\">]</span><span class=\"w\"> </span><span class=\"o\">(</span>rev<span class=\"w\"> </span><span class=\"m\">01</span><span class=\"o\">)</span>\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       If the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         lspci\\n        </span>\\n       </code>\\n       command is not available, please install the following packages and run the commands to update PCIe ID database:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>update\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>-y<span class=\"w\"> </span>pciutils\\nsudo<span class=\"w\"> </span>update-pciids\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"setting-up-apt-server\">\\n      <span id=\"aptsetup\">\\n      </span>\\n      <h2>\\n       Setting up APT server\\n       <a class=\"headerlink\" href=\"#setting-up-apt-server\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       To use the APT server provided by FuriosaAI, you must configure it on Ubuntu or Debian Linux as outlined below.\\n      </p>\\n      <ol class=\"arabic simple\">\\n       <li>\\n        <p>\\n         Install the required packages and register the signing key.\\n        </p>\\n       </li>\\n      </ol>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>update\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>-y<span class=\"w\"> </span>curl<span class=\"w\"> </span>gnupg\\ncurl<span class=\"w\"> </span>https://packages.cloud.google.com/apt/doc/apt-key.gpg<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>sudo<span class=\"w\"> </span>gpg<span class=\"w\"> </span>--dearmor<span class=\"w\"> </span>-o<span class=\"w\"> </span>/etc/apt/trusted.gpg.d/cloud.google.gpg\\n</pre>\\n       </div>\\n      </div>\\n      <ol class=\"arabic simple\" start=\"2\">\\n       <li>\\n        <p>\\n         Configure the APT server according to the instructions provided for the Linux distribution versions.\\n        </p>\\n       </li>\\n      </ol>\\n      <blockquote>\\n       <div>\\n        <div class=\"highlight-sh notranslate\">\\n         <div class=\"highlight\">\\n          <pre><span></span><span class=\"nb\">echo</span><span class=\"w\"> </span><span class=\"s2\">\"deb [arch=</span><span class=\"k\">$(</span>dpkg<span class=\"w\"> </span>--print-architecture<span class=\"k\">)</span><span class=\"s2\">] http://asia-northeast3-apt.pkg.dev/projects/furiosa-ai </span><span class=\"k\">$(</span>.<span class=\"w\"> </span>/etc/os-release<span class=\"w\"> </span><span class=\"o\">&amp;&amp;</span><span class=\"w\"> </span><span class=\"nb\">echo</span><span class=\"w\"> </span><span class=\"s2\">\"</span><span class=\"nv\">$VERSION_CODENAME</span><span class=\"s2\">\"</span><span class=\"k\">)</span><span class=\"s2\"> main\"</span><span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>sudo<span class=\"w\"> </span>tee<span class=\"w\"> </span>/etc/apt/sources.list.d/furiosa.list\\n</pre>\\n         </div>\\n        </div>\\n       </div>\\n      </blockquote>\\n     </section>\\n     <section id=\"installing-pre-requisite-packages\">\\n      <h2>\\n       Installing Pre-requisite Packages\\n       <a class=\"headerlink\" href=\"#installing-pre-requisite-packages\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       If you have registered the APT server as described above, you will be able to install the required packages: the device driver and PE Runtime.\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>update\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-pert-rngd<span class=\"w\"> </span>furiosa-driver-rngd\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       <a class=\"reference internal\" href=\"../device_management/furiosa_smi.html#furiosasmi\">\\n        <span class=\"std std-ref\">\\n         furiosa-smi\\n        </span>\\n       </a>\\n       is an useful CLI tool for listing and managing FuriosaAI NPUs.\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-smi\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"checking-npu-devices\">\\n      <h2>\\n       Checking NPU devices\\n       <a class=\"headerlink\" href=\"#checking-npu-devices\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Once the device driver and\\n       <a class=\"reference internal\" href=\"../device_management/furiosa_smi.html#furiosasmi\">\\n        <span class=\"std std-ref\">\\n         furiosa-smi\\n        </span>\\n       </a>\\n       are successfully installed,\\nyou can check the list of NPU devices as following command:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>furiosa-smi<span class=\"w\"> </span>info\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       Output:\\n      </p>\\n      <div class=\"highlight-default notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>+------+--------+----------------+---------+---------+--------------+\\n| Arch | Device | Firmware       | Temp.   | Power   | PCI-BDF      |\\n+------+--------+----------------+---------+---------+--------------+\\n| rngd | npu0   | 0.0.16+b4a67ca | 28.88°C | 38.00 W | 0000:4e:00.0 |\\n+------+--------+----------------+---------+---------+--------------+\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       Please refer to\\n       <a class=\"reference internal\" href=\"../device_management/furiosa_smi.html#furiosasmi\">\\n        <span class=\"std std-ref\">\\n         furiosa-smi\\n        </span>\\n       </a>\\n       to learn more about\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-smi\\n        </span>\\n       </code>\\n       command.\\n      </p>\\n     </section>\\n     <section id=\"upgrading-device-firmware\">\\n      <h2>\\n       Upgrading Device Firmware\\n       <a class=\"headerlink\" href=\"#upgrading-device-firmware\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       Upgrading firmware versions can improve the performance and stability of the devices.\\nIf there is newer firmware in the latest release, you can upgrade them using the following methods:\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>sudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-firmware-tools-rngd\\nsudo<span class=\"w\"> </span>apt<span class=\"w\"> </span>install<span class=\"w\"> </span>furiosa-firmware-image-rngd\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       Installing the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa-firmware-image-rngd\\n        </span>\\n       </code>\\n       package will automatically upgrade the firmware.\\nThe process takes approximately 3 to 5 minutes per device to complete.\\n      </p>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"../overview/roadmap.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Roadmap\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"furiosa_llm.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Quick Start with Furiosa LLM\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#requirements\">\\n         Requirements\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#verifying-if-the-system-has-devices\">\\n         Verifying if the system has devices\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#setting-up-apt-server\">\\n         Setting up APT server\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#installing-pre-requisite-packages\">\\n         Installing Pre-requisite Packages\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#checking-npu-devices\">\\n         Checking NPU devices\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#upgrading-device-firmware\">\\n         Upgrading Device Firmware\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n'),\n",
       " Page(id='1ba93fae-bf2e-42c1-a66d-dabbee880912', link=HttpUrl('https://furiosa-ai.github.io/docs-dev/2024.1/en/cloud_native_toolkit/kubernetes/scheduling_npus.html'), name='scheduling_npus', parent='', child=[], description='\\n\\n\\n\\n\\n* [.rst](../../_sources/cloud_native_toolkit/kubernetes/scheduling_npus.rst \"Download source file\")\\n* .pdf\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nScheduling NPUs\\n===============\\n\\n\\nContents\\n--------\\n\\n\\n* [Preparing Node](#preparing-node)\\n* [Requesting NPUs](#requesting-npus)\\n* [Scheduling NPUs With Specific Requirements](#scheduling-npus-with-specific-requirements)\\n\\n\\n\\n\\n\\nScheduling NPUs\\n[#](#scheduling-npus \"Link to this heading\")\\n============================================================\\n\\nThis page describes how administrator prepares node and user can consume NPU in Kubernetes.\\n\\nPreparing Node\\n[#](#preparing-node \"Link to this heading\")\\n----------------------------------------------------------\\n\\nAs an administrator, you have to install\\n[prerequisites](../../getting_started/prerequisites.html#installingprerequisites)\\nsuch as driver, firmware on nodes and deploy\\n[Furiosa Device Plugin](device_plugin.html#deviceplugin)\\n.\\nOnce you have installed it, your cluster exposes Furiosa NPUs as schedulable resources, such as\\n`furiosa.ai/rngd`\\n.\\n\\nTo ensure your node is ready, you can examine Capacity and/or Allocatable field of\\n`v1.node`\\nobject.\\nHere is an example of node that has 2 RNGD NPUs:\\n\\n```\\n...\\nstatus:\\n  ...\\n  allocatable:\\n    cpu: \"20\"\\n    ephemeral-storage: \"1770585791219\"\\n    furiosa.ai/rngd: \"2\"\\n    hugepages-1Gi: \"0\"\\n    hugepages-2Mi: \"0\"\\n    memory: 527727860Ki\\n    pods: \"110\"\\n  capacity:\\n    cpu: \"20\"\\n    ephemeral-storage: 1921208544Ki\\n    furiosa.ai/rngd: \"2\"\\n    hugepages-1Gi: \"0\"\\n    hugepages-2Mi: \"0\"\\n    memory: 527830260Ki\\n    pods: \"110\"\\n...\\n\\n```\\n\\nThe following command should show the\\n`Capacity`\\nfield of each node in the Kubernetes cluster.\\n\\n```\\nkubectl get nodes -o json | jq -r \\'.items[] | .metadata.name as $name | .status.capacity | to_entries | map(\"    \\\\(.key): \\\\(.value)\") | $name + \":\\\\n  capacity:\\\\n\" + join(\"\\\\n\")\\'\\n\\n```\\n\\n\\n\\nRequesting NPUs\\n[#](#requesting-npus \"Link to this heading\")\\n------------------------------------------------------------\\n\\nYou can consume NPUs from your containers in a Pod by requesting NPU resources, the same way you request CPU or memory.\\n\\nHowever, since NPUs are exposed as a custom resource, there are some limitations you should be aware of when requesting NPU resources:\\n\\n* You can specify NPU\\n  `limits`\\n  without specifying\\n  `requests`\\n  , because kubernetes will use limit as request if request is not specified.\\n* You can specify NPU in both\\n  `limits`\\n  and\\n  `requests`\\n  but these two values must be equal.\\n* You cannot specify NPU\\n  `request`\\n  without specifying\\n  `limits`\\n  .\\n\\nHere is an example manifest for a Pod that requests 2 RNGD NPUs:\\n\\n```\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: example-npu-request\\nspec:\\n  containers:\\n  - name: furiosa\\n    image: furiosaai/furiosa-smi:latest\\n    imagePullPolicy: IfNotPresent\\n    command: [\"sleep\"]\\n    args: [\"120\"]\\n    resources:\\n      limits:\\n        furiosa.ai/rngd: 2\\n\\n```\\n\\n\\n\\nScheduling NPUs With Specific Requirements\\n[#](#scheduling-npus-with-specific-requirements \"Link to this heading\")\\n------------------------------------------------------------------------------------------------------------------\\n\\nIn certain cases, user may need to schedule NPU workload on node that meet specific hardware or software requirements, such as particular driver versions.\\nIf the\\n[Furiosa Feature Discovery](feature_discovery.html#featurediscovery)\\nis deployed in your cluster, nodes are automatically labelled based on their hardware and software configurations including driver version.\\nThis allows user to schedule Pod on nodes that meet specific requirements.\\n\\nFollowing example shows how to use affinity to schedule a Pod that request 2 RNGD NPUs with specific driver version:\\n\\n```\\napiVersion: v1\\nkind: Pod\\nmetadata:\\n  name: example-npu-scheduling-with-affinity\\nspec:\\n  containers:\\n  - name: furiosa\\n    image: furiosaai/furiosa-smi:latest\\n    imagePullPolicy: IfNotPresent\\n    command: [\"sleep\"]\\n    args: [\"120\"]\\n    resources:\\n      limits:\\n        furiosa.ai/rngd: 2\\n  affinity:\\n    nodeAffinity:\\n      requiredDuringSchedulingIgnoredDuringExecution:\\n        nodeSelectorTerms:\\n        - matchExpressions:\\n          - key: furiosa.ai/driver-version\\n            operator: In\\n            values:\\n            - \"1.0.12\"\\n\\n```\\n\\n\\n\\n\\n\\n[previous\\n\\nInstalling Furiosa Metrics Exporter](metrics_exporter.html \"previous page\")\\n[next\\n\\nfuriosa-smi](../../device_management/furiosa_smi.html \"next page\")\\n\\n\\n\\nContents\\n\\n* [Preparing Node](#preparing-node)\\n* [Requesting NPUs](#requesting-npus)\\n* [Scheduling NPUs With Specific Requirements](#scheduling-npus-with-specific-requirements)\\n\\n\\n\\n\\n\\nBy FuriosaAI, Inc.\\n\\n\\n© Copyright 2024, FuriosaAI, Inc..\\n  \\n\\n\\n\\n\\n\\n\\n\\n\\n', description_clean='* [.rst](../../_sources/cloud_native_toolkit/kubernetes/scheduling_npus.rst \"Download source file\") * .pdf\\nScheduling NPUs ===============\\nContents --------\\n* [Preparing Node](#preparing-node) * [Requesting NPUs](#requesting-npus) * [Scheduling NPUs With Specific Requirements](#scheduling-npus-with-specific-requirements)\\nScheduling NPUs [#](#scheduling-npus \"Link to this heading\") ============================================================\\nThis page describes how administrator prepares node and user can consume NPU in Kubernetes.\\nPreparing Node [#](#preparing-node \"Link to this heading\") ----------------------------------------------------------\\nAs an administrator, you have to install [prerequisites](../../getting_started/prerequisites.html#installingprerequisites) such as driver, firmware on nodes and deploy [Furiosa Device Plugin](device_plugin.html#deviceplugin) .\\nOnce you have installed it, your cluster exposes Furiosa NPUs as schedulable resources, such as `furiosa.ai/rngd` .\\nTo ensure your node is ready, you can examine Capacity and/or Allocatable field of `v1.node` object. Here is an example of node that has 2 RNGD NPUs:\\n``` ... status:   ...   allocatable:     cpu: \"20\"     ephemeral-storage: \"1770585791219\"     furiosa.ai/rngd: \"2\"     hugepages-1Gi: \"0\"     hugepages-2Mi: \"0\"     memory: 527727860Ki     pods: \"110\"   capacity:     cpu: \"20\"     ephemeral-storage: 1921208544Ki     furiosa.ai/rngd: \"2\"     hugepages-1Gi: \"0\"     hugepages-2Mi: \"0\"     memory: 527830260Ki     pods: \"110\" ...\\n```\\nThe following command should show the `Capacity` field of each node in the Kubernetes cluster.\\n``` kubectl get nodes -o json | jq -r \\'.items[] | .metadata.name as $name | .status.capacity | to_entries | map(\"    \\\\(.key): \\\\(.value)\") | $name + \":\\\\n  capacity:\\\\n\" + join(\"\\\\n\")\\'\\n```\\nRequesting NPUs [#](#requesting-npus \"Link to this heading\") ------------------------------------------------------------\\nYou can consume NPUs from your containers in a Pod by requesting NPU resources, the same way you request CPU or memory.\\nHowever, since NPUs are exposed as a custom resource, there are some limitations you should be aware of when requesting NPU resources:\\n* You can specify NPU   `limits`   without specifying   `requests`   , because kubernetes will use limit as request if request is not specified. * You can specify NPU in both   `limits`   and   `requests`   but these two values must be equal. * You cannot specify NPU   `request`   without specifying   `limits`   .\\nHere is an example manifest for a Pod that requests 2 RNGD NPUs:\\n``` apiVersion: v1 kind: Pod metadata:   name: example-npu-request spec:   containers:   - name: furiosa     image: furiosaai/furiosa-smi:latest     imagePullPolicy: IfNotPresent     command: [\"sleep\"]     args: [\"120\"]     resources:       limits:         furiosa.ai/rngd: 2\\n```\\nScheduling NPUs With Specific Requirements [#](#scheduling-npus-with-specific-requirements \"Link to this heading\") ------------------------------------------------------------------------------------------------------------------\\nIn certain cases, user may need to schedule NPU workload on node that meet specific hardware or software requirements, such as particular driver versions. If the [Furiosa Feature Discovery](feature_discovery.html#featurediscovery) is deployed in your cluster, nodes are automatically labelled based on their hardware and software configurations including driver version. This allows user to schedule Pod on nodes that meet specific requirements.\\nFollowing example shows how to use affinity to schedule a Pod that request 2 RNGD NPUs with specific driver version:\\n``` apiVersion: v1 kind: Pod metadata:   name: example-npu-scheduling-with-affinity spec:   containers:   - name: furiosa     image: furiosaai/furiosa-smi:latest     imagePullPolicy: IfNotPresent     command: [\"sleep\"]     args: [\"120\"]     resources:       limits:         furiosa.ai/rngd: 2   affinity:     nodeAffinity:       requiredDuringSchedulingIgnoredDuringExecution:         nodeSelectorTerms:         - matchExpressions:           - key: furiosa.ai/driver-version             operator: In             values:             - \"1.0.12\"\\n```\\n[previous\\nInstalling Furiosa Metrics Exporter](metrics_exporter.html \"previous page\") [next\\nfuriosa-smi](../../device_management/furiosa_smi.html \"next page\")\\nContents\\n* [Preparing Node](#preparing-node) * [Requesting NPUs](#requesting-npus) * [Scheduling NPUs With Specific Requirements](#scheduling-npus-with-specific-requirements)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', html_content='<main class=\"bd-main\" id=\"main-content\" role=\"main\">\\n <div class=\"sbt-scroll-pixel-helper\">\\n </div>\\n <div class=\"bd-content\">\\n  <div class=\"bd-article-container\">\\n   <div class=\"bd-header-article d-print-none\">\\n    <div class=\"header-article-items header-article__inner\">\\n     <div class=\"header-article-items__start\">\\n      <div class=\"header-article-item\">\\n       <button class=\"sidebar-toggle primary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle primary sidebar\">\\n        <span class=\"fa-solid fa-bars\">\\n        </span>\\n       </button>\\n      </div>\\n     </div>\\n     <div class=\"header-article-items__end\">\\n      <div class=\"header-article-item\">\\n       <div class=\"article-header-buttons\">\\n        <div class=\"dropdown dropdown-download-buttons\">\\n         <button aria-expanded=\"false\" aria-label=\"Download this page\" class=\"btn dropdown-toggle\" data-bs-toggle=\"dropdown\" type=\"button\">\\n          <i class=\"fas fa-download\">\\n          </i>\\n         </button>\\n         <ul class=\"dropdown-menu\">\\n          <li>\\n           <a class=\"btn btn-sm btn-download-source-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" href=\"../../_sources/cloud_native_toolkit/kubernetes/scheduling_npus.rst\" target=\"_blank\" title=\"Download source file\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .rst\\n            </span>\\n           </a>\\n          </li>\\n          <li>\\n           <button class=\"btn btn-sm btn-download-pdf-button dropdown-item\" data-bs-placement=\"left\" data-bs-toggle=\"tooltip\" onclick=\"window.print()\" title=\"Print to PDF\">\\n            <span class=\"btn__icon-container\">\\n             <i class=\"fas fa-file-pdf\">\\n             </i>\\n            </span>\\n            <span class=\"btn__text-container\">\\n             .pdf\\n            </span>\\n           </button>\\n          </li>\\n         </ul>\\n        </div>\\n        <button class=\"btn btn-sm btn-fullscreen-button\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" onclick=\"toggleFullScreen()\" title=\"Fullscreen mode\">\\n         <span class=\"btn__icon-container\">\\n          <i class=\"fas fa-expand\">\\n          </i>\\n         </span>\\n        </button>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm nav-link pst-navbar-icon theme-switch-button\" title=\"light/dark\" aria-label=\"light/dark\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"theme-switch fa-solid fa-sun fa-lg\" data-mode=\"light\"></i>\\n    <i class=\"theme-switch fa-solid fa-moon fa-lg\" data-mode=\"dark\"></i>\\n    <i class=\"theme-switch fa-solid fa-circle-half-stroke fa-lg\" data-mode=\"auto\"></i>\\n  </button>\\n`);\\n        </script>\\n        <script>\\n         document.write(`\\n  <button class=\"btn btn-sm pst-navbar-icon search-button search-button__button\" title=\"Search\" aria-label=\"Search\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\">\\n    <i class=\"fa-solid fa-magnifying-glass fa-lg\"></i>\\n  </button>\\n`);\\n        </script>\\n        <button class=\"sidebar-toggle secondary-toggle btn btn-sm\" data-bs-placement=\"bottom\" data-bs-toggle=\"tooltip\" title=\"Toggle secondary sidebar\">\\n         <span class=\"fa-solid fa-list\">\\n         </span>\\n        </button>\\n       </div>\\n      </div>\\n     </div>\\n    </div>\\n   </div>\\n   <div class=\"onlyprint\" id=\"jb-print-docs-body\">\\n    <h1>\\n     Scheduling NPUs\\n    </h1>\\n    <!-- Table of contents -->\\n    <div id=\"print-main-content\">\\n     <div id=\"jb-print-toc\">\\n      <div>\\n       <h2>\\n        Contents\\n       </h2>\\n      </div>\\n      <nav aria-label=\"Page\">\\n       <ul class=\"visible nav section-nav flex-column\">\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#preparing-node\">\\n          Preparing Node\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#requesting-npus\">\\n          Requesting NPUs\\n         </a>\\n        </li>\\n        <li class=\"toc-h2 nav-item toc-entry\">\\n         <a class=\"reference internal nav-link\" href=\"#scheduling-npus-with-specific-requirements\">\\n          Scheduling NPUs With Specific Requirements\\n         </a>\\n        </li>\\n       </ul>\\n      </nav>\\n     </div>\\n    </div>\\n   </div>\\n   <div id=\"searchbox\">\\n   </div>\\n   <article class=\"bd-article\">\\n    <section id=\"scheduling-npus\">\\n     <span id=\"schedulingnpus\">\\n     </span>\\n     <h1>\\n      Scheduling NPUs\\n      <a class=\"headerlink\" href=\"#scheduling-npus\" title=\"Link to this heading\">\\n       #\\n      </a>\\n     </h1>\\n     <p>\\n      This page describes how administrator prepares node and user can consume NPU in Kubernetes.\\n     </p>\\n     <section id=\"preparing-node\">\\n      <h2>\\n       Preparing Node\\n       <a class=\"headerlink\" href=\"#preparing-node\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       As an administrator, you have to install\\n       <a class=\"reference internal\" href=\"../../getting_started/prerequisites.html#installingprerequisites\">\\n        <span class=\"std std-ref\">\\n         prerequisites\\n        </span>\\n       </a>\\n       such as driver, firmware on nodes and deploy\\n       <a class=\"reference internal\" href=\"device_plugin.html#deviceplugin\">\\n        <span class=\"std std-ref\">\\n         Furiosa Device Plugin\\n        </span>\\n       </a>\\n       .\\nOnce you have installed it, your cluster exposes Furiosa NPUs as schedulable resources, such as\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         furiosa.ai/rngd\\n        </span>\\n       </code>\\n       .\\n      </p>\\n      <p>\\n       To ensure your node is ready, you can examine Capacity and/or Allocatable field of\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         v1.node\\n        </span>\\n       </code>\\n       object.\\nHere is an example of node that has 2 RNGD NPUs:\\n      </p>\\n      <div class=\"highlight-yaml notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span><span class=\"nn\">...</span>\\n<span class=\"nt\">status</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"l l-Scalar l-Scalar-Plain\">...</span>\\n<span class=\"w\">  </span><span class=\"l l-Scalar l-Scalar-Plain\">allocatable</span><span class=\"p p-Indicator\">:</span>\\n<span class=\"w\">    </span><span class=\"nt\">cpu</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"20\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">ephemeral-storage</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"1770585791219\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">furiosa.ai/rngd</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"2\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">hugepages-1Gi</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"0\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">hugepages-2Mi</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"0\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">memory</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">527727860Ki</span>\\n<span class=\"w\">    </span><span class=\"nt\">pods</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"110\"</span>\\n<span class=\"w\">  </span><span class=\"nt\">capacity</span><span class=\"p\">:</span>\\n<span class=\"w\">    </span><span class=\"nt\">cpu</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"20\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">ephemeral-storage</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">1921208544Ki</span>\\n<span class=\"w\">    </span><span class=\"nt\">furiosa.ai/rngd</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"2\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">hugepages-1Gi</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"0\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">hugepages-2Mi</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"0\"</span>\\n<span class=\"w\">    </span><span class=\"nt\">memory</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">527830260Ki</span>\\n<span class=\"w\">    </span><span class=\"nt\">pods</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s\">\"110\"</span>\\n<span class=\"nn\">...</span>\\n</pre>\\n       </div>\\n      </div>\\n      <p>\\n       The following command should show the\\n       <code class=\"docutils literal notranslate\">\\n        <span class=\"pre\">\\n         Capacity\\n        </span>\\n       </code>\\n       field of each node in the Kubernetes cluster.\\n      </p>\\n      <div class=\"highlight-sh notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span>kubectl<span class=\"w\"> </span>get<span class=\"w\"> </span>nodes<span class=\"w\"> </span>-o<span class=\"w\"> </span>json<span class=\"w\"> </span><span class=\"p\">|</span><span class=\"w\"> </span>jq<span class=\"w\"> </span>-r<span class=\"w\"> </span><span class=\"s1\">\\'.items[] | .metadata.name as $name | .status.capacity | to_entries | map(\"    \\\\(.key): \\\\(.value)\") | $name + \":\\\\n  capacity:\\\\n\" + join(\"\\\\n\")\\'</span>\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"requesting-npus\">\\n      <h2>\\n       Requesting NPUs\\n       <a class=\"headerlink\" href=\"#requesting-npus\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       You can consume NPUs from your containers in a Pod by requesting NPU resources, the same way you request CPU or memory.\\n      </p>\\n      <p>\\n       However, since NPUs are exposed as a custom resource, there are some limitations you should be aware of when requesting NPU resources:\\n      </p>\\n      <ul class=\"simple\">\\n       <li>\\n        <p>\\n         You can specify NPU\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           limits\\n          </span>\\n         </code>\\n         without specifying\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           requests\\n          </span>\\n         </code>\\n         , because kubernetes will use limit as request if request is not specified.\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         You can specify NPU in both\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           limits\\n          </span>\\n         </code>\\n         and\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           requests\\n          </span>\\n         </code>\\n         but these two values must be equal.\\n        </p>\\n       </li>\\n       <li>\\n        <p>\\n         You cannot specify NPU\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           request\\n          </span>\\n         </code>\\n         without specifying\\n         <code class=\"docutils literal notranslate\">\\n          <span class=\"pre\">\\n           limits\\n          </span>\\n         </code>\\n         .\\n        </p>\\n       </li>\\n      </ul>\\n      <p>\\n       Here is an example manifest for a Pod that requests 2 RNGD NPUs:\\n      </p>\\n      <div class=\"highlight-yaml notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span><span class=\"nt\">apiVersion</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">v1</span>\\n<span class=\"nt\">kind</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">Pod</span>\\n<span class=\"nt\">metadata</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"nt\">name</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">example-npu-request</span>\\n<span class=\"nt\">spec</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"nt\">containers</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">name</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">furiosa</span>\\n<span class=\"w\">    </span><span class=\"nt\">image</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">furiosaai/furiosa-smi:latest</span>\\n<span class=\"w\">    </span><span class=\"nt\">imagePullPolicy</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">IfNotPresent</span>\\n<span class=\"w\">    </span><span class=\"nt\">command</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"s\">\"sleep\"</span><span class=\"p p-Indicator\">]</span>\\n<span class=\"w\">    </span><span class=\"nt\">args</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"s\">\"120\"</span><span class=\"p p-Indicator\">]</span>\\n<span class=\"w\">    </span><span class=\"nt\">resources</span><span class=\"p\">:</span>\\n<span class=\"w\">      </span><span class=\"nt\">limits</span><span class=\"p\">:</span>\\n<span class=\"w\">        </span><span class=\"nt\">furiosa.ai/rngd</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">2</span>\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n     <section id=\"scheduling-npus-with-specific-requirements\">\\n      <h2>\\n       Scheduling NPUs With Specific Requirements\\n       <a class=\"headerlink\" href=\"#scheduling-npus-with-specific-requirements\" title=\"Link to this heading\">\\n        #\\n       </a>\\n      </h2>\\n      <p>\\n       In certain cases, user may need to schedule NPU workload on node that meet specific hardware or software requirements, such as particular driver versions.\\nIf the\\n       <a class=\"reference internal\" href=\"feature_discovery.html#featurediscovery\">\\n        <span class=\"std std-ref\">\\n         Furiosa Feature Discovery\\n        </span>\\n       </a>\\n       is deployed in your cluster, nodes are automatically labelled based on their hardware and software configurations including driver version.\\nThis allows user to schedule Pod on nodes that meet specific requirements.\\n      </p>\\n      <p>\\n       Following example shows how to use affinity to schedule a Pod that request 2 RNGD NPUs with specific driver version:\\n      </p>\\n      <div class=\"highlight-yaml notranslate\">\\n       <div class=\"highlight\">\\n        <pre><span></span><span class=\"nt\">apiVersion</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">v1</span>\\n<span class=\"nt\">kind</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">Pod</span>\\n<span class=\"nt\">metadata</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"nt\">name</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">example-npu-scheduling-with-affinity</span>\\n<span class=\"nt\">spec</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"nt\">containers</span><span class=\"p\">:</span>\\n<span class=\"w\">  </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">name</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">furiosa</span>\\n<span class=\"w\">    </span><span class=\"nt\">image</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">furiosaai/furiosa-smi:latest</span>\\n<span class=\"w\">    </span><span class=\"nt\">imagePullPolicy</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">IfNotPresent</span>\\n<span class=\"w\">    </span><span class=\"nt\">command</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"s\">\"sleep\"</span><span class=\"p p-Indicator\">]</span>\\n<span class=\"w\">    </span><span class=\"nt\">args</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p p-Indicator\">[</span><span class=\"s\">\"120\"</span><span class=\"p p-Indicator\">]</span>\\n<span class=\"w\">    </span><span class=\"nt\">resources</span><span class=\"p\">:</span>\\n<span class=\"w\">      </span><span class=\"nt\">limits</span><span class=\"p\">:</span>\\n<span class=\"w\">        </span><span class=\"nt\">furiosa.ai/rngd</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">2</span>\\n<span class=\"w\">  </span><span class=\"nt\">affinity</span><span class=\"p\">:</span>\\n<span class=\"w\">    </span><span class=\"nt\">nodeAffinity</span><span class=\"p\">:</span>\\n<span class=\"w\">      </span><span class=\"nt\">requiredDuringSchedulingIgnoredDuringExecution</span><span class=\"p\">:</span>\\n<span class=\"w\">        </span><span class=\"nt\">nodeSelectorTerms</span><span class=\"p\">:</span>\\n<span class=\"w\">        </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">matchExpressions</span><span class=\"p\">:</span>\\n<span class=\"w\">          </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"nt\">key</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">furiosa.ai/driver-version</span>\\n<span class=\"w\">            </span><span class=\"nt\">operator</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"l l-Scalar l-Scalar-Plain\">In</span>\\n<span class=\"w\">            </span><span class=\"nt\">values</span><span class=\"p\">:</span>\\n<span class=\"w\">            </span><span class=\"p p-Indicator\">-</span><span class=\"w\"> </span><span class=\"s\">\"1.0.12\"</span>\\n</pre>\\n       </div>\\n      </div>\\n     </section>\\n    </section>\\n   </article>\\n   <footer class=\"prev-next-footer d-print-none\">\\n    <div class=\"prev-next-area\">\\n     <a class=\"left-prev\" href=\"metrics_exporter.html\" title=\"previous page\">\\n      <i class=\"fa-solid fa-angle-left\">\\n      </i>\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        previous\\n       </p>\\n       <p class=\"prev-next-title\">\\n        Installing Furiosa Metrics Exporter\\n       </p>\\n      </div>\\n     </a>\\n     <a class=\"right-next\" href=\"../../device_management/furiosa_smi.html\" title=\"next page\">\\n      <div class=\"prev-next-info\">\\n       <p class=\"prev-next-subtitle\">\\n        next\\n       </p>\\n       <p class=\"prev-next-title\">\\n        furiosa-smi\\n       </p>\\n      </div>\\n      <i class=\"fa-solid fa-angle-right\">\\n      </i>\\n     </a>\\n    </div>\\n   </footer>\\n  </div>\\n  <div class=\"bd-sidebar-secondary bd-toc\">\\n   <div class=\"sidebar-secondary-items sidebar-secondary__inner\">\\n    <div class=\"sidebar-secondary-item\">\\n     <div class=\"page-toc tocsection onthispage\">\\n      <i class=\"fa-solid fa-list\">\\n      </i>\\n      Contents\\n     </div>\\n     <nav class=\"bd-toc-nav page-toc\">\\n      <ul class=\"visible nav section-nav flex-column\">\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#preparing-node\">\\n         Preparing Node\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#requesting-npus\">\\n         Requesting NPUs\\n        </a>\\n       </li>\\n       <li class=\"toc-h2 nav-item toc-entry\">\\n        <a class=\"reference internal nav-link\" href=\"#scheduling-npus-with-specific-requirements\">\\n         Scheduling NPUs With Specific Requirements\\n        </a>\\n       </li>\\n      </ul>\\n     </nav>\\n    </div>\\n   </div>\\n  </div>\\n </div>\\n <footer class=\"bd-footer-content\">\\n  <div class=\"bd-footer-content__inner container\">\\n   <div class=\"footer-item\">\\n    <p class=\"component-author\">\\n     By FuriosaAI, Inc.\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n    <p class=\"copyright\">\\n     © Copyright 2024, FuriosaAI, Inc..\\n     <br/>\\n    </p>\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n   <div class=\"footer-item\">\\n   </div>\\n  </div>\\n </footer>\\n</main>\\n')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "version_name = 'rngd'\n",
    "data_dir = f'../../data/db/db-{version_name}_sdk.json'\n",
    "\n",
    "with open(data_dir, \"r\") as f:\n",
    "    data = json.load(f)\n",
    "    all_pages = [Page.model_validate_json(page) for page in data['sdk']]\n",
    "\n",
    "def find_page_with_url(url: str) -> Page:\n",
    "    for page in all_pages:\n",
    "        if str(page.link) == url:\n",
    "            return page\n",
    "    return None\n",
    "\n",
    "all_pages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "라마인덱스 \"Document\"로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert page to llama index Document and TextNode\n",
    "docs = [convert_page_to_llama_index_document(page) for page in all_pages]\n",
    "nodes = [TextNode(id_=doc.id_, text=doc.text, metadata=doc.metadata) for doc in docs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 챗봇 테스트 (link 인풋으로 직접 넣어주기)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletionResponse(text='Hello! How can I assist you today?', additional_kwargs={'model': 'llama3.1:70b', 'created_at': '2024-12-23T21:09:10.876773727Z', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 15339, 128009, 128006, 78191, 128007, 271, 9906, 0, 2650, 649, 358, 7945, 499, 3432, 30], 'total_duration': 198428672560, 'load_duration': 197643985909, 'prompt_eval_count': 12, 'prompt_eval_duration': 114793000, 'eval_count': 10, 'eval_duration': 666525000}, raw={'model': 'llama3.1:70b', 'created_at': '2024-12-23T21:09:10.876773727Z', 'response': 'Hello! How can I assist you today?', 'done': True, 'done_reason': 'stop', 'context': [128009, 128006, 882, 128007, 271, 15339, 128009, 128006, 78191, 128007, 271, 9906, 0, 2650, 649, 358, 7945, 499, 3432, 30], 'total_duration': 198428672560, 'load_duration': 197643985909, 'prompt_eval_count': 12, 'prompt_eval_duration': 114793000, 'eval_count': 10, 'eval_duration': 666525000}, logprobs=None, delta=None)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define LLM\n",
    "import os\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "\n",
    "llm = Ollama(model=\"llama3.1:70b\", request_timeout=600,temperature=0)\n",
    "llm.complete(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"You are a highly knowledgeable assistant specializing in Furiosa's NPU SDK. Your task is to provide detailed and accurate responses to user queries about Furiosa SDK, including:\n",
    "\n",
    "1. Interpreting and explaining code examples.\n",
    "2. Providing guidance on CLI (Command Line Interface) commands and their usage.\n",
    "3. Offering detailed information about supported software and hardware configurations.\n",
    "\n",
    "For each query:\n",
    "- Extract key details from the question and the provided context.\n",
    "- Use the retrieved contents to generate a clear and step-by-step explanation.\n",
    "- Always include relevant examples or commands, where applicable, to enhance understanding.\n",
    "\n",
    "Make sure your response is concise but comprehensive, ensuring the user can act on your guidance immediately.\n",
    "\n",
    "Question:\n",
    "{query}\n",
    "\n",
    "Context:\n",
    "{retrieved_contents}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Query:\n",
      "What is bert?\n",
      "============================================================\n",
      "\n",
      "\n",
      "* link_gt:\n",
      "https://furiosa-ai.github.io/docs-dev/2024.1/en/getting_started/furiosa_mlperf.html\n",
      "============================================================\n",
      "\n",
      "\n",
      "* ChatBot response:\n",
      "**What is BERT?**\n",
      "\n",
      "BERT (Bidirectional Encoder Representations from Transformers) is a popular deep learning model for natural language processing (NLP) tasks. It was developed by Google and introduced in the paper \"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\" in 2018.\n",
      "\n",
      "In the context of Furiosa's NPU SDK, BERT is one of the benchmarks used to evaluate the performance of machine learning models on FuriosaAI's hardware and software platforms. Specifically, the `furiosa-mlperf` command provides a subcommand called `bert-server` and `bert-offline`, which allow users to run BERT benchmark with server scenario and offline scenario, respectively.\n",
      "\n",
      "**Running BERT Benchmark**\n",
      "\n",
      "To run the BERT benchmark using the `furiosa-mlperf` command, you can use the following examples:\n",
      "\n",
      "* Server Scenario:\n",
      "```bash\n",
      "furiosa-mlperf bert-server ./bert-large ./bert-server-result --device-mesh \"npu:0:*\"\n",
      "```\n",
      "* Offline Scenario:\n",
      "```bash\n",
      "furiosa-mlperf bert-offline ./bert-large ./bert-offline-result --device-mesh \"npu:0:*\"\n",
      "```\n",
      "\n",
      "These commands will run the BERT Large serving inference benchmark and offline inference benchmark, respectively. The results will be written to a file in the specified results directory.\n",
      "\n",
      "**Understanding the Results**\n",
      "\n",
      "Once the process completes, you can view a summary of the results by opening the `mlperf_log_summary.txt` file in the results directory. This file contains information such as:\n",
      "\n",
      "* SUT name: GPT-J SUT\n",
      "* Scenario: Offline\n",
      "* Mode: PerformanceOnly\n",
      "* Samples per second: 11.842\n",
      "* Tokens per second (inferred): 817.095\n",
      "* Result is: VALID\n",
      "\n",
      "This summary provides an overview of the benchmark results, including the performance metrics and whether the result is valid or not.\n",
      "\n",
      "I hope this helps! Let me know if you have any further questions.\n"
     ]
    }
   ],
   "source": [
    "# Manual test \n",
    "query_in = \"What is bert?\"\n",
    "\n",
    "link_in = 'https://furiosa-ai.github.io/docs-dev/2024.1/en/getting_started/furiosa_mlperf.html'\n",
    "document = convert_page_to_llama_index_document(find_page_with_url(link_in))\n",
    "\n",
    "print('* Query:')\n",
    "print(query_in)\n",
    "print(\"=\"*60)\n",
    "print('\\n')\n",
    "\n",
    "print('* link_gt:')\n",
    "print(link_in)\n",
    "print(\"=\"*60)\n",
    "print('\\n')\n",
    "\n",
    "print('* ChatBot response:')\n",
    "\n",
    "full_prompt = prompt.format(query=query_in, retrieved_contents=document.text)\n",
    "result = llm.complete(full_prompt)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 벡터DB 설정과 Retriever 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jwlee-pro/anaconda3/envs/llm-quantize/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Define embedding\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"dunzhang/stella_en_1.5B_v5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load retriever from data dir\n",
    "# Save from html nodes\n",
    "import chromadb\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core.retrievers import VectorIndexRetriever\n",
    "\n",
    "vectordb_save_path = \"../../data/db/llama-index-resources/chroma\"\n",
    "collection_name = \"stella\"\n",
    "chroma_client = chromadb.PersistentClient(path=vectordb_save_path)\n",
    "chroma_collection = chroma_client.get_or_create_collection(collection_name)\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "# Save data\n",
    "index = VectorStoreIndex(nodes, storage_context=storage_context, embed_model=embed_model)\n",
    "# Load data\n",
    "# index = VectorStoreIndex.from_vector_store(\n",
    "#     vector_store, storage_context=storage_context, embed_model=embed_model,\n",
    "# )\n",
    "chroma_retriever = VectorIndexRetriever(index=index, similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load BM25Retriever\n",
    "- research에서 수집한 모든 페이지를 llama-index document로 변환 후 bm25에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding newlines for mmindex: 100%|██████████| 111k/111k [00:00<00:00, 127MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Save llama index document to bm25\n",
    "# Save html nodes\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "import Stemmer\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_defaults(\n",
    "    nodes=nodes,\n",
    "    similarity_top_k=5,\n",
    "    stemmer=Stemmer.Stemmer(\"english\"),\n",
    "    language=\"en\",\n",
    ")\n",
    "bm25_save_path = \"../../data/db/llama-index-resources/bm25\"\n",
    "bm25_retriever.persist(bm25_save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load bm25\n",
    "import Stemmer\n",
    "from llama_index.retrievers.bm25 import BM25Retriever\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_persist_dir(bm25_save_path)\n",
    "bm25_retriever.similarity_top_k = 5\n",
    "bm25_retriever.stemmer = Stemmer.Stemmer(\"english\")\n",
    "bm25_retriever.language = \"en\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hybrid\n",
    "- db: chroma + bm25 (두 방식이 상호보완적이므로)\n",
    "- normalize: dbsf\n",
    "- algorithm: Convex Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def normalize_dbsf(scores: List[str]):\n",
    "\tarr = np.array(scores)\n",
    "\tmean_value = np.mean(arr)\n",
    "\tstd_value = np.std(arr)\n",
    "\tmin_value = mean_value - 3 * std_value\n",
    "\tmax_value = mean_value + 3 * std_value\n",
    "\tnorm_score = (arr - min_value) / (max_value - min_value)\n",
    "\treturn norm_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def hybrid_cc(lexical_results, semantic_results, top_k=5, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Perform hybrid search using convex combination of BM25 and semantic scores.\n",
    "    \n",
    "    :param query: Search query (string)\n",
    "    :param alpha: Weight for BM25 scores (0 <= alpha <= 1). 1-alpha is weight for semantic scores.\n",
    "    \"\"\"\n",
    "    # Step 1: Perform BM25 Search\n",
    "    bm25_ids = np.array([result.id_ for result in lexical_results])\n",
    "    bm25_scores = np.array([result.score for result in lexical_results])\n",
    "    \n",
    "    # Step 2: Perform Semantic Search using ChromaRetriever\n",
    "    chroma_ids = np.array([result.id_ for result in semantic_results])\n",
    "    chroma_scores = np.array([result.score for result in semantic_results])\n",
    "    \n",
    "    # Step 3: Normalize the Scores\n",
    "    bm25_scores_norm = normalize_dbsf(bm25_scores)\n",
    "    chroma_scores_norm = normalize_dbsf(chroma_scores)\n",
    "\n",
    "    ids = [bm25_ids, chroma_ids]\n",
    "    scores = [bm25_scores_norm, chroma_scores_norm]\n",
    "    \n",
    "    df = pd.concat(\n",
    "\t\t[pd.Series(dict(zip(_id, score))) for _id, score in zip(ids, scores)], axis=1\n",
    "\t)\n",
    "    df.columns = [\"semantic\", \"lexical\"]\n",
    "    df = df.fillna(0)\n",
    "    df[\"weighted_sum\"] = df.mul((alpha, 1.0 - alpha)).sum(axis=1)\n",
    "    df = df.sort_values(by=\"weighted_sum\", ascending=False)\n",
    "\n",
    "    retrieved_ids, retrieved_scores = df.index.tolist()[:top_k], df[\"weighted_sum\"][:top_k].tolist()\n",
    "    retrieved_contents = []\n",
    "    for idx, id in enumerate(retrieved_ids):\n",
    "        content = next((node for node in lexical_results if node.id_ == id), None)\n",
    "        if content is not None:\n",
    "            content.score = retrieved_scores[idx]\n",
    "            retrieved_contents.append(content)\n",
    "            continue\n",
    "        content = next((node for node in semantic_results if node.id_ == id), None)\n",
    "        if content is not None:\n",
    "            content.score = retrieved_scores[idx]\n",
    "            retrieved_contents.append(content)\n",
    "\n",
    "    return retrieved_contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cutoff\n",
    "from llama_index.core.postprocessor import SimilarityPostprocessor\n",
    "\n",
    "cutoff = SimilarityPostprocessor(similarity_cutoff=0.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 단계 별 실행 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기서부터 수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_id                  3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa\n",
      "link        https://furiosa-ai.github.io/docs-dev/2024.1/e...\n",
      "question    What are the planned features for Furiosa LLM'...\n",
      "answer      Planned features for Furiosa LLM include Tenso...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "qa_dir = f'../../data/chatbot/qa-{version_name}_sdk.csv'\n",
    "\n",
    "qa_with_link = pd.read_csv(qa_dir, encoding=\"utf-8\", index_col=0)\n",
    "print(qa_with_link.loc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_id</th>\n",
       "      <th>link</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the planned features for Furiosa LLM'...</td>\n",
       "      <td>Planned features for Furiosa LLM include Tenso...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the key features of Furiosa LLM that ...</td>\n",
       "      <td>Furiosa LLM features include a vLLM-compatible...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>How does Furiosa LLM manage efficient KV cache...</td>\n",
       "      <td>Furiosa LLM manages efficient KV cache through...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dcd59fbc-fb76-4f34-b6ec-ea88a833b047</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the default configuration values for ...</td>\n",
       "      <td>The default configuration values for deploying...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dcd59fbc-fb76-4f34-b6ec-ea88a833b047</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the functionalities provided by the F...</td>\n",
       "      <td>The Furiosa device plugin discovers Furiosa NP...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>a214fb49-b797-4d38-b877-597b6bb059eb</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What command can be used to verify the install...</td>\n",
       "      <td>The command 'lspci -nn | grep FuriosaAI' can b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>a214fb49-b797-4d38-b877-597b6bb059eb</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the necessary steps to upgrade the fi...</td>\n",
       "      <td>To upgrade the firmware of FuriosaAI devices, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1ba93fae-bf2e-42c1-a66d-dabbee880912</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What are the constraints when specifying NPU r...</td>\n",
       "      <td>When specifying NPU resources, you can set NPU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1ba93fae-bf2e-42c1-a66d-dabbee880912</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>How does the deployment of Furiosa Feature Dis...</td>\n",
       "      <td>Furiosa Feature Discovery labels nodes based o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>1ba93fae-bf2e-42c1-a66d-dabbee880912</td>\n",
       "      <td>https://furiosa-ai.github.io/docs-dev/2024.1/e...</td>\n",
       "      <td>What steps must an administrator take to prepa...</td>\n",
       "      <td>An administrator must install prerequisites li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 page_id  \\\n",
       "0   3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa   \n",
       "1   3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa   \n",
       "2   3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa   \n",
       "3   dcd59fbc-fb76-4f34-b6ec-ea88a833b047   \n",
       "4   dcd59fbc-fb76-4f34-b6ec-ea88a833b047   \n",
       "..                                   ...   \n",
       "58  a214fb49-b797-4d38-b877-597b6bb059eb   \n",
       "59  a214fb49-b797-4d38-b877-597b6bb059eb   \n",
       "60  1ba93fae-bf2e-42c1-a66d-dabbee880912   \n",
       "61  1ba93fae-bf2e-42c1-a66d-dabbee880912   \n",
       "62  1ba93fae-bf2e-42c1-a66d-dabbee880912   \n",
       "\n",
       "                                                 link  \\\n",
       "0   https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "1   https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "2   https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "3   https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "4   https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "..                                                ...   \n",
       "58  https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "59  https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "60  https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "61  https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "62  https://furiosa-ai.github.io/docs-dev/2024.1/e...   \n",
       "\n",
       "                                             question  \\\n",
       "0   What are the planned features for Furiosa LLM'...   \n",
       "1   What are the key features of Furiosa LLM that ...   \n",
       "2   How does Furiosa LLM manage efficient KV cache...   \n",
       "3   What are the default configuration values for ...   \n",
       "4   What are the functionalities provided by the F...   \n",
       "..                                                ...   \n",
       "58  What command can be used to verify the install...   \n",
       "59  What are the necessary steps to upgrade the fi...   \n",
       "60  What are the constraints when specifying NPU r...   \n",
       "61  How does the deployment of Furiosa Feature Dis...   \n",
       "62  What steps must an administrator take to prepa...   \n",
       "\n",
       "                                               answer  \n",
       "0   Planned features for Furiosa LLM include Tenso...  \n",
       "1   Furiosa LLM features include a vLLM-compatible...  \n",
       "2   Furiosa LLM manages efficient KV cache through...  \n",
       "3   The default configuration values for deploying...  \n",
       "4   The Furiosa device plugin discovers Furiosa NP...  \n",
       "..                                                ...  \n",
       "58  The command 'lspci -nn | grep FuriosaAI' can b...  \n",
       "59  To upgrade the firmware of FuriosaAI devices, ...  \n",
       "60  When specifying NPU resources, you can set NPU...  \n",
       "61  Furiosa Feature Discovery labels nodes based o...  \n",
       "62  An administrator must install prerequisites li...  \n",
       "\n",
       "[63 rows x 4 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What are the planned features for Furiosa LLM's future releases, and how do they enhance its capabilities?\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa_with_link['question'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer = 3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa \n",
      "\n",
      "----------\n",
      "[NodeWithScore(node=TextNode(id_='0acdfa06-7dff-4603-9a5c-dbc4e3310580', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/software_stack.html', 'title': 'software_stack', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/overview/software_stack.rst \"Download source file\") * .pdf\\nFuriosaAI’s Software Stack ==========================\\nContents --------\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nFuriosaAI’s Software Stack [#](#furiosaai-s-software-stack \"Link to this heading\") ==================================================================================\\nFuriosaAI provides the streamlined software stack to allow FuriosaAI NPU to be used in various applications and environments. Here, we outline the SW stack provided by FuriosaAI, explaining the roles of each component, together with guidelines and tutorials. The above diagram demonstrates the SW stack provided by FuriosaAI, by layers.\\nThe following outlines the key components.\\nKernel Driver, Firmware, and PE Runtime [#](#kernel-driver-firmware-and-pe-runtime \"Link to this heading\") ----------------------------------------------------------------------------------------------------------\\nThe kernel device driver enables the Linux operating system to recognize NPU devices and expose them as Linux device files. The firmware runs on the SoC within the RNGD card and provides low-level APIs to the PE Runtime (PERT) that runs on the Processing Element (PE). PERT is responsible for communicating with the host’s runtime and scheduling, managing the resources of PEs to execute NPU tasks.\\nFuriosa Compiler [#](#furiosa-compiler \"Link to this heading\") --------------------------------------------------------------\\nFuriosa compiler analyzes, optimizes a model graph, and generates a NPU executable program. The operation passes involve graph-level optimization, operator fusion, memory allocation optimization, scheduling, and data movement minimization across layers. When `torch.compile()` backend, `FuriosaBackend` is used or `furiosa-llm` is used, the Furiosa Compiler is transparently used to generate NPU executable programs for Runtime.\\nFuriosa Runtime [#](#furiosa-runtime \"Link to this heading\") ------------------------------------------------------------\\nRuntime loads multiple executable NPU programs generated by Furiosa compiler, and run them on the NPU. A single model can be compiled into multiple executable programs according to model architectures and applications. Runtime is responsible for scheduling NPU programs and managing computation and memory resource on NPUs and CPUs. Also, Runtime can use multiple NPUs and provides a single entry point to run the model on multiple NPUs.\\nFuriosa Model Compressor (Quantizer) [#](#furiosa-model-compressor-quantizer \"Link to this heading\") ----------------------------------------------------------------------------------------------------\\nFuriosa Model Compressor is a library as well as toolkit for model calibration and quantization. Model quantization is a powerful technique to reduce memory footprint, computation cost, inference latency and power consumption. Furiosa Model Compressor provides post-training quantization methods, such as\\n* BF16 (W16A16) * INT8 Weight-Only (W8A16) * FP8 (W8A8) * INT8 SmoothQuant (W8A8) * INT4 Weight-Only (W4A16 AWQ / GPTQ) (Planned in release 2024.2)\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ----------------------------------------------------\\nFuriosa LLM provides a high-performance inference engine for LLM models, such as Llama 3.1 70B, 8B, GPT-J, and Bert. Furiosa LLM is designed to provide the state-of-the-art serving optimization for LLM models. The key features of Furiosa LLM include vLLM-compatible API, PagedAttention, continuous batching, HuggingFace hub support, and OpenAI-compatible API server. You can find further information at [Furiosa LLM](../furiosa_llm/intro.html#furiosallm) .\\nKubernetes Support [#](#kubernetes-support \"Link to this heading\") ------------------------------------------------------------------\\nKubernetes, an open-source platform designed to manage containerized applications and services, is extensively adopted by various companies due to its robust capabilities for deploying, scaling, and automating containerized workloads. FuriosaAI software stack also offers native integration with Kubernetes, allowing seamless deployment and management of AI applications within a Kubernetes environment.\\nFuriosaAI’s device plugin enables Kubernetes clusters to recognize FuriosaAI’s NPUs and allows NPUs to be scheduled for workloads and services that require them. This feature allows users to easily deploy AI workloads with FuriosaAI NPUs on Kubernetes, enabling efficient resource utilization and scaling.\\nYou can find more information about Kubernetes support in the [Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit) .\\n[previous\\nFuriosaAI RNGD](rngd.html \"previous page\") [next\\nSupported Models](supported_models.html \"next page\")\\nContents\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.433814764022827), NodeWithScore(node=TextNode(id_='3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/intro.html', 'title': 'intro', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\") * .pdf\\nFuriosa LLM ===========\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ====================================================\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models, Furiosa LLM is designed to provide the state-of-the-art serving optimization. The features of Furiosa LLM includes:\\n* vLLM-compatible API * Efficient KV cache management with PagedAttention * Continuous batching of incoming requests in serving * Quantization: INT4, INT8, FP8, GPTQ, AWQ * Data Parallelism and Pipeline Parallelism across multiple NPUs * Tensor Parallelism (planned in release 2024.2) across multiple NPUs * OpenAI-compatible API server * Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned) * HuggingFace model integration and hub support * HuggingFace PEFT support (planned)\\n[previous\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.2418622970581055), NodeWithScore(node=TextNode(id_='a53038c2-0668-4963-875e-79abe9c99e2c', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/whatsnew/index.html', 'title': 'index', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/whatsnew/index.rst \"Download source file\") * .pdf\\nWhat’s New ==========\\nContents --------\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nWhat’s New [#](#what-s-new \"Link to this heading\") ==================================================\\nThis page describes the changes and functionality available in in the latest releases of Furiosa SDK 2024.1.0.\\nFuriosa SDK 2024.1.0 (2024-10-11) [#](#furiosa-sdk-2024-1-0-2024-10-11 \"Link to this heading\") ----------------------------------------------------------------------------------------------\\n2024.1.0 is the first SDK release for RNGD. This release is alpha release, and the features and APIs described in this document may change in the future.\\n### Highlights [#](#highlights \"Link to this heading\")\\n* Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B * Furiosa Quantizer supports the following quantization methods:      + BF16 (W16A16)   + INT8 Weight-Only (W8A16)   + FP8 (W8A8)   + INT8 SmoothQuant (W8A8) * Furiosa LLM      + Efficient KV cache management with PagedAttention   + Continuous batching support in serving   + OpenAI-compatible API server   + Greedy search and beam search   + Pipeline Parallelism and Data Parallelism across multiple NPUs * `furiosa-mlperf`   command      + Server and Offline scenarios   + BERT, GPT-J, LLaMA 3.1 benchmarks * System Management Interface      + System Management Interface Library and CLI for Furiosa NPU family * Cloud Native Toolkit      + Kubernetes integration for managing and monitoring the Furiosa NPU family\\nComponent version\\n[#](#id1 \"Link to this table\")\\n| Package name | Version | | --- | --- | | furiosa-compiler | 2024.1.0 | | furiosa-device-plugin | 2024.1.0 | | furiosa-driver-rngd | 2024.1.0 | | furiosa-feature-discovery | 2024.1.0 | | furiosa-firmware-image-tools | 2024.1.0 | | furiosa-firmware-image-rngd | 0.0.19 | | furiosa-libsmi | 2024.1.0 | | furiosa-llm | 2024.1.0 | | furiosa-llm-models | 2024.1.0 | | furiosa-mlperf | 2024.1.0 | | furiosa-mlperf-resources | 2024.1.0 | | furiosa-model-compressor | 2024.1.0 | | furiosa-model-compressor-impl | 2024.1.0 | | furiosa-native-compiler | 2024.1.0 | | furiosa-native-runtime | 2024.1.0 | | furiosa-smi | 2024.1.0 | | furiosa-torch-ext | 2024.1.0 |\\n[previous\\nSupported Models](../overview/supported_models.html \"previous page\") [next\\nRoadmap](../overview/roadmap.html \"next page\")\\nContents\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.134758949279785), NodeWithScore(node=TextNode(id_='13853744-dc18-4c98-b1c2-4f5806b28514', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/', 'title': '', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](_sources/index.rst \"Download source file\") * .pdf\\nFuriosaAI Developer Center ==========================\\nContents --------\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nFuriosaAI Developer Center [#](#furiosaai-developer-center \"Link to this heading\") ==================================================================================\\nWelcome to the FuriosaAI Developer Center. FuriosaAI provides an streamlined software stack for deep learning model inference on FuriosaAI NPUs. This document provides a guide to easily perform the entire workflow of writing inference applications, from starting with PyTorch model to model quantization, serving, and production deployment.\\nWarning\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version, and the features and APIs described in this document may change in the future.\\nOverview [#](#overview \"Link to this heading\") ----------------------------------------------\\n* [FuriosaAI RNGD](overview/rngd.html#rngd)   : RNGD Hardware Specification, and features * [FuriosaAI’s Software Stack](overview/software_stack.html#softwarestack)   : An overview of the FuriosaAI software stack * [Supported Models](overview/supported_models.html#supportedmodels)   : A list of supported models * [What’s New](whatsnew/index.html#whatsnew)   : New features and changes in the latest release * [Roadmap](overview/roadmap.html#roadmap)   : The future roadmap of FuriosaAI Software Stack\\nGetting Started [#](#getting-started \"Link to this heading\") ------------------------------------------------------------\\n* [Installing Prerequisites](getting_started/prerequisites.html#installingprerequisites)   : How to install the prerequisites for FuriosaAI Software Stack * [Quick Start with Furiosa LLM](getting_started/furiosa_llm.html#gettingstartedfuriosallm) * [Running MLPerf™ Inference Benchmark](getting_started/furiosa_mlperf.html#gettingstartedfuriosamlperf)\\nCloud Native Toolkit [#](#cloud-native-toolkit \"Link to this heading\") ----------------------------------------------------------------------\\n* [Cloud Native Toolkit](cloud_native_toolkit/intro.html#cloudnativetoolkit)   : An overview of the Cloud Native Toolkit * [Kubernetes Support](cloud_native_toolkit/kubernetes.html#kubernetes)   : An overview of the Kubernetes Support\\nDevice Management [#](#device-management \"Link to this heading\") ----------------------------------------------------------------\\n* [furiosa-smi](device_management/furiosa_smi.html#furiosasmi)   : A command line utility for managing FuriosaAI NPUs\\nCustomer Support [#](#customer-support \"Link to this heading\") --------------------------------------------------------------\\n* [FuriosaAI Homepage](https://furiosa.ai) * [FuriosaAI Forum](https://furiosa-ai.discourse.group/) * [FuriosaAI Customer Portal](https://furiosa-ai.atlassian.net/servicedesk/customer/portals/) * [FuriosaAI Warboy SDK Document](https://furiosa-ai.github.io/docs/latest/en/)\\n[next\\nFuriosaAI RNGD](overview/rngd.html \"next page\")\\nContents\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.042851448059082), NodeWithScore(node=TextNode(id_='d4927eaf-a1a0-40bd-9624-79db4213c5fc', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/roadmap.html', 'title': 'roadmap', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/overview/roadmap.rst \"Download source file\") * .pdf\\nRoadmap =======\\nContents --------\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nRoadmap [#](#roadmap \"Link to this heading\") ============================================\\nFurisaAI strives to deliver the releases for each month, while offering patch releases. This page shows the forward-looking roadmap of ongoing & upcoming projects and when they are expected to land, broken down by areas on [our software stack](software_stack.html#softwarestack) .\\nLatest Recent Release [#](#latest-recent-release \"Link to this heading\") ------------------------------------------------------------------------\\nThe latest release is 2024.1.0 (alpha) on October 11, 2024. You can find the release notes [here](../whatsnew/index.html#whatsnew) .\\nFuture Releases [#](#future-releases \"Link to this heading\") ------------------------------------------------------------\\nNote\\nThe roadmap is subject to change and may not reflect the final product.\\n### 2024.2.0 (beta 0) - November, 2024 [#](#beta-0-november-2024 \"Link to this heading\")\\n* Model support:      + Language Models: CodeLLaaMA2, Vicuna, Solar, EXAONE-3.0   + Vision Models: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, .. * (Furiosa LLM) Tensor Parallelism support Phase 1: Intra-chip * Torch 2.4.1 support * CPU memory swapping in Furiosa LLM\\n### 2024.3.0 (beta 1) - December, 2024 [#](#beta-1-december-2024 \"Link to this heading\")\\n* Model support: TBD * (Furiosa LLM) Tensor Parallelism support Phase 2: Inter-chip * `torch.compile()`   backend * Huggingface Optimum integration\\n[previous\\nWhat’s New](../whatsnew/index.html \"previous page\") [next\\nInstalling Prerequisites](../getting_started/prerequisites.html \"next page\")\\nContents\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=3.0420069694519043)]\n",
      "----------\n",
      "[NodeWithScore(node=TextNode(id_='3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/intro.html', 'title': 'intro', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\") * .pdf\\nFuriosa LLM ===========\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ====================================================\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models, Furiosa LLM is designed to provide the state-of-the-art serving optimization. The features of Furiosa LLM includes:\\n* vLLM-compatible API * Efficient KV cache management with PagedAttention * Continuous batching of incoming requests in serving * Quantization: INT4, INT8, FP8, GPTQ, AWQ * Data Parallelism and Pipeline Parallelism across multiple NPUs * Tensor Parallelism (planned in release 2024.2) across multiple NPUs * OpenAI-compatible API server * Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned) * HuggingFace model integration and hub support * HuggingFace PEFT support (planned)\\n[previous\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6566028339457801), NodeWithScore(node=TextNode(id_='a53038c2-0668-4963-875e-79abe9c99e2c', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/whatsnew/index.html', 'title': 'index', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/whatsnew/index.rst \"Download source file\") * .pdf\\nWhat’s New ==========\\nContents --------\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nWhat’s New [#](#what-s-new \"Link to this heading\") ==================================================\\nThis page describes the changes and functionality available in in the latest releases of Furiosa SDK 2024.1.0.\\nFuriosa SDK 2024.1.0 (2024-10-11) [#](#furiosa-sdk-2024-1-0-2024-10-11 \"Link to this heading\") ----------------------------------------------------------------------------------------------\\n2024.1.0 is the first SDK release for RNGD. This release is alpha release, and the features and APIs described in this document may change in the future.\\n### Highlights [#](#highlights \"Link to this heading\")\\n* Model Support: LLaMA 3.1 8B/70B, BERT Large, GPT-J 6B * Furiosa Quantizer supports the following quantization methods:      + BF16 (W16A16)   + INT8 Weight-Only (W8A16)   + FP8 (W8A8)   + INT8 SmoothQuant (W8A8) * Furiosa LLM      + Efficient KV cache management with PagedAttention   + Continuous batching support in serving   + OpenAI-compatible API server   + Greedy search and beam search   + Pipeline Parallelism and Data Parallelism across multiple NPUs * `furiosa-mlperf`   command      + Server and Offline scenarios   + BERT, GPT-J, LLaMA 3.1 benchmarks * System Management Interface      + System Management Interface Library and CLI for Furiosa NPU family * Cloud Native Toolkit      + Kubernetes integration for managing and monitoring the Furiosa NPU family\\nComponent version\\n[#](#id1 \"Link to this table\")\\n| Package name | Version | | --- | --- | | furiosa-compiler | 2024.1.0 | | furiosa-device-plugin | 2024.1.0 | | furiosa-driver-rngd | 2024.1.0 | | furiosa-feature-discovery | 2024.1.0 | | furiosa-firmware-image-tools | 2024.1.0 | | furiosa-firmware-image-rngd | 0.0.19 | | furiosa-libsmi | 2024.1.0 | | furiosa-llm | 2024.1.0 | | furiosa-llm-models | 2024.1.0 | | furiosa-mlperf | 2024.1.0 | | furiosa-mlperf-resources | 2024.1.0 | | furiosa-model-compressor | 2024.1.0 | | furiosa-model-compressor-impl | 2024.1.0 | | furiosa-native-compiler | 2024.1.0 | | furiosa-native-runtime | 2024.1.0 | | furiosa-smi | 2024.1.0 | | furiosa-torch-ext | 2024.1.0 |\\n[previous\\nSupported Models](../overview/supported_models.html \"previous page\") [next\\nRoadmap](../overview/roadmap.html \"next page\")\\nContents\\n* [Furiosa SDK 2024.1.0 (2024-10-11)](#furiosa-sdk-2024-1-0-2024-10-11)   + [Highlights](#highlights)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.5345927465047097), NodeWithScore(node=TextNode(id_='d4927eaf-a1a0-40bd-9624-79db4213c5fc', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/roadmap.html', 'title': 'roadmap', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/overview/roadmap.rst \"Download source file\") * .pdf\\nRoadmap =======\\nContents --------\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nRoadmap [#](#roadmap \"Link to this heading\") ============================================\\nFurisaAI strives to deliver the releases for each month, while offering patch releases. This page shows the forward-looking roadmap of ongoing & upcoming projects and when they are expected to land, broken down by areas on [our software stack](software_stack.html#softwarestack) .\\nLatest Recent Release [#](#latest-recent-release \"Link to this heading\") ------------------------------------------------------------------------\\nThe latest release is 2024.1.0 (alpha) on October 11, 2024. You can find the release notes [here](../whatsnew/index.html#whatsnew) .\\nFuture Releases [#](#future-releases \"Link to this heading\") ------------------------------------------------------------\\nNote\\nThe roadmap is subject to change and may not reflect the final product.\\n### 2024.2.0 (beta 0) - November, 2024 [#](#beta-0-november-2024 \"Link to this heading\")\\n* Model support:      + Language Models: CodeLLaaMA2, Vicuna, Solar, EXAONE-3.0   + Vision Models: MobileNetV1, MobileNetV2, ResNet152, ResNet50, EfficientNet, YOLOv8m, .. * (Furiosa LLM) Tensor Parallelism support Phase 1: Intra-chip * Torch 2.4.1 support * CPU memory swapping in Furiosa LLM\\n### 2024.3.0 (beta 1) - December, 2024 [#](#beta-1-december-2024 \"Link to this heading\")\\n* Model support: TBD * (Furiosa LLM) Tensor Parallelism support Phase 2: Inter-chip * `torch.compile()`   backend * Huggingface Optimum integration\\n[previous\\nWhat’s New](../whatsnew/index.html \"previous page\") [next\\nInstalling Prerequisites](../getting_started/prerequisites.html \"next page\")\\nContents\\n* [Latest Recent Release](#latest-recent-release) * [Future Releases](#future-releases)   + [2024.2.0 (beta 0) - November, 2024](#beta-0-november-2024)   + [2024.3.0 (beta 1) - December, 2024](#beta-1-december-2024)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.42308473409330327), NodeWithScore(node=TextNode(id_='0acdfa06-7dff-4603-9a5c-dbc4e3310580', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/overview/software_stack.html', 'title': 'software_stack', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/overview/software_stack.rst \"Download source file\") * .pdf\\nFuriosaAI’s Software Stack ==========================\\nContents --------\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nFuriosaAI’s Software Stack [#](#furiosaai-s-software-stack \"Link to this heading\") ==================================================================================\\nFuriosaAI provides the streamlined software stack to allow FuriosaAI NPU to be used in various applications and environments. Here, we outline the SW stack provided by FuriosaAI, explaining the roles of each component, together with guidelines and tutorials. The above diagram demonstrates the SW stack provided by FuriosaAI, by layers.\\nThe following outlines the key components.\\nKernel Driver, Firmware, and PE Runtime [#](#kernel-driver-firmware-and-pe-runtime \"Link to this heading\") ----------------------------------------------------------------------------------------------------------\\nThe kernel device driver enables the Linux operating system to recognize NPU devices and expose them as Linux device files. The firmware runs on the SoC within the RNGD card and provides low-level APIs to the PE Runtime (PERT) that runs on the Processing Element (PE). PERT is responsible for communicating with the host’s runtime and scheduling, managing the resources of PEs to execute NPU tasks.\\nFuriosa Compiler [#](#furiosa-compiler \"Link to this heading\") --------------------------------------------------------------\\nFuriosa compiler analyzes, optimizes a model graph, and generates a NPU executable program. The operation passes involve graph-level optimization, operator fusion, memory allocation optimization, scheduling, and data movement minimization across layers. When `torch.compile()` backend, `FuriosaBackend` is used or `furiosa-llm` is used, the Furiosa Compiler is transparently used to generate NPU executable programs for Runtime.\\nFuriosa Runtime [#](#furiosa-runtime \"Link to this heading\") ------------------------------------------------------------\\nRuntime loads multiple executable NPU programs generated by Furiosa compiler, and run them on the NPU. A single model can be compiled into multiple executable programs according to model architectures and applications. Runtime is responsible for scheduling NPU programs and managing computation and memory resource on NPUs and CPUs. Also, Runtime can use multiple NPUs and provides a single entry point to run the model on multiple NPUs.\\nFuriosa Model Compressor (Quantizer) [#](#furiosa-model-compressor-quantizer \"Link to this heading\") ----------------------------------------------------------------------------------------------------\\nFuriosa Model Compressor is a library as well as toolkit for model calibration and quantization. Model quantization is a powerful technique to reduce memory footprint, computation cost, inference latency and power consumption. Furiosa Model Compressor provides post-training quantization methods, such as\\n* BF16 (W16A16) * INT8 Weight-Only (W8A16) * FP8 (W8A8) * INT8 SmoothQuant (W8A8) * INT4 Weight-Only (W4A16 AWQ / GPTQ) (Planned in release 2024.2)\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ----------------------------------------------------\\nFuriosa LLM provides a high-performance inference engine for LLM models, such as Llama 3.1 70B, 8B, GPT-J, and Bert. Furiosa LLM is designed to provide the state-of-the-art serving optimization for LLM models. The key features of Furiosa LLM include vLLM-compatible API, PagedAttention, continuous batching, HuggingFace hub support, and OpenAI-compatible API server. You can find further information at [Furiosa LLM](../furiosa_llm/intro.html#furiosallm) .\\nKubernetes Support [#](#kubernetes-support \"Link to this heading\") ------------------------------------------------------------------\\nKubernetes, an open-source platform designed to manage containerized applications and services, is extensively adopted by various companies due to its robust capabilities for deploying, scaling, and automating containerized workloads. FuriosaAI software stack also offers native integration with Kubernetes, allowing seamless deployment and management of AI applications within a Kubernetes environment.\\nFuriosaAI’s device plugin enables Kubernetes clusters to recognize FuriosaAI’s NPUs and allows NPUs to be scheduled for workloads and services that require them. This feature allows users to easily deploy AI workloads with FuriosaAI NPUs on Kubernetes, enabling efficient resource utilization and scaling.\\nYou can find more information about Kubernetes support in the [Cloud Native Toolkit](../cloud_native_toolkit/intro.html#cloudnativetoolkit) .\\n[previous\\nFuriosaAI RNGD](rngd.html \"previous page\") [next\\nSupported Models](supported_models.html \"next page\")\\nContents\\n* [Kernel Driver, Firmware, and PE Runtime](#kernel-driver-firmware-and-pe-runtime) * [Furiosa Compiler](#furiosa-compiler) * [Furiosa Runtime](#furiosa-runtime) * [Furiosa Model Compressor (Quantizer)](#furiosa-model-compressor-quantizer) * [Furiosa LLM](#furiosa-llm) * [Kubernetes Support](#kubernetes-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.3943539776036881), NodeWithScore(node=TextNode(id_='13853744-dc18-4c98-b1c2-4f5806b28514', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/', 'title': '', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](_sources/index.rst \"Download source file\") * .pdf\\nFuriosaAI Developer Center ==========================\\nContents --------\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nFuriosaAI Developer Center [#](#furiosaai-developer-center \"Link to this heading\") ==================================================================================\\nWelcome to the FuriosaAI Developer Center. FuriosaAI provides an streamlined software stack for deep learning model inference on FuriosaAI NPUs. This document provides a guide to easily perform the entire workflow of writing inference applications, from starting with PyTorch model to model quantization, serving, and production deployment.\\nWarning\\nThis document is based on Furiosa SDK 2024.1.0 (alpha) version, and the features and APIs described in this document may change in the future.\\nOverview [#](#overview \"Link to this heading\") ----------------------------------------------\\n* [FuriosaAI RNGD](overview/rngd.html#rngd)   : RNGD Hardware Specification, and features * [FuriosaAI’s Software Stack](overview/software_stack.html#softwarestack)   : An overview of the FuriosaAI software stack * [Supported Models](overview/supported_models.html#supportedmodels)   : A list of supported models * [What’s New](whatsnew/index.html#whatsnew)   : New features and changes in the latest release * [Roadmap](overview/roadmap.html#roadmap)   : The future roadmap of FuriosaAI Software Stack\\nGetting Started [#](#getting-started \"Link to this heading\") ------------------------------------------------------------\\n* [Installing Prerequisites](getting_started/prerequisites.html#installingprerequisites)   : How to install the prerequisites for FuriosaAI Software Stack * [Quick Start with Furiosa LLM](getting_started/furiosa_llm.html#gettingstartedfuriosallm) * [Running MLPerf™ Inference Benchmark](getting_started/furiosa_mlperf.html#gettingstartedfuriosamlperf)\\nCloud Native Toolkit [#](#cloud-native-toolkit \"Link to this heading\") ----------------------------------------------------------------------\\n* [Cloud Native Toolkit](cloud_native_toolkit/intro.html#cloudnativetoolkit)   : An overview of the Cloud Native Toolkit * [Kubernetes Support](cloud_native_toolkit/kubernetes.html#kubernetes)   : An overview of the Kubernetes Support\\nDevice Management [#](#device-management \"Link to this heading\") ----------------------------------------------------------------\\n* [furiosa-smi](device_management/furiosa_smi.html#furiosasmi)   : A command line utility for managing FuriosaAI NPUs\\nCustomer Support [#](#customer-support \"Link to this heading\") --------------------------------------------------------------\\n* [FuriosaAI Homepage](https://furiosa.ai) * [FuriosaAI Forum](https://furiosa-ai.discourse.group/) * [FuriosaAI Customer Portal](https://furiosa-ai.atlassian.net/servicedesk/customer/portals/) * [FuriosaAI Warboy SDK Document](https://furiosa-ai.github.io/docs/latest/en/)\\n[next\\nFuriosaAI RNGD](overview/rngd.html \"next page\")\\nContents\\n* [Overview](#overview) * [Getting Started](#getting-started) * [Cloud Native Toolkit](#cloud-native-toolkit) * [Device Management](#device-management) * [Customer Support](#customer-support)\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.17281989524921104)]\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Retrieve document\n",
    "print(f\"Answer = {qa_with_link['page_id'].values[0]} \\n\")\n",
    "print(\"-\"*10)\n",
    "\n",
    "## VectorDB\n",
    "semantic_results = chroma_retriever.retrieve(qa_with_link['question'].values[0])\n",
    "\n",
    "## BM25\n",
    "lexical_results = bm25_retriever.retrieve(qa_with_link['question'].values[0])\n",
    "print(lexical_results)\n",
    "print(\"-\"*10)\n",
    "\n",
    "## Hybrid\n",
    "retrieved_contents = hybrid_cc(semantic_results=semantic_results, lexical_results=lexical_results)\n",
    "print(retrieved_contents)\n",
    "print(\"-\"*10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[NodeWithScore(node=TextNode(id_='3e9b309f-d9d2-4ee7-be9e-9ffe421d4cfa', embedding=None, metadata={'source': 'https://furiosa-ai.github.io/docs-dev/2024.1/en/furiosa_llm/intro.html', 'title': 'intro', 'parent_doc_id': '', 'child_doc_ids': '[]'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text='* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\") * .pdf\\nFuriosa LLM ===========\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ====================================================\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models, Furiosa LLM is designed to provide the state-of-the-art serving optimization. The features of Furiosa LLM includes:\\n* vLLM-compatible API * Efficient KV cache management with PagedAttention * Continuous batching of incoming requests in serving * Quantization: INT4, INT8, FP8, GPTQ, AWQ * Data Parallelism and Pipeline Parallelism across multiple NPUs * Tensor Parallelism (planned in release 2024.2) across multiple NPUs * OpenAI-compatible API server * Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned) * HuggingFace model integration and hub support * HuggingFace PEFT support (planned)\\n[previous\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..', mimetype='text/plain', start_char_idx=None, end_char_idx=None, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), score=0.6566028339457801)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Cutoff\n",
    "retrieved_contents_filtered = cutoff.postprocess_nodes(retrieved_contents)\n",
    "retrieved_contents_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'* [.rst](../_sources/furiosa_llm/intro.rst \"Download source file\") * .pdf\\nFuriosa LLM ===========\\nFuriosa LLM [#](#furiosa-llm \"Link to this heading\") ====================================================\\nFuriosa LLM provides a high-performance inference engine for LLM models and Multi-Modal LLM models, Furiosa LLM is designed to provide the state-of-the-art serving optimization. The features of Furiosa LLM includes:\\n* vLLM-compatible API * Efficient KV cache management with PagedAttention * Continuous batching of incoming requests in serving * Quantization: INT4, INT8, FP8, GPTQ, AWQ * Data Parallelism and Pipeline Parallelism across multiple NPUs * Tensor Parallelism (planned in release 2024.2) across multiple NPUs * OpenAI-compatible API server * Various decoding algorithms, greedy search, beam search, top-k/top-p, speculative decoding (planned) * HuggingFace model integration and hub support * HuggingFace PEFT support (planned)\\n[previous\\nRunning MLPerf™ Inference Benchmark](../getting_started/furiosa_mlperf.html \"previous page\") [next\\nReferences](references.html \"next page\")\\nBy FuriosaAI, Inc.\\n© Copyright 2024, FuriosaAI, Inc..'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retrieved_contents_filtered[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Complete prompt & Generate LLM answer\n",
    "print(qa_with_link['question'].values[0])\n",
    "if len(retrieved_contents) > 0:\n",
    "    full_prompt = prompt.format(query=qa_with_link['question'].values[0], retrieved_contents=retrieved_contents_filtered)\n",
    "    result = llm.complete(full_prompt)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from llama_index.core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class SubBotResponse(BaseModel):\n",
    "    answer: str = Field(\n",
    "        default=\"\",\n",
    "        description=\"Answer of llm based on user question and given context\",\n",
    "    )\n",
    "    docs: List[str] = Field(\n",
    "        default=[],\n",
    "        description=\"List of reference_id of the metadata in Something to read.\",\n",
    "    )\n",
    "\n",
    "output_parser = PydanticOutputParser(output_cls=SubBotResponse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.workflow import (\n",
    "    Event,\n",
    "    StartEvent,\n",
    "    StopEvent,\n",
    "    Workflow,\n",
    "    step,\n",
    "    Context,\n",
    ")\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "from llama_index.llms.ollama import Ollama\n",
    "\n",
    "class RetrieverEvent(Event):\n",
    "    retrieved_nodes: List[NodeWithScore]\n",
    "\n",
    "class CutoffEvent(Event):\n",
    "    retrieved_nodes_with_score: List[NodeWithScore]\n",
    "\n",
    "class PostprocessEvent(Event):\n",
    "    retrieved_contents: List[dict]\n",
    "\n",
    "class PromptEvent(Event):\n",
    "    prompt: str\n",
    "\n",
    "class HybridFlow(Workflow):\n",
    "\n",
    "    llm = Ollama(model=\"llama3.1:70b\")\n",
    "\n",
    "    @step\n",
    "    async def retrieve(self, ctx: Context, ev: StartEvent) -> RetrieverEvent:\n",
    "        query = ev.query\n",
    "        ctx.data[\"query\"] = query\n",
    "        return RetrieverEvent(retrieved_nodes=hybrid_cc(query, 3, 0.18))\n",
    "\n",
    "    @step\n",
    "    async def cutoff(self, ev: RetrieverEvent) -> CutoffEvent:\n",
    "        retrieved_nodes = ev.retrieved_nodes\n",
    "        return CutoffEvent(\n",
    "            retrieved_nodes_with_score=cutoff.postprocess_nodes(retrieved_nodes)\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def postprocess(self, ev: CutoffEvent) -> PostprocessEvent:\n",
    "        retrieved_nodes_with_score = ev.retrieved_nodes_with_score\n",
    "        return PostprocessEvent(retrieved_contents=postprocess_nodes(retrieved_nodes_with_score))\n",
    "\n",
    "    @step\n",
    "    async def prompt(self, ctx: Context, ev: PostprocessEvent) -> PromptEvent:\n",
    "        query = ctx.data[\"query\"]\n",
    "        retrieved_contents = ev.retrieved_contents\n",
    "        return PromptEvent(\n",
    "            prompt=prompt.format(query=query, retrieved_contents=retrieved_contents)\n",
    "        )\n",
    "\n",
    "    @step\n",
    "    async def generate(self, ev: PromptEvent) -> StopEvent:\n",
    "        prompt = ev.prompt\n",
    "        print(prompt)\n",
    "        response = await self.llm.acomplete(prompt)\n",
    "        return StopEvent(result=str(response))\n",
    "\n",
    "w = HybridFlow(timeout=60, verbose=True)\n",
    "result = await w.run(query=qa_with_link['question'].values[1])\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-quantize",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
